
# [A Hybrid Neural Coding Approach for Pattern Recognition With Spiking Neural Networks](https://ieeexplore.ieee.org/document/10347028/)
## 题目：用于脉冲神经网络模式识别的混合神经编码方法
**作者：Xinyi Chen; Qu Yang; Jibin Wu; Haizhou Li; Kay Chen Tan**  
**源码： https://github.com/xychen-comp/HybridCoding-SNN**  
****

# 摘要
近年来，受大脑启发的脉冲神经网络（SNNs）在解决模式识别任务方面展现出了有希望的能力。然而，这些SNNs是建立在同质神经元的基础上，利用统一的神经编码来表示信息。鉴于每种神经编码方案都有其优点和缺点，这些SNNs在实现诸如准确性、响应时间、效率和鲁棒性等关键性能方面面临挑战，所有这些对于实际应用都至关重要。在本研究中，我们认为应该全面设计SNN架构，以纳入异构编码方案。作为这一方向的初步探索，我们提出了一个混合神经编码和学习框架，它包含了一系列在神经科学中发现的多样化神经编码方案。此外，它还包括一个灵活的神经编码分配策略，以适应特定任务的要求，以及新颖的逐层学习方法，以有效实现混合编码SNNs。我们在图像分类和声音定位任务中展示了所提出框架的优越性。具体来说，所提出的混合编码SNNs达到了与最先进的SNNs相当准确性，同时显著降低了推理延迟和能耗，以及高噪声鲁棒性。本研究为混合神经编码设计提供了有价值的见解，为开发高性能神经形态系统铺平了道路。

# 关键词
- 混合神经编码和学习框架
- 逐层学习
- 神经编码
- 神经形态计算
- 脉冲神经网络

# I. 引言
人类大脑是最复杂且能效高的计算系统，其中生物神经元使用电脉冲或“脉冲”相互传递信息。脉冲神经网络（SNNs），具有丰富的神经元动态和稀疏的脉冲活动，旨在模拟生物神经系统在硅基中的卓越信息处理机制。所包含的更高程度的生物学细节赋予了SNNs更大的潜力，以达到其生物对应物前所未有的性能。

近期在SNN训练算法发展[1]、[2]、[3]和模型架构设计[4]、[5]方面的进步，使得SNNs能够广泛应用于图像分类[6]、[7]、语音处理[8]、[9]、[10]和机器人控制[11]、[12]等。然而，如何将感觉信号编码成脉冲序列并在SNN内部处理它们以实现最佳任务性能仍然难以捉摸。用于解决模式识别任务的最新技术（SOTA）SNNs主要基于同质神经元，这些神经元共享统一的神经编码方案。它进一步依赖于大规模数据集的扩展学习，以达到高分类准确率。这种同质编码方法在有效实现系统在实践中预期实现的多个目标方面面临挑战，包括准确性、效率、响应时间和鲁棒性。例如，考虑一个集成了视觉、触觉和声音等多种感觉输入的机器人系统。在不同的空间和时间分辨率下收集的信号需要不同的处理。

生物神经系统的发现促使我们探索神经计算中的多样化神经编码方案。在过去的几十年中，越来越多的生物学证据表明，感知和认知是由多样化的神经编码方案支持的，这些方案被认为在神经系统中的信号处理、学习和记忆方面发挥着至关重要的作用[13]。神经编码的最早研究可以追溯到1926年，当时Adrian和Zotterman首次揭示了向肌肉内神经末梢发出的神经脉冲的放电率与挂在肌肉上的重量成正比[14]。从那时起，来自不同神经系统的大量证据累积起来，并得出结论，神经元的放电率是关键的信息载体。然而，率编码未能解释神经计算的许多重要特征。为了解决这个限制，提出了时间编码方案作为补充方法，以解释率编码的局限性。例如，在人类视觉系统中，自刺激开始后，可以在150毫秒内完成对象识别[15]，在这段时间内，信号需要穿过多个相互连接的阶段。提出了等级顺序编码来解释这种快速的信息处理。它表明感觉信息是通过脉冲的时序顺序来表示的，更重要的特征将更早地传达[16]。此外，在海马体中形成记忆期间，发现脉冲活动与正在进行的神经振荡相位相关[17]。此外，如在丘脑、海马体和听觉系统中观察到的，神经元能够以小的脉冲间隔发射一连串脉冲。这种快速信息传输机制促成了突发编码的发展[18]。

关于神经编码的大量研究为SNN设计提供了丰富的灵感。然而，大多数现有的SNNs仅基于这些神经编码方案中的单一类型，忽视了它们之间的关键相互作用。因此，这种设计方法通常会导致目标任务的次优性能。例如，直接编码在输入或输出层使用模拟值，保持了信息的高分辨率，但它是最不具备生物学合理性和能效的编码方案。大多数关于ANN到SNN转换的研究采用率编码来近似ReLU激活函数的输出与脉冲神经元的放电率[19]、[20]、[21]、[22]、[23]。然而，转换后的SNNs的高准确性通常以长时间的推理为代价。作为一种更可靠的编码方案，突发编码将信息编码到脉冲间隔（ISI）中，并允许在短暂的时间间隔内传输脉冲爆发，以实现鲁棒的信息传输[24]。尽管性能优越，实施突发编码需要高计算成本。一些最近的研究正在寻找更有效的编码方案。例如，相位编码将信息嵌入到基于脉冲相位的神经振荡中，显著降低了脉冲密度[25]。然而，原始的相位编码难以表示高度动态的信息流。另一方面，首次脉冲时间（TTFS）编码通过首次脉冲时间编码信息[26]、[27]、[28]。然而，基于TTFS的SNNs在训练期间面临梯度不稳定和死神经元问题[27]，这限制了其可扩展性。

在本文中，我们认为应该全面设计SNNs，通过纳入各种神经编码方案来实现最佳性能。为此，我们提出了一个混合神经编码和学习框架。正如图1所示，所提出的框架包含了一个由生物启发的神经编码方案组成的神经编码动物园。根据分配策略和任务要求，这些编码方案被分配到每个网络层，从而提供了所需的信息表示基础。此外，我们引入了一种逐层学习方法，以确保在每个网络层有效实现所需的神经表示。因此，混合编码SNNs可以利用多样化的编码方案来实现最佳任务性能。我们在图像和音频感知任务上验证了所提出框架的有效性，结果表明所期望的高准确性和鲁棒性，以及低延迟和能耗。本文的主要贡献总结如下：

- 我们提出了一种新的混合神经编码和学习框架，它采取全面的方法设计SNN的神经编码方案，以满足特定任务要求和环境条件。
- 我们提出了一种逐层学习方法，可以高效地实现所期望的神经编码方案，并具有高效性。
- 我们展示了所提出的框架在执行图像分类和声音定位任务时的优越性和多功能性。
- 我们的研究为多样化的混合神经编码设计提供了有价值的见解，为使用混合编码SNNs解决现实世界的模式识别任务提供了实用的指导。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/9c2cf9bf2d3247ddaa4af04382e7ea94.png" width="70%" /> </div>


本文的其余部分组织如下。在第二节中，我们详细介绍了所提出的混合神经编码和学习框架。在第三节和第四节中，我们分别评估了所提出框架在图像分类和声音定位任务中的性能。此外，我们在第四节进行了一系列的消融研究，比较了不同的混合编码设计。最后，我们在第五节中得出了我们的发现。

# II. 一种用于尖峰神经网络的混合神经编码与学习框架

在本节中，我们提出了一种混合神经编码和学习框架，为设计混合编码尖峰神经网络（SNNs）提供了一种全面的方法。如图1所示，我们的框架由三个关键组成部分构成：神经编码库、混合编码分配策略和逐层学习方法。接下来，我们首先概述SNNs及其编码方案。基于此，我们随后描述了构成我们神经编码库的一系列受大脑启发的神经编码方案。我们还将详细阐述用于将这些编码方案分配到网络不同层的策略。此外，我们以图像分类和声音定位任务为例，阐释如何设计混合编码分配策略以实现不同的任务目标。最后，我们展示了所提出的逐层学习方法。

## A. 神经编码库

与传统人工神经元不同，尖峰神经元旨在再现生物神经元的复杂神经元动态。特别是，尖峰神经元使用尖峰序列作为信息载体来相互传递信息。信息是如何通过一系列尖峰序列表示的，这一概念被称为神经编码方案，它显著影响其信息处理能力。通常，尖峰序列中的频率、精确的尖峰时间以及同步模式都可以用来传递信息。适当地将这些神经编码方案分配给SNN，可以显著提高其信息处理效率、效果和鲁棒性。

受神经科学中发现的丰富生物神经表示的启发，已探索了多种神经编码方案，每种方案都有其独特的优势和局限性。在我们提出的框架中，神经编码库是对最具代表性的编码方案的全面收集，为设计混合编码SNNs提供了丰富的候选选项。它包括直接编码、频率编码、相位编码、爆发编码和首次尖峰时间（TTFS）编码，有助于构建能够满足多样化任务需求并适应各种环境条件的多功能SNNs。以下，我们提供了每种候选神经编码方案的详细总结，它们的优点和缺点在图2中进行了描述。值得注意的是，我们的神经编码库可以轻松整合任何新发现或开发的神经编码方案。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/46fc851ab1ce4083b1154e2b779ea311.png" width="70%" /> </div>


- 直接编码在SNNs的输入和输出层中得到广泛应用，它直接使用模拟值来编码输入刺激或解码输出[3]，[10]。鉴于其模拟特性，这是最不生物学合理且能效低的编码方案，因为它放弃了基于二进制尖峰的信息表示。尽管如此，直接编码可以避免其他编码方案固有的采样误差和小延迟，从而确保信息表示的高保真度。

- 频率编码使用给定时间窗口内的平均发射频率来表示信号值。由于ReLU激活值和尖峰神经元的发射频率之间的相似性，频率编码已广泛用于ANN到SNN的转换方法[19]，[20]，[21]，[22]，[23]，以构建能够良好近似ANN特征表示的SNNs。尽管其生物学合理性和优越的信息表示能力，频率编码常因高延迟、能效低下以及在表示高度动态信号方面的无效性而受到批评。

- 相位编码通过尖峰活动相对于基础神经振荡的相位来表示信息[29]。它被证明比频率编码在信息传输上更加高效，并且提供比TTFS编码更高的噪声鲁棒性[30]。然而，相位编码的表示能力受到基础神经振荡频率的限制，这导致在表示快速变化刺激时性能下降[25]，[31]。

- 爆发编码有效地利用ISI来表示信息[32]，并且在信息传输上非常高效[33]。然而，跟踪ISI引入了高计算复杂性。为解决这个问题，最近的研究提出使用一个神经元模型，该模型可以在单个时间步内发出多个尖峰来表示分级ISIs[24]，[34]，从而形成一个简单而健壮的神经编码方案。

- TTFS编码基于首次尖峰的时间对信息进行编码，其中较早的尖峰代表更重要的信息。这种编码方案带来了快速推理、低尖峰密度和低能耗的有利属性[35]，[36]。然而，TTFS编码因臭名昭著的死神经元问题而受到影响，这可能会影响训练稳定性。此外，尖峰时间对神经元噪声非常敏感，这是神经系统和模拟计算基板中常见的现象。

## B. 混合编码分配策略

如前所述，每种均匀的神经编码方案都有其独特的优点和缺点，如果单独应用，将显著影响SNNs的整体性能。因此，我们的目标是设计能够利用这些均匀神经编码方案的优势来实现最佳任务性能的混合编码SNNs。这可以通过从我们的神经编码库中选择合适的神经编码方案，并根据不同的任务需求和环境条件将它们分配到网络的不同部分来实现。然而，这将导致一个复杂的组合优化问题，对于大规模网络来说是难以解决的。为了减少设计工作量并加速训练，我们将网络层组织成三个块，每个块在其整体中采用均匀的神经编码方案。具体来说，我们在这项工作中关注三个网络块：输入层、隐藏层和输出层。以下，我们描述了在将神经编码方案分配给这三个网络块时的关键因素。

- 输入层作为SNN与其外部环境之间的接口，扮演着重要角色。对于这一层来说，提供对输入刺激的高效、实时和高保真的表示至关重要。为了实现这些目标，输入编码方案必须针对输入信号的特性和当前环境条件进行定制，确保快速响应，同时在采样和编码过程中最小化信息损失。

- 隐藏层在从输入刺激中提取丰富和层次化特征表示方面起着关键作用。因此，所选择的编码方案不仅促进有效的特征提取，而且还需要在计算成本和对神经元噪声的鲁棒性之间取得平衡。

- 输出层作为决策生成的输出接口，因此需要一种神经编码方案，该方案可以同时促进准确和快速的决策制定。

这种分配策略作为如何构建能够满足特定任务目标和环境条件的最优混合编码SNN的一般指导方针。

## C. 图像分类的混合编码设计

在本节中，基于前面介绍的神经编码库和分配策略，我们将说明如何实际构建混合编码SNN来解决图像分类任务。

1) **直接编码以实现高保真输入表示**：在图像分类任务中，通常需要对输入图像进行高保真的表示。然而，使用频率编码可能需要一个大的采样时间窗口和高发射频率，导致运行缓慢且效率低下。另一方面，时间编码方案（例如，TTFS编码）可能会遇到死神经元和梯度不稳定的问题，对训练的便利性产生不利影响[27]。为了解决这些挑战，我们采用了直接编码方案，将图像像素的强度值视为输入电流，并直接将其注入到第一隐藏层的神经元中[3]，[10]。这种方法绕过了模拟到尖峰的转换过程，消除了基于速率的采样过程中的信息损失以及时间编码中的量化误差。

2) **爆发编码以实现可靠和快速的隐藏特征表示**：与频率编码不同，后者限制神经元一次最多发射一个尖峰，而爆发神经元可以生成多达Γ个尖峰。这一特性有助于以更大的鲁棒性更快地传输重要信息。因此，我们采用爆发编码来隐藏层，以确保尖峰特征表示能够迅速而有效地传输到后续层。具体来说，Γ设置为5，考虑到生物学发现中神经元很少在单个时间步内发射超过五个尖峰[37]（有关Γ选择的更详细分析，请参见补充材料）。我们使用了[34]中引入的爆发神经元模型，其中膜电位的充电如下：

$$
v_l(t) = v_l(t - 1) + I_l(t),
$$

其中 $I_l(t)$ 表示由输入尖峰诱导的输入电流，定义为 $I_l(t) = W_l s_{l-1}(t)$ 。 $s_{l-1}(t)$ 是来自层 $l - 1$的输入尖峰， $W_l$ 表示层 $l$ 和 $l - 1$ 之间的权重矩阵。一旦膜电位 $v_l$ 超过发射阈值 $V_l^{th}$ ，就会生成输出尖峰爆发 $s_l$ ，并且膜电位 $v_l$ 将使用减法重置方案[38]重置为：

$$
s_l(t) = \min\left(\max\left(v_l(t) - V_l^{th}, 0\right), \Gamma\right),
$$

$$
v_l(t) = v_l(t) - s_l(t) \cdot V_l^{th}，
$$

其中 $s_l(t)$ 表示时间步 $t$ 中的爆发尖峰计数，其值取自范围 $[0, \Gamma]$ 。

3) **TTFS编码以实现快速高效的输出决策**：在隐藏层完成图像特征提取过程后，输出层负责决策制定。理想情况下，分类决策应在输出层 $L$ 积累了足够的证据后立即做出。为了实现这一点，我们采用TTFS编码，一旦检测到第一个输出尖峰，就做出最终决策，而不需要等待所有模拟时间步完成。这种设计导致推理时间显著减少，同时有效避免了与时间编码通常相关的梯度不稳定性问题，因为它仅限于单层实现。具体来说，我们采用了双指数泄漏积分-发射（LIF）尖峰神经元模型。它比隐藏层中使用的爆发神经元模型提供了更丰富的时间动态，并且定义为[39]：

$$
v_L(t) = W_L K_L(t),
$$

$$
s_L(t) = H(v_L(t) - V_L^{th})，
$$

其中 $H(\cdot)$ 表示Heaviside步函数。一旦膜电位 $v_L$ 穿过发射阈值 $V_L^{th}$ ，神经元就会发射尖峰。 $K_L(t)$ 是由输入尖峰诱导的后突触电位（PSP）核，定义为[39]：

$$
K_L(t) = K_0 \cdot (m_L(t) - I_L(t)),
$$

$$
m_L(t) = e^{-1/\tau_m} \cdot (m_L(t - 1) + s_{L-1}(t)),
$$

$$
I_L(t) = e^{-1/\tau_s} \cdot (I_L(t - 1) + s_{L-1}(t)),
$$

其中 $K_0$ 是归一化常数，它使 $K_L$ 的最大值与 $V_L^{th}$ 对齐， $\tau_m$ 和 $\tau_s$ 分别是两个突触组件 $m_L$ 和 $I_L$ 的衰减常数。

输入图像的分类结果，即 $y_L$ ，由产生第一个尖峰的输出神经元 $i$ 确定。我们记录这个第一个尖峰的触发时间为 $t_f$ 。然而，在某些边缘情况下，使用特定一组标准来做出最终决策。如果多个神经元同时发射，决策如下做出：

$$
y_L = \max_i (v_{L_i} (t_f)).
$$

此外，在没有任何神经元发射直到结束的情况下，我们将最后一个时间步视为决策时间，并根据(5)确定分类结果。

## D. 声音定位的混合编码设计

在本节中，我们进一步采用所提出的混合神经编码和学习框架来解决声音定位任务，展示了其在不同信号模态和任务需求中的泛化能力。

1) **相位编码以实现高保真输入表示**：哺乳动物具有非凡的能力来确定声音的来源，因为它们可以辨别两个耳朵之间到达的时间差（TDOA）[40]。具体来说，来自同一源的声音传播并以不同的时间延迟和能量衰减到达两个耳朵，这为声音定位提供了关键线索。为了检测这些差异，每个耳蜗首先采用相位编码将不同的声音编码为相位锁定的尖峰序列。随后，内侧上橄榄（MSO）中的检测神经元可以辨别这些尖峰序列之间的相位差异，从而实现声音定位[41]。

借鉴声音信号的时间特性和生物信息表示机制，相位编码成为提取和编码定位线索的理想选择。因此，我们采用多音调相位编码（MTPC）[42]作为我们框架中的输入编码方案，以确保输入的高保真表示。如图3所示，接收到的音频首先被分解为几个单音调正弦信号。然后，在每个正弦信号的第一个峰值时间生成一个尖峰，表示声音的到达时间。巧合检测神经元随后检测两个麦克风之间的相位差异，如果在观察到特定的时间延迟，则发出一个尖峰。最后，从子带生成的输出尖峰使用恒定Q变换（CQT）进行聚合，以压缩输入维度。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/b8334e046049491885478e5b80a45dd4.png" width="70%" /> </div>


2) **爆发编码以实现鲁棒的隐藏特征表示**：在音频信号处理中，快速信息传输和鲁棒信息表示是选择隐藏层编码方案时两个理想的属性。低延迟可以显著提高系统的总体鲁棒性，因为它允许系统快速响应输入信号的变化。同时，鲁棒的信息表示可以有效克服普遍存在的神经元噪声。为此，我们选择爆发编码用于隐藏层，因为它在这两个方面表现出色，如图2所示。

3) **TTFS编码以实现快速高效的输出决策**：高精度、对移动声源的快速响应和优越的能效是任何听觉接口的关键属性。这些因素激发了我们为定位网络的输出层选择TTFS编码。在第III-B节中，我们将说明TTFS编码如何有效地减少推理时间，而不影响定位精度。此外，在第IV-B节中，我们将比较TTFS编码与其他编码方案，以进一步验证其在声音定位的背景下的有效性。

## E. 混合编码的逐层学习方法

尽管混合编码SNNs在分配不同编码方案到不同网络阶段时提供了灵活性，但它也带来了自己的挑战。特别是，使用不同的神经编码方案使得传统的端到端训练方法不兼容。为了解决这一挑战，我们提出了一种新的逐层训练方法，专门用于实现设计的混合编码SNN。具体来说，隐藏层和输出层被独立地以更易于管理的方式进行训练。

### 1) 隐藏层

对于所有隐藏层，采用了逐层教师-学生学习方法。具体来说，我们的方法利用一个预训练的ANN作为教师，来监督学生SNN的训练。考虑到ANN的中间特征表示作为目标，我们混合编码SNN的隐藏层被训练以生成等效的基于尖峰计数的特征表示。为此，使用均方误差（MSE）作为每个隐藏层的局部损失函数，定义如下：

$$
L_l \left( \hat{y}_ l, c_l(T) \right) = \frac{1}{2} \sum_{t=1}^{T} \left( \hat{y}_{l} - r_l \cdot c_l(T) \right)^2,
$$

其中 $\hat{y}_ l$ 表示ANN层 $l$ 中神经元的激活， $T$ 是时间窗口长度， $c_l(T) = \sum_{t=1}^{T} s_l(t)$ 是总尖峰计数。 $r_l$ 是一个层级缩放因子，其值固定为1。这确保了尖峰神经元的发射率，表示为 $c_l(T)/T$ ，可以有效地与ANN神经元的激活值对齐（有关 $r_l$ 选择的更详细分析，请参见补充材料）。

为了消除训练和测试之间的不匹配，我们通过考虑输入尖峰序列的时间动态，而不仅仅是像[21]中那样只考虑平均发射率来训练每个隐藏层。具体来说，采用时间反向传播（BPTT）算法在每个层进行时间信用分配。权重更新可以得出如下：

$$
\Delta W_l \propto \frac{\partial L_l}{\partial W_l} = \sum_{t=1}^{T} \frac{\partial L_l}{\partial v_l(t)} s_{l-1}(t).
$$

为了表达方便，我们设 $\delta_l(t) = \frac{\partial L_l}{\partial s_l(t)}$ ，得到

$$
\frac{\partial L_l}{\partial v_l(t)} = \left( \delta_l(t + 1) \frac{\partial s_l(t+1)}{\partial v_l(t+1)} + \delta_l(t) \frac{\partial s_l(t)}{\partial v_l(t)} \right),
$$

如果 $t < T$ ，则

$$
\delta_l(T) \frac{\partial s_l(T)}{\partial v_l(T)}，
$$

如果 $t = T$ ，

$$
\delta_l(t) = \begin{cases} 
V_l^{th} \delta_l(t + 1) \frac{\partial s_l(t+1)}{\partial v_l(t+1)}, & \text{如果 } t < T, \\
\frac{2}{T} \left( \hat{y}_ l - r_l \left( \frac{1}{T} \sum_{t=1}^{T} s_l(t) \right) \right), & \text{如果 } t = T.
\end{cases}
$$

为了解决爆发神经元中的不连续性问题（如(2)所示），我们采用了直接通过估计器（即 $d⌊x⌋/dx = 1$ ）[43]，并得到 $\frac{\partial s_l(t)}{\partial v_l(t)} = 1$ 。这种局部学习方法，此后称为局部串联学习（LTL）规则，将原始的以速率编码为重点的LTL规则[44]扩展到适应额外的神经编码方案。

### 2) 输出层

为了实现快速准确的决策，输出层被训练以基于第一个输出尖峰做出正确的分类决策，这里称之为TTFS学习。它通过仔细平衡两个学习目标来实现。一方面，目标神经元的权重应该被调整以尽可能早地发射，以减少推理延迟。另一方面，所有其他神经元应该比目标神经元晚发射，以确保决策的准确性。这两个学习目标通过调整输出层的权重一起优化，同时保持所有其他隐藏层权重不变。

为了实现第一个目标，我们选择交叉熵（CE）损失作为第一个损失函数，它通过在训练期间增加目标神经元的膜电位来推进第一个尖峰时间：

$$
L_{L_1} = -\ln \frac{\exp(v_{L_{\text{target}}}(t_f))}{\sum_{i=1}^{n} \exp(v_{L_i}(t_f))},
$$

其中 $v_{L_i}(t_f)$ 表示输出神经元 $i$ 在第一个尖峰时间 $t_f$ 的电位， $n$ 是类别总数。

由于固定的发射阈值和由最小化 $L_1$ 导致的不断增长的膜电位，决策时间将不断提前，直到在最早可能的时间步做出每个决策。然而，这可能导致过度拟合问题，因为利用的输入信息不足。为了解决这个问题，我们引入了另一个损失，即 $L_2$ ，以暂停错误的决策并允许更多时间来利用输入信息。具体来说，当任何其他神经元比目标神经元早发射时，将触发长期抑制（LTD）：

$$
L_{L_2} = \sum_{i \neq \text{target}} \theta(t_f) \cdot (v_{L_i}(t_f) - V_L^{th}),
$$

其中 $\theta(t_f)$ 是一个缩放因子，定义为：

$$
\theta(t_f) = \max \left( 1 - \frac{\text{acc}(t_f)}{\text{acc}(T)} , 0 \right),
$$

其中 $\text{acc}(t_f)$ 和 $\text{acc}(T)$ 分别对应于第一个尖峰时间和最后一个时间步的推理准确率，其值在每次评估后更新。对于过早做出的错误决策，如果将决策时间推迟到更晚的时间步可以提高准确率，则其发射时间将被延迟，即 $\theta(t_f) > 0$ 。

上述两个损失函数的结合确保了简单决策可以尽早做出，而困难决策则被推迟到更晚和更信息丰富的时间步。输出层的权重更新可以表述如下：

$$
\Delta W_L \propto \frac{\partial L_L}{\partial W_L} = \frac{\partial L_L}{\partial v_L(t_f)} K_L(t_f),
$$

其中总损失 $L_L = \alpha L_{L_1} + \beta L_{L_2}$ 由两个超参数 $\alpha$ 和 $\beta$ 进行调整。通过调节 $\beta/\alpha$ 的比率，我们在分类准确率和推理延迟之间取得平衡。根据具体任务需求，较大的 $\beta/\alpha$ 有利于准确率，而较小的值则最小化推理延迟（有关 $\beta$ 和 $\alpha$ 选择的更详细分析，请参见补充材料）。在这项工作中，我们采用指标ΔAcc. × tinf作为在准确率和推理延迟之间权衡的手段。ΔAcc.表示从ANN到SNN的准确率下降，而tinf，即平均推理时间，等同于不同样本的平均第一个尖峰时间tf。

# III. 准确快速的图像分类与混合编码

在本节中，我们将比较所提出的混合编码方法与其他最先进的脉冲神经网络(SNNs)实现在CIFAR10[50]、CIFAR-100[50]和Tiny-ImageNet[51]数据集上的性能，主要考虑图像分类任务的两个主要性能指标：分类准确率和推理延迟[52]。对于所有数据集，我们使用VGG-16[53]和ResNet-20[54]网络结构。随后，我们将验证所提出的逐层学习方法的有效性和收敛速度。最后，我们将展示所提出的方法在显著降低计算成本的同时，能够达到最先进的分类准确率。为了简化，直接编码、速率编码、爆发编码、相位编码和首次脉冲时间编码方案在以下部分中分别用D、R、B、P和T表示。源代码可在 https://github.com/xychen-comp/HybridCoding-SNN 上找到。

### A. 卓越的图像分类性能
在表I中，我们报告了我们的结果，并将其与其他最先进的SNN模型进行了比较。为确保公平比较，我们选择了基于网络转换方法的转换误差或直接训练方法的分类准确率的竞争性SNN基准。总体而言，如图4所示的推理曲线，所提出的混合编码方法在所有模型架构和数据集上达到了可竞争的分类准确率，同时显著减少了推理时间。

对于CIFAR-10数据集，我们的VGG-16模型平均只需要4.87个时间步就能达到95.66%的分类准确率。而QCFS[20]，被认为是所有ANN到SNN转换方法中最好的，只能在16个时间步内达到可比较的准确率。从转换的ResNet-20模型中可以得出类似的结论。此外，我们的ResNet-20模型的表现超过了其他直接训练的模型，如STBP-tdBN[4]和TET[48]。

对于更具挑战性的CIFAR-100数据集，我们的模型在平均推理时间步分别为6.88和3.94的VGG-16和ResNet-20上达到了75.75%和75.39%的令人满意的准确率。如图4(b)和(e)所示，尽管我们的模型的分类准确率略低于Calibration[21]、Burst+LIPooling[34]和QCFS模型，但值得注意的是，它们的结果至少需要16个时间步才能达到。因此，我们的模型在推理时间和能耗方面更为有利。此外，我们在大规模的Tiny-ImageNet数据集上评估了我们的方法。由于该数据集上缺乏基准，我们使用他们公开提供的代码复制了Calibration、Burst+LIPooling和QCFS方法的结果。如图4(c)和(f)所示，显然我们提出的模型能够以更短的推理时间达到更优越的结果。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/ad59cdba093e44c4a8b0d67990bff767.png" width="70%" /> </div>


为了阐明所提出的混合编码SNN如何实现早期决策，我们在图5中展示了我们两个混合编码模型D+B+T和D+R+T的决策时间分布。虽然表I中列出的其他SOTA作品在输出层采用直接编码，导致所有决策都在最终时间步T进行，但我们的混合编码模型表现出由TTFS编码决策机制控制的不同决策时间。此外，很明显，首次脉冲时间在D+B+T和D+R+T模型中分别密集分布在4和8左右。这一结果证实了爆发编码有助于加快隐藏层之间的信息传输，为TTFS分类器所做出的早期决策提供了基础。此外，值得注意的是，较早时间步做出的决策表现出的准确率比晚些时候做出的决策高，如红色条所示。这一观察表明，早期决策通常对应于较简单的样本，TTFS编码能够确定不同样本何时已积累了足够的证据。与在最终时间步做出所有决策的直接解码相比，TTFS编码可以显著减少平均推理时间，同时实现高分类准确率。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/128712e59bd9469889280657d6923094.png" width="70%" /> </div>


<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/0b8c3b9bbbd94ec68bae6a5917bbb621.png" width="70%" /> </div>


### B. 逐层学习方法的有效性和快速训练收敛
为了进一步探索所提出的逐层学习方法的有效性和训练收敛速度，我们在本节中进行了一系列的研究。所有实验都在CIFAR-10数据集上使用VGG-16架构进行。

首先，为了评估LTL规则在产生由神经编码方案指定的期望隐藏层表示方面的有效性，我们系统地比较了Calibration模型[21]和LTL训练的D+R+D和D+B+D模型的性能。选择Calibration方法进行比较的原因是，在所有考虑的SOTA方法中，这种特殊方法在基本机制方面与我们提出的LTL学习方法最为相似。LTL训练的D+R+D和D+B+D模型分别只比教师ANN的准确率下降了0.56%和0.31%，这表明LTL规则在产生基于速率和爆发的神经表示方面非常有效。同样，在研究中，Calibration方法[21]被提出用于在逐层方式中微调隐藏层表示，遵循速率编码的原则。然而，该方法忽略了脉冲列的时间动态，并且只在脉冲列级别进行训练。因此，他们的模型采用D+R+D编码遇到了更大的准确率下降1.21%。

为了分析这种性能提升的根本原因，我们计算了教师ANN和学生SNN的卷积层之间的归一化MSE损失（即(6)），结果如图6(a)所示。正如预期的那样，LTL训练的D+R+D模型比Calibration模型实现了更低的MSE损失。这一发现表明，微调每个隐藏层的时间动态对于实现所需的神经表示至关重要。此外，LTL训练的D+B+D模型略优于D+R+D模型，表明爆发编码比速率编码能更好地近似教师ANN的神经表示。

此外，利用教师ANN的知识，逐层LTL规则比其他端到端训练规则能实现更快的训练收敛。为了说明这一点，我们比较了LTL规则与STBP-tdBN方法[4]和TET规则[48]的学习曲线。这两种方法是直接训练SNN的端到端方法，与我们的方法相当。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/d62ec12387c94c85aab95f1ad1683e78.png" width="70%" /> </div>


### C. 混合编码的卓越能效
在前几节中，我们展示了所提出的混合神经编码和学习框架可以实现快速决策。在这里，我们分析这一属性是否还能进一步为节能做出贡献。我们遵循IBM TrueNorth神经形态芯片在其开创性的Science论文[55]中提出的共同实践，来评估本工作中SNNs的能耗。此后，它已成为神经形态计算社区中用于基准测试不同SNN和ANN模型能效的普遍标准[10]、[56]、[57]。该方法侧重于量化SNNs和ANNs中基本操作的能耗，即突触操作(SynOps)。它提供了一种方便可靠的方法来估计和比较多个模型的能耗，从而实现公平的能效评估。为此，我们计算了等结构ANN和SNN的SynOps比率，通过乘法累加(MAC)和累加(AC)操作分别进行。ANN模型中所需的总SynOps可以计算为：

$$
SynOps(ANN) = L \cdot \sum_{l=1}^{L} \frac{fl_{in} \cdot N_l}{f_{l}}
$$  

其中L是总层数， $f_{l_{in}}$ 表示从前一层到层l的连接数， $N_l$ 是层l中的神经元总数。由于SNN模型具有额外的时间维度，并且仅在脉冲发生时操作，因此它们的总SynOps计算与ANN模型不同。因此，SNN模型中的总SynOps公式如下：

$$ SynOps(SNN) = T \cdot \sum_{t=1}^{T} \sum_{l=1}^{L-1} \sum_{j=1}^{N_l} f_{l_{out},j} \cdot s_j(t) $$

其中T是总推理时间， $f_{l_{out}}$ 表示从层l的神经元j到下一层的连接数， $s_j(t)$ 表示神经元j的脉冲计数。

为了与其他SOTA SNN模型进行公平比较，我们找到了最近的一些公开代码，并在CIFAR-10数据集上使用VGG-16架构复制了他们的结果。特别是，我们报告了在达到可比较的分类准确率时的时间步的SynOps比率。结果总结在表II中，我们的模型实现了最低的SynOps比率0.49，至少比其他SOTA模型低3.90倍。值得注意的是，我们的模型所需的总SynOps远低于QCFS转换方法，在T=16时达到1.91的SynOps比率。能耗的差异进一步验证了我们最初的发现，表明推理延迟的减少主要不是由于爆发编码提供的压缩时间窗口。相反，爆发编码允许重要信息更早地传输，允许TTFS编码做出早期和有效的决策。令人惊讶的是，TET直接训练模型的SynOps比率即使在可比的推理时间下也显著高于我们的，我们将其归因于TET训练中引入的活动正则化损失。具体来说，这个损失项促进了脉冲随时间的稳定生成。一旦去除这个损失项，模型在最后几个时间步中倾向于更频繁地发放脉冲，这反过来降低了整体的发射率。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/8515a6457b724c6c913b307969da8ce8.png" width="70%" /> </div>


最近一项关于45 nm CMOS技术的研究的经验证据表明，32位浮动MAC和AC操作分别消耗4.6 pJ和0.9 pJ的能量。因此，我们的SNN模型可以产生一个数量级的节能效果。当使用更便宜的32位整数运算时（相应的MAC和AC运算为3.1pJ和0.1pJ），节省可以进一步提高到65.31×。

# IV. 混合编码实现高效且鲁棒的声音定位

在本节中，我们评估了所提出的混合神经编码和学习框架在SLoClas数据集上的性能[59]，该数据集旨在用于真实世界的声音定位和分类任务。特别是，我们全面比较了混合编码SNN与其他最新模型，关注定位精度、推理延迟、能耗和噪声鲁棒性。此外，进行了一系列消融研究，以深入了解不同混合神经编码组合对整体性能的影响。数据预处理、MTPC前端和SNN架构的详细配置在补充材料中进行了总结。

## A. 精确、快速且鲁棒的声音定位

为了全面评估我们提出的模型和其他最新方法的定位精度，我们报告了平均绝对误差（MAE）和定义如下的分类准确率[59]：

$$
\text{MAE (°)} = \frac{1}{N_t} \sum_{i=1}^{N_t} | \hat{\theta}_i - \theta_i |,
$$

$$
\text{Acc. (\%)} = \frac{1}{N_t} \sum_{i=1}^{N_t} ( | \hat{\theta}_i - \theta_i | < \eta ),
$$

其中 $\hat{\theta}_i$ 和 $\theta_i$ 分别是样本 $i$ 的估计和真实方位角。 $\eta$ 是确定样本是否正确分类的可接受绝对误差。 $N_t$ 是测试样本的总数。鉴于原始音频以5°的分辨率记录，我们通过将 $\eta$ 设置为2.5°来保持一致性。

在表III中，我们的混合编码SNN实现了0.60°的MAE，并且平均推理时间仅为4.37个时间步，超越了所有其他最新SNN模型，同时所需的推理时间相当或更短。定位精度也与其他最近提出的ANN模型相当。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/ff9d6fbf61ac4b6492d5db94367eb6e1.png" width="70%" /> </div>


此外，我们模型的噪声鲁棒性也得到了评估，与其他SNN模型相比。方向背景噪声片段提供在SLoClas数据集中，随机选择并添加到测试音频剪辑中，以不同的信噪比（SNR）。如图7所示，我们的混合编码SNN在不同噪声水平下始终展现出更高的背景噪声鲁棒性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/626a35eca2d545f5be33c289818c865c.png" width="70%" /> </div>


## B. 混合编码设计的消融研究

为了系统地研究声音定位任务中不同混合编码组合的影响，我们进行了一系列消融研究。具体来说，我们详细分析了四种最有前途的组合：P+R+D、P+B+D、P+R+T和P+B+T。

### 1) 定位精度、延迟和能耗：

我们首先评估了不同混合编码设计的平均绝对误差（MAE）、推理时间和SynOps。为了研究输出解码方案对网络性能的影响，我们首先对P+B+T和P+B+D进行了比较分析，以及P+R+T和P+R+D。显然，直接解码和TTFS编码产生了几乎相同的MAE，而TTFS编码仅需要大约三分之一到一半的平均推理时间。这些结果进一步支持了我们的观点，即TTFS编码可以在保持高精度的同时减少推理延迟和能耗。有趣的是，两种输出编码方案之间的能效比和推理时间比显示出一致的值，无论隐藏层使用了什么编码方案。这一观察表明，减少推理时间在总节能中起着关键作用。

此外，结果还为我们提供了关于隐藏层编码方案影响的宝贵见解。与频率编码相比，爆发编码通过减少0.22°的MAE并加快3.25个时间步的决策制定而表现出色。然而，爆发编码可能导致更高的尖峰发射率，从而增加能耗。为了优化网络性能，选择爆发编码和频率编码取决于任务的具体要求。例如，如果优先考虑能效，P+R+T设计可能是首选。或者，如果最小化MAE和延迟是主要关注点，P+B+T设计无疑是一个更优越的选择。值得注意的是，尽管它比P+R+T设计需要更多的能量，但它仍然只需要竞争性ANN模型一半的能耗，实现了精度、延迟和能耗之间的最佳平衡。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/95908ab3e2da41e5a5dc5e6206b78c9a.png" width="70%" /> </div>


### 2) 环境噪声：

为了研究混合编码设计对噪声鲁棒性的影响，我们使用两种不同形式的环境噪声生成了噪声污染的测试样本，即工厂噪声和嘈杂噪声。所有模型都在干净的训练样本上进行训练，然后在不同信噪比下的噪声污染测试样本上进行评估。不同混合编码设计的结果如图8(a)和(b)所示。总的来说，P+B+T设计在大多数条件下表现出最高的噪声鲁棒性。这一显著的进步可以归因于TTFS编码对累积噪声不太敏感，因为它只需要大约三分之一的决策时间。然而，当环境噪声显著损害信息完整性时，TTFS编码也可能产生不利影响，因为它只能利用有限的证据，因为推理时间的减少。此外，我们的结果表明，混合编码SNNs在嘈杂噪声下的表现一致优于工厂噪声，因为后者具有更大的频率变化。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/b274746cd70544ab87b18c56b7748d2a.png" width="70%" /> </div>


### 3) 神经元噪声：

此外，我们还分析了混合编码设计对神经元噪声的鲁棒性，神经元噪声在人类神经系统中无处不在。在神经元噪声条件下研究网络性能提供了一个机会，可以识别出最有可能模仿人类听觉系统的最有前途的设计。神经元噪声是通过引入尖峰删除操作来模拟的，这意味着在每个时间步，一定比例的隐藏神经元以给定的概率未能生成输出尖峰。结果以删除率函数的形式在图8(c)中可视化。这表明TTFS编码在神经元噪声条件下比直接解码更可靠，这与我们对环境噪声的观察一致。有趣的是，当大量信息传输失败（>60%）时，P+R+T设计在性能上超过了P+B+T设计。这一观察突出了频率编码的固有优势，其尖峰比爆发编码包含更多信息。因此，它可以用较少的尖峰计数保留更多信息。
# V. 结论

在本文中，我们提出了一个混合神经编码和学习框架，以解决SNNs在模式识别任务中的应用。特别是，我们展示了通过全面设计SNN以整合混合神经编码方案，我们可以利用不同神经编码方案的优势，根据任务需求和环境条件实现最佳性能。为了克服训练混合编码SNNs所面临的挑战，我们提出了一种逐层学习方法，该方法在产生所需的神经表示方面既高效又有效，与现有的SNN学习方法相比具有显著优势。我们广泛的实验表明，与其他使用同质神经编码方案构建的SNNs相比，我们可以实现最先进的图像分类准确性和声音定位精度，同时显著提高推理速度、能效和噪声鲁棒性。

虽然我们的研究主要考察了图像分类和声音定位任务，但我们强调本文提出的设计原则和训练方法可以扩展到其他模式识别任务和不同的环境条件。值得注意的是，成功实施我们的混合编码方法需要全面了解各种神经编码方案的优势和局限性以及特定任务的需求。在未来的研究中，我们的目标是开发一种神经编码搜索方法，该方法可以根据任务需求和环境条件自动确定每个单独脉冲神经元的最优混合神经编码设计，从而减少所需的专业知识水平。

# 声明

本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
