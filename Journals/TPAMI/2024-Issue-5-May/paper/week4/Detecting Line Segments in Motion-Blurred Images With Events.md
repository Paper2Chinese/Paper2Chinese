# 题目：[Detecting Line Segments in Motion-Blurred Images With Events](https://ieeexplore.ieee.org/document/10323537)  
## 用事件检测运动模糊图像中的线段
**作者：Huai Yu; Hao Li; Wen Yang; Lei Yu; Gui-Song Xia** 

**源码链接：** https://levenberg.github.io/FE-LSD
****

# 摘要

在运动模糊下提高线段检测器的可靠性是实际应用中最重要的挑战之一，例如在视觉SLAM和3D线映射等应用中。现有的线段检测方法在运动模糊发生时，面临着在准确检测和定位线段方面的严重性能下降。尽管如此，事件数据对于图像来说显示出强大的互补特性，具有最小模糊和高时间分辨率下的边缘感知能力，这可能有利于可靠的线段识别。为了在运动模糊中稳健地检测线段，我们提出了利用图像和事件的互补信息。具体来说，我们首先设计了一个通用的帧-事件特征融合网络，用于提取和融合详细的图像纹理和低延迟事件边缘，该网络包括一个基于通道注意力的浅层融合模块和一个基于自注意力的双沙漏模块。然后，我们利用最先进的线框解析网络在融合的特征图上检测线段。此外，由于缺乏成对运动模糊图像和事件的线段检测数据集，我们贡献了两个数据集，即合成的FE-Wireframe和现实的FE-Blurframe，用于网络训练和评估。对组件配置的广泛分析证明了我们融合网络的设计有效性。与最先进的方法相比，我们的方法在保持可比的实时性能的同时，实现了最高的检测精度。除了对运动模糊的鲁棒性外，我们的方法在高动态范围场景下的线检测也表现出色。

# 关键词

- 帧-事件融合 (Frame-event fusion)
- 线段检测 (Line segment detection)
- 运动模糊 (Motion blur)

# I. 引言
线段在图像中编码了丰富的几何信息和高级场景布局，它是图像结构感知和3D几何估计的基本原语。然而，随着运动模糊的出现，线段检测常常因为运动模糊和纹理擦除而遭受严重的性能下降。作为图像中最常见的伪影之一，运动模糊通常发生在低照明条件和高速运动下。与具有清晰锐利边缘的图像中的相比，运动模糊图像中的几何结构常常变得模糊，这对准确检测和定位线段构成了巨大挑战，见图1(a)的一个实例。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/6b73d5551ef24584ad67388091f3ab12.png#pic_ center" width="70%" />
</div>

这将直接影响到线特征的可重复性，以在图像间建立对应关系，然后降低后续应用的性能，例如，3D线映射[2]、视觉SLAM[3]和自动驾驶[4], [5]。

尽管在过去的几十年中，线段检测在诸如[6], [8], [9], [10]等文献中取得了有希望的进展，但它们很少考虑高动态范围和多样化运动的场景，因此在处理运动模糊图像时常常失去其有效性。如图1所示，由于模糊中不同时间的场景信息重叠，线段不再呈现为独特的伸长边缘，而是作为与背景混合的模糊带。为了解决这个问题，一个直观的解决方案是先去模糊图像，然后检测线段[11]。然而，检测性能高度依赖于运动去模糊的质量，由于运动模糊的不确定性，这本身就是一个病态问题。此外，运动去模糊方法通常是为了提高图像质量而开发的，而不是为了更好的结构感知[1], [12]。另一方面，一些试验直接在运动模糊图像中检测线条[7], [13], [14]，它们只能确定线段的分布或模糊带。然而，它既不能模拟多样化的模糊线（例如，围绕线上的点旋转），也不能几何上定位线段的位置。即使使用基于学习模型[8], [15]，用线注释进行训练仍然无法模拟模糊分布并确定线位置。因此，仅基于模糊图像准确检测和定位线段是具有挑战性的，主要是由于保留的信息有限。

最近，新开发的事件相机受到了越来越多的关注[16], [17]，它输出像素级亮度变化的事件，而不是标准的强度帧。通常，事件数据以极高的时间分辨率（高达微秒）在强度边缘异步生成，因此它对边缘感知能力强，并且对运动模糊具有鲁棒性。受这些特性的启发，我们提出将事件数据引入到运动模糊图像中的线段检测任务中。一方面，图像帧可以维持纹理和结构，这也有助于抑制事件噪声[18]。另一方面，事件数据可以在模糊图像中识别出独特的边缘，并解决多样化的相机运动问题。因此，事件相机显示出对RGB相机的强互补特性，在高时间分辨率下展现出最小模糊和高度边缘感知能力。因此，在数据驱动的训练过程中利用事件数据，对于增强线检测和定位的鲁棒性，特别是对抗运动模糊具有巨大潜力。然而，有效地融合两个领域的数据以检测线段，面临着几个挑战性问题，值得深入研究。第一个挑战是避免事件噪声对线端点预测的影响。此外，确保融合的特征图在具有多样化相机运动和高动态范围场景的条件下，能准确捕获线边缘也是至关重要的。最后，还必须解决缺乏结合视觉和事件数据的线段检测数据集的问题。

在本文中，我们提出了一种在运动模糊图像中使用事件的鲁棒线段检测方法，即帧-事件融合线段检测（FE-LSD）。作为前端，设计了一个新颖的特征融合主干，用于提取和融合图像和事件的信息，它由一个基于通道注意力的浅层模块和一个基于自注意力的堆叠双沙漏模块组成。浅层融合模块旨在抑制事件噪声并增强图像边缘特征。堆叠的双沙漏模块是为了进行多尺度融合并获取融合的特征图而开发的。作为后端，使用最先进的线段检测器，例如HAWP [9]和ULSD [10]，在融合的特征图上检测线段，分别称为FE-HAWP和FE-ULSD。图1(i)和(l)中不同方法的性能概览显示，提出的FE-HAWP和FE-ULSD表现最佳。设计在图像和事件上的融合网络大大提高了线检测的准确性，尤其是在遇到运动模糊和高动态范围场景时，这将极大地促进诸如视觉SLAM等实际应用的鲁棒性。据我们所知，这是第一项利用事件信息在运动模糊图像中进行鲁棒线段检测的工作。我们的贡献可以总结如下：

- 引入事件以协助运动模糊图像中的线段检测，可以鲁棒地解决由运动模糊引起的性能下降问题。融合图像和事件的思想充分利用了低延迟事件边缘和详细图像纹理的互补属性，从而有效提高了线检测的准确性和鲁棒性。
- 设计了一个通用的帧-事件特征融合网络来提取和融合图像和事件的信息。浅层融合和多尺度解码器融合的组合充分利用了通道注意力和自注意力机制，从而增强了事件和帧的特征提取。
- 构建了两个帧-事件线段检测数据集，即合成的FE-Wireframe和现实世界的FE-Blurframe，用于线段检测。广泛的定性和定量结果证明了我们网络设计的效力和所提方法在遇到运动模糊和高动态范围场景时的优越性。

# III. 方法

## A. 问题陈述

我们首先介绍Debled-Rennesson提出的模糊线段的概念[31]。离散直线定义为：

$$
l = \{(x, y) | c \leq ax - by < c + v\}, \quad (1)
$$

其中 $(x, y) \in Z^2$ 是像素坐标， $\{a, b, c, v\} \in Z^4$ 是四个参数以确定线段， $v$ 描述线宽。另外定义了一个厚度参数 $\mu$ 作为线 $ax - by = c$ 和 $ax - by = c + v$ 之间水平和垂直距离的最小值，即 $\mu = \frac{v}{\max(|a|, |b|)}$ 。

在实践中，运动模糊图像中线段的模糊分布通常是复杂的，如图2所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/0d4329e84dbc42b8a723f5ad40efe5f8.png#pic_ center" width="70%" />
</div>

一个简单的厚度参数不能精确地模拟线段的分布，例如旋转线。在本文中，图像中的线段定义为时间函数 $l(t)$ ， $ts \leq t \leq ts + T$ ，在时间 $t$ 捕获的清晰图像上检测到的线段。 $ts$ 可以是曝光开始时间， $T$ 是曝光持续时间。运动模糊图像的成像过程可以被视为在曝光持续时间 $T$ 期间所有清晰图像 $I(t)$ 的平均，即 $\tilde{I} = \frac{1}{T} \int_ {ts}^{ts+T} I(t)dt$ 。由于时间分辨率在时间平均上丢失了，我们引入了高时间分辨率的事件 $E = \{(x_ i, y_ i, p_ i, t_ i)\}_ {ti \in [ts, ts+T]}$ 到这个任务中。给定运动模糊图像 $\tilde{I}$ 和时间对齐的事件 $E$ 在 $T$ 期间，使用帧和事件数据的线段检测可以定义为：

$$
L(t) = FE-LSD(\tilde{I}, E), \quad (2)
$$

其中 $L(t)$ 表示线段集合， $FE-LSD$ 表示检测函数，我们主要关注曝光结束时间 $t = ts + T$ 时的检测结果。

## B. 事件表示

与以一定频率流式传输图像的RGB相机不同，事件相机不输出同步帧，而是异步输出事件点。对于每个像素 $u = [x, y]^T$ ，如果在时间 $t$ 在对数域中的捕获亮度 $L$ 变化超过对比度阈值 $C$ ，则触发一个事件点 $e = (x, y, t, p)$ 。

$$
\Delta L = p (\log L(x, y, t) - \log L(x, y, t - \Delta t)) \geq C, \quad (3)
$$

其中 $\Delta t$ 是在相同像素上生成的两个时间相邻事件之间的时间间隔。亮度的增加和减少将分别导致正（$p = +1$）和负（$p = -1$）极性。

事件流具有异步和稀疏特性。为了遵循CNN架构，通常将异步事件流转换为固定大小的张量。最近，最常用的事件表示包括事件计数[38]、活动事件表面[39]、体素网格[40]和事件尖峰张量（EST）[41]。在这些表示中，EST是一个四维网格 $H \times W \times B \times 2$ ，其中时间维度均匀地划分为 $B$ 个箱子。每个箱子进一步编码极性作为正和负维度。因此，我们选择EST作为事件表示，因为它保留了最多的时间和极化信息。EST计算如下：

$$
EST^±(x, y, \tau) = \sum_ {e_ i \in E^±} \delta(x - x_ i, y - y_ i) \max\{0, 1 - |\tau - t_ i^\*| \}, \quad (4)
$$

其中 $\tau \in \{0, 1, ..., B - 1\}$ ， $t_ i^\* \equiv \frac{B}{T}(t_ i - t_ 0)$ 。 $t_ 0$ 是事件流在时间 $T$ 期间的最早时间戳， $e_ i \in E^±$ 表示分别计算正和负EST的事件的极性。 $\delta(x, y)$ 是二维单位脉冲函数。当 $x = y = 0$ 时， $\delta(x, y)$ 等于1，否则 $\delta(x, y) = 0$ 。这个方程等价于双线性采样操作。图3显示了原始事件的事件可视化，EST表示，以及原始事件叠加在相应模糊图像上的视图。两个对应于EST的正负极性的时空格格进一步堆叠成一个 $H \times W \times 2B$ 张量，以适应CNN的常见要求。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/9ab66822a0904441a628a5afddca4e9e.png#pic_ center" width="70%" />
</div>


## C. 网络结构

给定运动模糊图像和对齐的EST数据，我们需要设计一个有效的融合策略来提取线段检测的互补信息。最近的先进线段检测方法见证了沙漏网络在提取特征图方面的有效性[25], [26]，因此我们考虑在两个分支输入的特征级别上进行图像和事件的融合，采用多尺度编码器-解码器结构。然而，如果两个输入特征直接来自原始图像和事件，两种模态之间的交互将不足，事件噪声将对后续线段检测产生负面影响。因此，我们构造性地融合了图像和事件的浅层和深层特征，然后使用两个最先进的线段检测器，即HAWP[9]和ULSD[10]来获得最终的检测结果（见图4）。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/3fed44c6964f49f48862f4610747037b.png#pic_ center" width="70%" />
</div>

特征融合主干网络包括两种模块：(i) 浅层模块，旨在提取浅层特征并抑制事件噪声；(ii) 双沙漏模块，采用编码器-解码器结构进行多尺度特征融合以生成特征图。

1)浅层模块：对于 $H \times W \times 3$ 的RGB图像和空间对齐的 $H \times W \times 2B$ EST数据，浅层模块首先分别使用浅层1（包括7×7卷积，步长为2，批量归一化和ReLU）对RGB和EST进行下采样，可以获得具有相同通道数的初步RGB和EST特征。然后，图像和事件特征通过浅层融合块（SFB）进行融合，并且融合的特征分别与原始RGB和EST特征相加。接下来，使用浅层2（三个残差块[42]和第一个残差块后的最大池化模块）进行下采样和特征提取。精炼的特征输入到第二个SFB模块中。最后，融合的特征与浅层2的输出相加以获得相同维度的图像特征 $X^{(0)}_ F$ 和事件特征 $X^{(0)}_ E$ ，然后将它们输入到后续的双沙漏模块中。

SFB是浅层模块的核心部分，其网络结构如图5所示。对于输入图像特征 $X^F$ 和 EST特征 $X^E$ ，SFB首先通过通道连接它们并使用1×1卷积保持通道数。然后，分别使用通道注意力（CA）块[43]计算注意力 $Attn^F$ 和 $Attn^E$ ，这些块是从SENet[44]修改而来的。注意力进一步与原始特征相乘，然后与另一种模态的特征相加，通过注意力加权特征融合。最后，融合的特征使用残差块进行精炼，以获得浅层图像特征 $X^o_ F$ 和事件特征 $X^o_ E$ 。SFB的整个过程可以描述为：

$$
X = \text{Conv1×1} (\text{Concat}(X^F, X^E)) \\
Attn^F = \text{CAF}(X) \\
Attn^E = \text{CAE}(X) \\
X^o_ F = \text{ResF}(X^F + X^E \odot Attn^E) \\
X^o_ E = \text{ResE}(X^E + X^F \odot Attn^F),
$$

其中Conv1×1表示1×1卷积，Concat表示按通道连接，CA表示通道注意力模块，Res表示残差模块， $\odot$ 表示逐元素乘法。

2)双沙漏模块：如HAWP[9]和ULSD[10]中所述，使用编码器-解码器网络，即堆叠的沙漏网络[45]，用于获得线段检测的特征图。通过两个分支的浅层特征，我们设计了堆叠的双沙漏模块来进一步融合和提取特征，如图4所示。图像和事件特征首先通过编码器-解码器网络进行融合，然后通过残差块。然后，融合的特征分别与输入图像和事件特征相加，以恢复下一轮双沙漏模块的两个分支特征。对于最后一个双沙漏模块，残差块后的融合特征直接输出为后续线段检测器的最终特征图。堆叠的双沙漏模块的计算为：

$$
Y^{(i)} = \text{Res}(\text{E−D}(X^{(i)}_ F, X^{(i)}_ E)) \\
X^{(i+1)}_ F = X^{(i)}_ F + Y^{(i)} \\
X^{(i+1)}_ E = X^{(i)}_ E + Y^{(i)},
$$

其中E−D表示编码器-解码器网络， $X^{(i)}_ F$ 和 $X^{(i)}_ E$ 分别表示第 $i$ 个双沙漏模块的输出图像和事件特征（$X^{(0)}_ F$ 和 $X^{(0)}_ E$ 是浅层模块的输出）。 $Y^{(i)}$ 表示第 $i$ 个双沙漏模块输出的融合特征。

双沙漏模块的核心是编码器-解码器网络，如图6所示，它由成对的特征编码器、解码器融合块（DFB）和解码器组成。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/38b8ca10c7e94de8a03240071a40c582.png#pic_ center" width="70%" />
</div>

编码器和解码器由残差块实现。在特征编码期间，使用步长为2的最大池化层对特征图进行下采样。在解码期间，使用步长为2对其进行上采样，以确保在同一级别的编码器、解码器和DFB具有相同的特征大小。DFB（见图7）由1×1卷积和变压器模块组成，使用2个层归一化（LN）模块、一个轻量级多头自注意力（MHSA）模块和一个逆残差前馈网络（IRFFN）[46]。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5e63f591dc28456e87730cd0231d6616.png#pic_ center" width="70%" />
</div>

DFB模块首先通过通道连接和1×1卷积将输入的图像-事件特征融合为一个特征，然后使用变压器进一步融合和提取深度特征。变压器主要用于两个原因：(i) 与CNN相比，变压器具有更强的捕获全局特征的能力，这有利于长线段目标的检测；(ii) 对于图像和事件特征的融合，变压器可以提供自注意力以及交叉注意力，以实现全局跨模态特征交互和信息融合。

轻量级MHSA模块的结构如图7右下角所示。与原始的MHSA[47]相比，这个轻量级版本增加了一个 $k \times k$ 卷积（步长为 $k$）以减少 $K$ 和 $V$ 的空间大小，从而减少计算复杂性和内存消耗。此外，使用可学习的相对位置编码器提供像素之间的相对位置信息。对于输入特征 $X \in \mathbb{R}^{h \times w \times c}$ ，轻量级MHSA模块计算输出特征 $Y \in \mathbb{R}^{h \times w \times c}$ 如下：

$$
X = \text{Conv}_ k×k(X) \\
Q = \text{Conv1×1}_ Q(X) \\
K = \text{Conv1×1}_ K(X') \\
V = \text{Conv1×1}_ V(X') \\
\text{Attn} = \text{Softmax}\left(\frac{Q \cdot (K + \text{RPE})^T}{\sqrt{d_ h}}\right) \\
Y = \text{Attn} \cdot V,
$$

其中RPE $\in \mathbb{R}^{h \times w \times c}$ 是相对位置编码器， $d_ h$ 是每个头的维度。

一旦特征通过轻量级MHSA模块，它们随后被输入到IRFFN[46]中。它由1×1卷积和3×3深度卷积（DW）组成，其中3×3深度卷积可以在降低计算成本的同时提取局部特征。前两个卷积的输出通过高斯误差线性单元（GELU）和批量归一化激活。整个IRFFN计算过程可以表示为：

$$
X' = \text{Conv1×1}(X) \\
Y = \text{Conv1×1}(\text{DWConv}(X') + X').
$$

3)线段检测器：一旦获得融合的特征图，就使用尖端线段检测器执行线段检测。检测过程分为两个阶段，即线段提案网络（LPN）和线段分类网络。LPN阶段包括连接点提案模块和线段提案模块，分别产生连接点和线段提案。随后，基于它们的连接关系匹配线段和连接点提案，以生成最终的线段候选项。每个线段候选与融合特征图中的几何匹配关联有一个特征向量。然后，使用线段分类网络通过真实二进制监督对线段进行分类。最后，选择置信度分数超过设定阈值的候选作为最终检测结果。

通过将特征融合主干与检测器网络结合，可以使用同步视觉图像和EST数据在运动模糊图像中实现线段检测。特征融合网络可以通过简单地替换它们的特征提取主干，轻松地应用于现有的线段检测器。为了验证特征融合网络的通用性，我们将其应用于当前最先进的线段检测器HAWP[9]和ULSD[10]，分别命名为FE-HAWP和FE-ULSD。

# IV. 实验与分析

## A. 数据集

LSD（Line Segment Detection）数据集，如Wireframe [25]和YorkUrban [24]，在LSD方法中起着至关重要的作用。然而，目前还没有公开可用的LSD数据集能够提供几何和时间上对齐的RGB图像和事件。此外，在运动模糊的RGB图像或EST（Event Spike Tensor）帧上从头开始创建精确的线段注释也是一项非常繁琐的工作。基于这些要求，我们首先在现有的Wireframe数据集[25]的基础上构建了一个更大规模的合成数据集，即FE-Wireframe。然后，考虑到合成数据和真实数据之间可能存在较大差距，我们通过收集真实数据并手动标记线段，贡献了一个真实数据集，即FE-Blurframe。

FE-Wireframe: 合成数据生成的目标是避免在运动模糊上进行繁琐的线段注释。有了标记过的Wireframe数据集[25]，我们使用ESIM [48]生成合成数据，构建管道如图8所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/be0b591f2e2846f1ae789964c74c6e71.png#pic_ center" width="70%" />
</div>

首先，原始RGB帧Iraw被重新投影到3D空间的单位坐标系中，然后投影到图像空间以获得帧I0，使用初始相机姿态和相机内在参数。通过在短时间窗口T内模拟的相机轨迹，可以在任何插值时间tk生成帧Ik。接下来，使用在时间tk-1和tk的两个相邻帧Ik-1和Ik，我们可以获得强度变化，并使用公式(3)生成事件Ek。时间窗口T=30毫秒，并且对于每个图像序列，事件对比度阈值C是从均匀分布U(0.05, 0.5)中随机采样的。然后，我们可以获取事件数据E = ∑_ {k=0}^{N-1} Ek和模拟帧I = {Ik}_ N^k，其中N+1个图像。模拟帧N+1的数量是基于亮度变化和像素位移自适应采样的，这比ESIM [48]中的常数值更鲁棒。需要注意的是，相机运动轨迹的设计确保了最后一张图像IN正好是原始图像Iraw，以重用现有的线段注释。然后通过平均模拟的N+1张图像获得运动模糊图像IB。最后，我们获得了合成事件数据E、同步运动模糊图像IB和线段注释。FE-Wireframe数据集包含5000对帧-事件训练样本和462对测试样本。一些数据样本和线注释如图9所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/6c8df898de824303ad0d25d62eb7db88.png#pic_ center" width="70%" />
</div>

FE-Blurframe: 对于具有帧-事件线段检测的运动模糊（FEBlurframe）的真实数据集的生成，我们构建了一个双相机系统进行真实世界数据收集[49]，包括一个DAVIS 346事件相机和一个FLIR RGB相机。双相机使用相同的镜头和一个分光器，在两个相机之间进行粗略的几何校准，然后通过最大化静止的FLIR图像和DAVIS APS图像之间的结构相似性获得精确匹配。两个相机由外部信号触发，我们通过最大化FLIR图像和事件计数图像之间的结构相似性获得时间偏移。在武汉大学校园收集了52个序列，包括典型的室内和室外场景，如图书馆、餐厅、体育馆、办公楼和教室。每个序列包括来自事件相机的事件流和APS图像，以及来自FLIR相机的同步RGB图像。事件相机和FLIR相机的分辨率分别为346×260和640×512。为了确保能够捕获用于线段注释的清晰图像，FLIR RGB相机的帧率设置为200 Hz。我们从52个序列中裁剪了800个片段，每个片段包含30毫秒内的事件和同步的7张RGB图像。然后，使用Super SloMo [50]将RGB图像从7插值到40帧，以自然生成运动模糊图像。7帧平均会在模糊区域产生伪影（例如，脊柱），而插值的40帧则更连续，以产生平滑和自然的运动模糊图像。对于注释，我们在30毫秒间隔的最新到达图像上标记线段。此外，事件与该图像叠加以进行注释验证。最后，真实数据集包含800个样本，包括清晰图像、合成模糊图像、事件流和线段注释。数据集随机分为训练集600个样本和测试集200个样本。一些数据样本和线注释如图10所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/8e6dbfdb5c2b4f0ab6b8c2fdea1a990b.png#pic_ center" width="70%" />
</div>

## B. 实验设置和评估指标

实验设置：在实验中，EST的时间维度B设置为5。图像和EST的大小直接调整为512×512，然后输入到特征融合主干。在这个主干中，DHM（Dual Hourglass Module）的数量设置为2，每个DHM中的编码器数量设置为5。在特征融合主干之后，我们获得了一个大小为128×128×256的融合特征图。FE-HAWP的参数和训练配置也设置为与原始HAWP相同。网络使用Adam优化器[51]进行训练。网络训练的学习率、权重衰减和训练批量大小分别设置为 4×10^-4、1×10^-4 和4。在线段提案网络（LPN）模块中，连接点提案和线段提案的数量分别设置为K_ junc = 300、K_ line = 5000。为了训练线段分类器，从LPN中选择的正样本和负样本的数量分别设置为N_ pos = 300、N_ neg = 300。此外，我们还从地面真实注释中添加了N\*_ pos = 300个正样本到训练数据集中。同时，为了获得每个线段的特征向量，从线上均匀采样了32个点，特征向量的维度设置为1024。同时，训练使用步长衰减学习策略，网络训练了30个周期。学习率在25个周期后减少了0.1倍。由于双沙漏模块中有两个并行的编码器，我们使用组卷积来提高效率，通过不共享权重地对两个编码器进行分组。本文中使用的数据增强包括水平和垂直翻转以及180°旋转。模型训练和测试在单个NVIDIA RTX 3090Ti GPU上进行。

评估指标：我们使用了在检测线段任务中经常使用的评估指标，包括APH（Average Precision of Hard Examples）、FH（Frequency of Hard Examples）、平均结构平均精度（msAP）、sAP5、sAP10、sAP15、连接点平均精度（mAPJ）和每秒帧数（FPS）。

APH和FH是使用精确度和召回率计算的，遵循传统的LSD[6]和L-CNN[25]。sAP是在L-CNN[15]中提出的，以反映几何结构。预测线段和真实线段（GT）之间的距离决定了预测线段是否为真正例。sAP5、sAP10和sAP15是当距离小于5、10和15像素时的sAP值，分别为。而msAP是sAP5、sAP10和sAP15的平均值。

mAPJ用于衡量连接点预测的精确度，计算方式与线段的sAP类似。真正的连接点是通过计算预测和GT连接点之间的欧几里得距离来确定的。mAPJ是在将距离阈值设置为0.5、1和2像素时的平均精度。

## C. 配置分析

在本节中，我们首先在合成的FE-Wireframe数据集上进行实验，以分析FE-LSD的三个主要配置，即输入数据融合、事件表示和融合策略。然后，在FE-Wireframe数据集上训练的模型在真实数据集上进行微调，以显示迁移学习结果。

1)输入数据融合：为了评估输入数据对网络性能的影响，我们使用三种不同的输入集训练原始的HAWP和ULSD模型：仅模糊图像、仅EST和两者的连接。值得注意的是，基于模糊图像的结果是使用模糊图像重新训练的。结果如表I所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/3c7e96f06b6f4e2981af50792f11030d.png#pic_ center" width="70%" />
</div>

对于单模态输入，仅使用图像帧可以获得更高的精度。这是因为事件数据丢失了许多纹理信息，事件噪声妨碍了连接点预测。最重要的是，当使用事件增强基于图像的线段检测时，使用简单的连接可以提高线检测性能。HAWP在帧-事件连接上的msAP比使用图像和事件训练的模型高出3.2和20.5点。ULSD模型显示出一致的改进，msAP分别高出6.1和21.9点。这些结果证明了边缘感知事件在检测线段方面的好处。即使使用基本的连接，也可以提高检测精度。

2)事件表示：不同事件表示方法在事件数据处理中保留的信息量不同，这直接影响FE-LSD的性能。为了研究影响，我们测试了四种不同的事件表示，即事件尖峰张量（EST）[41]、体素网格[40]、事件计数+活动事件表面（EC+SAE）[38], [39]、无极性的事件计数+活动事件表面（EC+SAE\*）。结果如表II所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/10e3add9a3534c619dc43ad88cf35830.png#pic_ center" width="70%" />
</div>

在四种表示中，当向体素网格和EC+SAE\*添加极性信息时，即EST和EC+SAE，所有指标的综合性能都有所提高。此外，与EC+SAE和EC+SAE\*相比，EST和体素网格保留了时间信息，因此获得了更高的精度，这表明了时间信息的重要性。最重要的是，基于EST的最高精度是基于EST的，它编码了极性信息并保留了时间信息。因此，EST被选为FE-LSD的最终事件表示。

3)融合模块分析：对于图像和事件特征的融合，我们首先测试了所提出的SFB（Shallow Fusion Block）和DFB（Decoder Fusion Block）的效果，结果如表III所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/46ea45e163834ff3a858e687a9ba37ac.png#pic_ center" width="70%" />
</div>

当不使用SFB时，直接从网络中移除，当不使用DFB时，使用元素逐元素加法代替DFB。我们可以观察到，当不使用任何融合模块时，网络的精度最低。然后，当添加SFB时，msAP分别提高了2.1和1.0点，当仅使用DFB时，分别提高了4.6和4.4点，对于FE-HAWP和FE-ULSD。当在具有DFB的模型中添加SFB时，msAP分别提高了0.3和0.9点，对于FE-HAWP和FE-ULSD。由于不同的检测器具有不同的容量，将SFB添加到更高的基线并不总是以相似的幅度提高性能。DFB带来的增益大于SFB，表明了多尺度编码器-解码器融合深度特征的重要性。SFB和DFB的使用获得了最准确的结果，FE-HAWP和FE-ULSD分别达到了53.2%和55.2%的msAP。这些结果验证了所提出的SFB和DFB模块的有效性。

同时，我们通过可视化特征图来进一步定性分析两个融合块的有效性，使用类激活图（CAM）[7]，如图11所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/bce82491367b4b46b3ee91f48633be9f.png#pic_ center" width="70%" />
</div>

第一行显示了未使用SFB和DFB训练的FE-HAWP的CAMs，而第二行显示了使用两个模块的FE-HAWP的相应样本。CAM反映了网络对图像不同部分的注意力分布。CAM中的红色表示对这些部分的更大注意力。通过添加SFB和DFB，网络更加关注边缘，并且对线段端点有更强的响应。这些可视化结果证明了SFB和DFB模块在改善网络识别和定位线段能力方面的重要性。

其次，我们进一步进行实验，讨论设计的两个模块，即浅层模块（SM）和双沙漏模块（DHM）的有效性。在测试另一个模块时，直接移除一个模块。结果如表IV所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/6da4e965a0864a9cac6c6470812716dd.png#pic_ center" width="70%" />
</div>

总的来说，DHM在检测线段方面比SM起着更关键的作用。当与DHM结合使用时，SM可以略微提高检测性能。然后，为了证明浅层模块在抑制事件噪声方面的有效性，我们在图12中展示了几个事件图像、浅层模块前后对应的特征图的实例。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/9b5f3dbeed7a4069bb8090a8e300cdd8.png#pic_ center" width="70%" />
</div>

对于这些来自FE-Blurframe数据集的真实事件，带有“盐噪声”，我们可以清楚地观察到在均匀区域和边缘周围的“盐噪声”。在浅层模块之后，背景区域的特征强度比之前更加均匀。虽然边缘周围特征强度仍然保持明显的特征强度。 

基于网络架构，我们进一步讨论了DHM的数量和DHM中特征编码器的数量，如表V所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c0666aadbef44ca5926f8d3972cfd76c.png#pic_ center" width="70%" />
</div>

在FE-HAWP框架内讨论，不失一般性。为了效率评估，我们计算了提取主干特征图的平均时间成本（时间）以及FPS和参数数量（参数）。当使用相同的DHM时，更多的编码器会得到更好的结果。但是，由于编码器网络中的下采样，最大编码器数量为5。当使用相同数量的编码器时，更多的DHM会得到更好的精度，但推理速度较低。然而，24 GB GPU RAM无法覆盖3个DHM的内存需求。因此，我们将DHM的数量设置为2，编码器的数量为5。

4)在真实数据集上的迁移学习：在我们的实验中，基于Wireframe数据集生成的合成数据减轻了在真实图像和事件上进行繁琐数据注释的负担。然而，训练在合成数据上的模型的泛化能力尚未在真实数据集上进行测试。此外，合成的运动模糊图像与真实世界不同，因为缺少3D信息。因此，我们构建了一个真实的数据集FE-Blurframe，具有现实图像和事件，以讨论从模拟到现实的差距。为了验证迁移学习的有效性，评估了三个模型，即仅在合成数据上训练（S）、仅在真实数据上训练（R）和在真实数据上微调预训练模型（F），它们在同一个真实数据集上进行评估。结果如表VI所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c9721b2837764dafab12a884b3ed2524.png#pic_ center" width="70%" />
</div>

可以观察到，仅在合成数据上训练的模型在真实世界的测试集上分别获得了30.7%和34.4%的msAP，对于FE-HAWP和FE-ULSD。这种性能下降与HAWP [9]在仅在Wireframe上训练并在YorkUrban数据集上测试时相似。原因主要有两个：(i) 合成数据和真实数据之间的显著差异；(ii) 合成事件数据是基于理想的事件生成模型获得的，而真实事件数据的质量受到事件相机的镜头、噪声、对比度阈值和其他因素的影响。然后，合成预训练模型的性能在真实数据集上进行微调后得到了大幅度的提高，并且与仅在真实数据上训练的模型相比也有显著的改进。融合训练的msAP最终提高到63.3%和62.9%，对于FE-HAWP和FE-ULSD，分别。此外，我们在图13中比较了使用HAWP和FE-HAWP在真实运动模糊图像和事件上的线检测结果。FE-HAWP在多样化的运动模糊图像上获得了一致更好的结果，验证了所提出方法的泛化能力。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c5b3c9d5d54f4001a82916a1617ae983.png#pic_ center" width="70%" />
</div>

此外，我们在图14中绘制了损失和msAP的曲线。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/7112a2507ef34f3887a8b24872e54f8c.png#pic_ center" width="70%" />
</div>

红色曲线是使用预训练模型训练的，绿色曲线是使用随机初始化从头开始训练的。微调预训练模型可以加快收敛速度并提高最终性能。这些结果表明合成数据集和真实数据集之间存在显著差异，这严重影响了模型从模拟到真实世界的泛化能力。然而，大规模合成数据集有助于模型预训练，从而释放数据注释的劳动，并提高在真实数据集上的收敛速度和精度。

## D. 与最先进技术的比较

为了评估所提出的FE-LSD的性能，我们在合成的FE-Wireframe和真实的FE-Blurframe数据集上进行了广泛的比较。竞争对手包括传统的LSD [6]、FBSD [7]（为模糊图像设计）、基于学习的L-CNN [15]、HAWP [9]、LETR [8]。这些基于学习的方法直接使用官方训练的模型在运动模糊图像上进行评估。由于没有公开可用的仅使用事件的检测方法的源代码，我们实现了LSD和HAWP在事件时间表面上，以及使用e2vid方法[52]重建的图像上的HAWP，进行比较。对于FE-Wireframe，我们还额外使用了官方的HAWP和ULSD模型在去模糊图像上进行评估，即HAWP†和ULSD†。最后，由于所提出的FE-LSD接受图像和EST的输入，这些方法在连接图像和EST上进行了重新训练，以进行公平的比较（即L-CNN‡、HAWP‡、ULSD‡和LETR‡）。所有这些方法都在配备有Intel i9 12900 K CPU和单个NVIDIA RTX 3090Ti GPU的服务器上进行了测试。

1)在FE-Wireframe数据集上的结果：图15显示了在FE-Wireframe数据集上的定性比较。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/edd7199f43c8499ba3f314f10c76195b.png#pic_ center" width="70%" />
</div>

第一行是输入的运动模糊图像，第二行是相应的事件输入。为了更好的可视化，检测到的线条和手动标记的线条绘制在曝光结束时刻的清晰RGB图像上。由于LSD和FBSD是基于梯度的方法，它们可以在运动模糊图像中检测到大量的线段。然而，大多数线段是误检测或分段的线段，导致定量指标较低。另一方面，基于学习的HAWP和LETR在学习模型上对模糊图像的检测率较低。这是因为官方训练的模型是由清晰图像驱动的，无法处理运动模糊问题。然而，当我们使用模糊图像和事件的连接重新训练它们时，正确检测显著增加。最后，所提出的FE-HAWP和FE-ULSD表现最佳，具有最高的检测率和最低的误报率。

表VII总结了在合成FE-Wireframe数据集上的定量比较，而图16显示了sAP10和APH的PR曲线。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/f14def4d7f734881811a1cc5bdf1be5a.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/1a86a280e1a44fa2bcd46d473070fa4e.png#pic_ center" width="70%" />
</div>

当仅给出运动模糊图像时，传统的LSD、FBSD和基于学习的L-CNN、HAWP、ULSD、HAWP的准确性较低。ULSD获得的最高msAP达到5.2%，FBSD获得最高的APH为24.9%。如果我们使用官方的RED-Net模型[53]进行去模糊，并使用官方的HAWP和ULSD模型进行线段检测，准确性要高得多，但仍然比直接在运动模糊图像上重新训练的结果差。原因是去模糊模型缺乏泛化能力。然后，如果我们使用清晰的Wireframe训练集重新训练去模糊模型，并使用官方的HAWP和ULSD模型进行检测，结果要好得多。然而，它们仍然无法与所提出的FE-HAWP和FE-ULSD的结果相比。此外，重新训练去模糊模型的技巧对于每个新数据集来说并不实用。在事件时间表面上和重建图像上使用HAWP的效果比在模糊图像上的官方模型更好，这表明事件可以在快速运动时帮助检测线段。然后，当同时使用图像和EST输入时，重新训练的模型的性能比仅使用图像输入的性能要好得多。重新训练的ULSD‡获得的最高msAP达到了51.7%。这些改进表明，事件数据可以增强运动模糊图像的边缘感知能力。最后，我们提出了使用我们的帧-事件融合模块获得的最高性能。FE-HAWP和FE-ULSD的msAP分别比重新训练的ULSD‡高出1.3和3.7点。除了APH，FE-ULSD在所有指标上都获得了最高的准确性，而APH略低于FE-HAWP。这是因为当置信度阈值设置为0.5时，FE-ULSD的召回率较低，如APH PR曲线所示。

关于检测速度，由于其特征融合主干比原始的堆叠沙漏网络多一个编码器分支，并引入了更多耗时的变压器进行特征融合，因此FE-ULSD和FE-HAWP都比原始方法慢。然而，与基于变压器的方法LETR [8]相比，所提出的方法大约快了三倍，这证明了所提出方法的有效性。

2)在FE-Blurframe数据集上的结果：为了进一步证明所提出方法在现实世界中的有效性，我们在FE-Blurframe数据集上展示了定性结果，如图17所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/9fa83a2591634ac7b85566733b44b9bc.png#pic_ center" width="70%" />
</div>

传统的LSD和FBSD在合成FE-Wireframe数据集上的性能与在真实FE-Blurframe数据集上的性能一致。官方训练的模型，HAWP和LETR，在模糊图像上的检测率较低，但比在合成FE-Wireframe数据集上的相同模型的准确性要高。这是因为合成数据和真实世界数据集之间的显著数据差异。然后，重新训练模型以使用图像和事件的连接大大提高了性能，并产生更多的检测线段。与FE-Wireframe上的结果类似，所提出的FE-HAWP和FE-ULSD检测到的线段最多，与地面真实标签的相似性最高，反映了所提出方法的有效性。

表VIII和图18给出了在FE-Blurframe数据集上的定量比较。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/d7c3c5d7c2c64c11a6301cf6c1f1000f.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/87e7871e26bf4004a5cea996bf81d538.png#pic_ center" width="70%" />
</div>

FE-HAWP和FE-ULSD仍然比其他基于学习的方法获得最高的准确性。FE-HAWP获得了52.0%的msAP，比重新训练的HAWP†高出9.4个百分点。FE-ULSD获得了51.8%的msAP，比重新训练的ULSD†高出5.1个百分点。如果我们使用迁移学习策略对预训练模型进行微调，即FE-HAWP‡和FE-ULSD‡，与FE-HAWP和FE-ULSD相比，性能分别提高了11.3和11.1个百分点。此外，由于在微调后获得的线段候选项较少，FE-HAWP‡和FE-ULSD‡的推理FPS高于FE-HAWP和FE-ULSD。

## E. 鲁棒性分析

对运动模糊的鲁棒性：通过融合图像和事件数据，我们有效地提高了运动模糊图像中线段检测的性能。然而，仍然很难确定融合在不同摄像机运动下的性能。因此，我们通过计算连接点的平均位移来分析运动模糊程度。位移分布和相应的线检测性能如图19所示，评估了FE-HAWP和HAWP。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/44dc2a3f127c4c27b730fc4d47457a0e.png#pic_ center" width="70%" />
</div>

每个子图的x轴通过计算图像中连接点的平均位移来测量模糊度。如果平均位移接近0像素，则意味着模糊度小。FE-Wireframe和FE-Blurframe的模糊度分布显示在图19的顶部。FE-Wireframe的平均模糊度约为28像素，FE-Blurframe约为18像素。HAWP的msAP分布表明，更大的模糊会导致线检测精度降低。然后，当使用所提出的FE-HAWP对图像和事件进行检测时，线检测精度更高，对不同模糊度的鲁棒性更强。

对高动态范围（HDR）的鲁棒性：事件相机的HDR特性也应该有助于鲁棒的线段检测。因此，我们进一步使用Wireframe生成合成HDR图像，并在合成的Wireframe数据集上扩展实验。对于暗和亮的清晰图像，FE-HAWP与HAWP相比有更多的真正例检测。定量比较在表IX的顶部给出，FE-HAWP的准确性远高于HAWP，无论是对于暗清晰图像还是亮清晰图像。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5e9740a437134a89a66596983bcd4910.png#pic_ center" width="70%" />
</div>

此外，为了全面测试事件相机的两个特性，即低延迟和HDR，我们进一步模拟了既有运动模糊又有曝光问题的图像，结果如图20和表IX的底部所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5ec5b58bd8e04d889a89b70e7b83ed00.png#pic_ center" width="70%" />
</div>

可以观察到，运动模糊会显著降低HAWP的准确性，大部分线段缺失。而对于FE-HAWP，我们的设计保持了高检测率，定性可视化效果要好得多。另一个观察是，FE-HAWP在暗图像中的性能优于亮图像，这意味着强照明下的图像编码量化导致了信息丢失。此外，尽管我们没有强调真实世界数据收集中的HDR问题，但FE-Blurframe数据集中自然涉及了许多HDR图像。表VIII中的结果证明了其在运动模糊和HDR问题上的有效性。

# V. 结论

在本文中，我们提出了一种使用事件来解决运动模糊图像中性能下降问题的线段检测方法。所提出的帧-事件特征融合主干充分利用了图像和事件之间的互补信息，通过浅层和多尺度解码器融合模块，可以很好地提取出结构边缘信息，无论摄像机运动是慢还是快。然后，我们采用了最先进的线段检测器HAWP和ULSD来进行端到端的线段检测。为了训练我们的模型并为社区做出贡献，我们构建了两个线段检测数据集，即FE-Wireframe和FE-Blurframe，它们包含了运动模糊图像和空间-时间对齐的事件数据。通过广泛的组件配置分析，验证了我们网络设计的合理性，与最先进技术的全面比较表明，所提出的FE-LSD在检测运动模糊图像中的线段方面是有效的。此外，所提出的方法在高动态范围场景中检测线段时也显示出鲁棒性。在未来，我们将进一步探索事件数据的异步特性，以同时检测线段和估计线运动。


# 声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
