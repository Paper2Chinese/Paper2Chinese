# 题目：[Knockoffs-SPR: Clean Sample Selection in Learning With Noisy Labels](https://ieeexplore.ieee.org/document/10337771)  
## Knockoff SPR：带噪声标签学习中的干净样本选择
**作者：Yikai Wang; Yanwei Fu; Xinwei Sun** 

**源码链接：** https://github.com/YikaiWang/Knockoffs-SPR
****

# 摘要

噪声训练集通常会导致神经网络的泛化和鲁棒性下降。在本文中，我们提出了一个新的理论保证的清洁样本选择框架，用于噪声标签的学习。具体来说，我们首先提出了一种可扩展的惩罚回归（SPR）方法，用于模拟网络特征和独热标签之间的线性关系。在SPR中，通过回归模型中解决的零均值偏移参数来识别清洁数据。我们理论上展示了在某些条件下SPR可以恢复清洁数据。在一般情况下，这些条件可能不再满足；一些噪声数据可能被错误地选为清洁数据。为了解决这个问题，我们提出了一种数据自适应方法，即带有Knockoff过滤器的可扩展惩罚回归（Knockoffs-SPR），它可以在选定的清洁数据中控制误选率（FSR）。为了提高效率，我们进一步提出了一种分割算法，将整个训练集划分为可以并行解决的小片段，使框架可扩展到大型数据集。虽然Knockoffs-SPR可以被视为标准监督训练流水线的样本选择模块，但我们进一步将其与半监督算法结合起来，利用噪声数据作为未标记数据的支持。在几个基准数据集和真实世界噪声数据集上的实验结果表明了我们框架的有效性，并验证了Knockoffs-SPR的理论结果。

# 关键词

- Knockoffs方法
- 噪声标签学习
- 第二类错误控制

# Ⅰ. 引言

深度学习在许多监督学习任务上取得了显著的成功，这些任务通常由数百万标记过的训练数据训练而成。深度模型的性能在很大程度上依赖于标签注释的质量，因为神经网络对噪声标签敏感，甚至可以轻易地记住随机标记的注释[1]。这样的噪声标签可以导致模型泛化和鲁棒性的退化。至关重要的是，在许多现实世界场景中，获取精确的标签既昂贵又困难，这使得监督深度模型学习噪声数据成为一个现实挑战。

之前有许多努力通过使模型对噪声数据具有鲁棒性来解决这一挑战，例如修改网络架构[2][3][4][5]或损失函数[6][7][8][9]。本文通过直接选择干净样本来解决这一挑战。受动态样本选择方法[9][10][11][12][13][14][15][16]的启发，我们构建了一个样本选择和网络训练之间的“良性”循环：选定的干净样本可以改善网络训练；另一方面，改进的网络有助于选择干净数据。随着这个循环的发展，性能可以得到提升。为了建立这一点，一个关键问题仍然存在：如何有效地区分干净数据和噪声数据？

预备知识。现有的工作中用于区分干净数据和噪声数据的典型原则包括大损失[11]、不一致的预测[17]和不规则的特征表示[18]。前两个原则识别标签空间中的不规则行为，而最后一个分析了特征空间中同一类别实例的表示。在本文中，我们提出将标签和特征空间统一起来，通过建立线性关系：

$$
y_ i = x_ i^T \beta + \epsilon,
$$

其中数据i的特征-标签对(xi ∈ Rp: 特征向量; yi ∈ Rc: 一位有效标签向量)。我们还有固定的(未知的)系数矩阵β ∈ Rp×c和随机噪声ε ∈ Rc。本质上，这里的线性关系是一个理想化的近似，因为网络被训练为最小化特征的(软最大)线性投影和一位有效标签向量之间的差异。对于一个训练良好的网络，干净数据的输出预测应该尽可能接近一位有效向量，而噪声数据的输出熵应该较大。因此，如果底层线性关系在没有软最大操作的情况下被很好地近似，相应的数据很可能是干净的。相反，噪声数据的特征-标签对可能不会被线性模型很好地近似。

最简单衡量线性模型拟合优度的方法是检查预测误差或残差， $r_ i = y_ i - x_ i^T \hat{\beta}$ ，其中 $\hat{\beta}$ 是β的估计。更大的 $\|r_ i\|$ 指示更大的误差，因此实例i更可能是噪声数据。已经提出了许多方法来测试 $r_ i$ 是否为非零。特别是，我们强调经典的统计留一法[19]，它计算标准化残差为：

$$
t_ i = \frac{y_ i - x_ i^T \hat{\beta}_ {-i}}{\hat{\sigma}_ {-i}} \cdot \sqrt{1 + x_ i^T (X_ {-i}^T X_ {-i})^{-1} x_ i},
$$

其中 $\hat{\sigma}$ 是尺度估计，下标 $-i$ 表示在留出第i个数据用于测试的情况下，给出的n-1个数据的估计。等价地，线性回归模型可以重新表述为明确表示残差：

$$
Y = X\beta + \gamma + \epsilon, \quad \epsilon_ {ij} \sim N(0, \sigma^2),
$$

通过引入均值移动参数γ，如[20]中所述，特征X ∈ Rn×p和标签Y ∈ Rn×c按行配对和堆叠。对于γ ∈ Rn×c的每一行，γi表示第i个数据的预测残差。这种表述已经在不同的研究主题中得到了广泛的研究，包括经济学[21][22][23][24]、鲁棒回归[20][25]、统计排名[26]、人脸识别[27]、半监督小样本学习[28][29]和贝叶斯偏好学习[30]等。这种表述在特定的研究任务中有不同的焦点。例如，在鲁棒回归问题[20][25]中，目标是获得一个对γ影响具有鲁棒性的估计 $\hat{\beta}$ 。在这里，对于从噪声标签中采样干净数据，我们感兴趣的是恢复零行的γ，因为这些元素对应于干净数据。

可扩展的惩罚回归 (SPR)。为了实现这一目标，从统计的角度来看，我们的会议报告[31]从(3)开始构建了一个样本选择框架，称为可扩展的惩罚回归(Scalable Penalized Regression, SPR)。通过在γ上施加稀疏惩罚P(γ; λ)，SPR通过从∞到0变化λ来获得γ(λ)的正则化解路径。然后它识别那些早期(或在较大的λ下)被选为非零的样本作为噪声数据，而那些晚期被选的作为干净数据，以手动指定的选定数据比例。在不可表示条件[32][33]下，SPR在模型选择一致性方面具有优势，即它可以恢复噪声数据集。通过仅将干净数据输入到下一轮训练中，训练出的网络受到噪声数据的污染较少，因此在实证上表现良好。

Knockoffs-SPR。然而，不可表示条件要求先验的真噪声集，这在实践中是无法获取的。因此我们无法知道SPR在实践中是否有理论保证，当这个条件失败时，使用SPR训练的网络可能仍然被大量的噪声数据污染，导致性能下降，正如我们在实验中验证的那样。为了解决SPR中的假选择问题，我们提供了一个数据自适应的样本选择算法，以在所需水平q下很好地控制选定数据中噪声数据的预期比例，例如q = 0.05。由于我们的目标是为下一轮训练识别干净数据，我们将此比例称为错误选择率(False-Selection-Rate, FSR)。FSR是稀疏回归中II型错误的期望率，因为非零元素对应于噪声数据。我们实现FSR控制的方法受到统计学中敲除方法的启发，这是一个最近开发的用于变量选择的框架[34][35][36][37]。敲除的目标是选择非零变量并通过将敲除特征 $\tilde{X}$ 作为原始特征X的伪造副本来控制假发现率(False-Discovery-Rate, FDR)。由于FDR对应于稀疏回归中I型错误率的期望，原始的敲除方法不能直接应用于样本选择，因为FSR是II型错误的期望率，并且敲除中没有理论保证来控制II型错误。为了实现FSR控制，我们提出了Knockoffs-SPR，它通过置换原始标签Y来构造敲除标签 $\tilde{Y}$ ，并将其实现在数据分区策略中以进行FSR控制。

正式地说，我们在SPR方法中重新利用了统计学中的敲除；并提出了一种新的数据自适应样本选择算法，称为Knockoffs-SPR。它通过控制选定的干净数据中噪声数据的比例来扩展SPR。有了这个属性，Knockoffs-SPR确保了数据中的干净模式占主导地位，从而带来更好的网络训练。具体来说，我们将整个噪声训练集划分为两个随机子集，并将Knockoffs-SPR分别应用于这两个子集。每次，我们使用一个子集来估计β，另一个通过比较通过回归在噪声标签和置换标签上分别获得的解路径γ(λ)和 $\tilde{\gamma}$ (λ)来选择干净数据。通过这种β和γ之间的解耦结构，我们证明了FSR可以通过任何预定水平进行控制。与原始的SPR理论相比，我们的新理论使我们能够在一般条件下有效地选择干净数据。

与网络训练结合，整个框架在图1中进行了说明，其中样本选择和网络学习被很好地结合在一起。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c2c99c0f844f470d8ad449e7d2c8a418.png#pic_ center" width="70%" />
</div>

具体来说，我们迭代地运行网络学习过程和样本选择过程，并重复此循环直到收敛。为了将Knockoffs-SPR整合到深度架构的端到端训练流水线中，最简单的方法是直接解决每个训练小批量或训练周期的Knockoffs-SPR以选择干净数据。每个小批量解决Knockoffs-SPR是有效的，但存在可识别性问题。一个小批量中的样本量可能太小，无法区分所有类别中的干净模式和噪声模式，特别是对于具有小批量大小的大型数据集。解决整个训练集的Knockoffs-SPR功能强大，但存在复杂性问题，导致计算成本不可接受。为了解决这两个问题，我们通过提出一种分割策略，在复杂性和可识别性之间取得平衡，将整个数据分割成小块，使得每个小块都可以高效解决，并且足够大以区分干净模式和噪声模式。然后Knockoffs-SPR并行运行在每个小块上，使其可以扩展到大型数据集。

由于被移除的噪声数据仍包含对网络训练有用的信息，我们采用了带有CutMix[38]的半监督训练流水线，将噪声数据用作未标记数据。我们进行了广泛的实验来验证我们的框架在几个基准数据集和真实世界噪声数据集上的有效性。结果表明了我们的Knockoffs-SPR算法的有效性。

贡献：我们的贡献如下：

- 在思想上，我们提出在一般场景下控制选择干净数据时的假选择率。
- 在方法论上，我们提出了Knockoffs-SPR，一种数据自适应方法来控制FSR。
- 在理论上，我们证明了Knockoffs-SPR可以在任何所需水平上控制FSR。
- 在算法上，我们提出了一种分割算法，通过平衡可识别性和复杂性来进行更好的样本选择，以扩展到大型数据集。
- 在实验上，我们在几个基准数据集和真实世界噪声数据集上展示了我们方法的有效性和效率。

扩展：我们这项工作的会议版本SPR，在[31]中发表。与SPR[31]相比，我们有以下扩展：

- 我们确定了SPR的局限性，并考虑在选择干净数据时控制FSR。
- 我们提出了一个新的框架：Knockoffs-SPR，在一般场景下，无论是理论上还是实证上，都能有效地选择干净数据。
- 我们将我们的方法应用于Clothing1M，并取得了比基线更好的结果。

本文的其余部分组织如下：第II节，我们介绍我们的SPR算法及其噪声集恢复理论。第III节，介绍了Knockoffs-SPR算法及其FSR控制定理。第IV节，提出了几种策略，将Knockoffs-SPR很好地整合到网络训练中。第V节，我们的工作与之前的研究进行了联系。第VI节，我们在几个合成和真实世界的噪声数据集上进行了实验，并进一步对Knockoffs-SPR进行了实证分析。第VII节总结了本文。

# Ⅱ. 清洁样本选择

## A. 问题设置
我们有一个图像-标签对的数据集 $\{(img_ i, y_ i)\}_ {i=1}^n$ ，其中噪声标签 $y_ i$ 是从真实标签 $y_ i^\*$ 被污染的。真实标签 $y_ i^\*$ 和污染过程是未知的。我们的目标是学习一个模型 $f(\cdot)$ ，使其能够从图像 $img_ i$ 识别出真实的类别 $y_ i^\*$ ，即，在噪声标签 $y_ i$ 上训练后， $f(img_ i) = y_ i^\*$ 。

在本文中，我们采用深度神经网络作为识别模型，并将 $f(\cdot)$ 分解为 $f_ c(g(\cdot))$ ，其中 $g(\cdot)$ 是用于特征提取的深度模型， $f_ c(\cdot)$ 是用于分类的最终全连接层。对于每个输入图像 $img_ i$ ，特征提取器 $g(\cdot)$ 用于编码特征 $x_ i := g(img_ i)$ 。然后全连接层用于输出得分向量 $\hat{y}_ i = f_ c(x_ i)$ ，该向量表示它属于每个类别的机会，预测由 $\hat{y}_ i = \arg\max(\hat{y}_ i)$ 提供。

由于训练数据包含许多噪声标签，简单地从所有数据进行训练会导致泛化和鲁棒性严重下降。直观地说，如果我们能够从噪声训练集中识别出清洁标签，并用清洁数据训练网络，我们可以减少噪声标签的影响，实现更好的性能和模型的鲁棒性。为了实现这一点，我们提出了一个样本选择算法，以理论保证在噪声训练集中识别清洁数据。

## B. 通过惩罚回归选择清洁样本
受到用于异常值检测的留一法启发，我们为每个数据引入了一个显式的噪声数据指标 $\gamma_ i$ ，并假设提取的特征 $x_ i$ 和独热标签 $y_ i$ 之间存在线性关系，带有噪声数据指标，如下所示：

$$
y_ i = x_ i^T \beta + \gamma_ i + \epsilon_ i,
$$

其中 $y_ i \in \mathbb{R}^c$ 是 $c$ 类任务的独热向量； $x_ i \in \mathbb{R}^p, \beta \in \mathbb{R}^{p \times c}, \gamma_ i \in \mathbb{R}^c, \epsilon_ i \in \mathbb{R}^c$ 。噪声数据指标 $\gamma_ i$ 可以被视为线性预测的校正。对于清洁数据， $y_ i \sim \mathcal{N}(x_ i^T \beta^\*, \sigma^2 I_ c)$ 且 $\gamma_ i^\* = 0$ ，对于噪声数据， $y_ i^\* = y_ i - \gamma_ i^\* \sim \mathcal{N}(x_ i^T \beta^\*, \sigma^2)$ 。我们记 $C := \{i : \gamma_ i^\* = 0\}$ 为真实的清洁集。

为了选择清洁数据进行训练，我们提出了一种可扩展的惩罚回归（Scalable Penalized Regression, SPR），设计如下：

$$
argmin_ {\beta, \gamma} \frac{1}{2} \|Y - X\beta - \gamma\|_ F^2 + P(\gamma; \lambda),
$$

其中我们有矩阵公式 $X \in \mathbb{R}^{n \times p}, Y \in \mathbb{R}^{n \times c}$ 的 $\{x_ i, y_ i\}_ {i=1}^n$ ； $P(\cdot; \lambda)$ 是行稀疏惩罚，系数参数 $\lambda$ 。所以我们有 $P(\gamma; \lambda) = \sum_ {j=1}^n P(\gamma_ i; \lambda)$ ，例如，群套索稀疏性 $P(\gamma; \lambda) = \lambda \sum_ i \|\gamma_ i\|_ 2^2$ 。

为了估计 $C$ ，我们只需要解 $\gamma$ 而不需要估计 $\beta$ 。因此为了简化优化，我们将 $\gamma$ 固定时的普通最小二乘（OLS）估计代入 $\beta$ 中（公式5）。为确保 $\hat{\beta}$ 可识别，我们在 $X$ 上应用 PCA 使得 $p \ll n$ ，以便 $X$ 具有全列秩。记 $\tilde{X} = I - X(X^TX)^{\dagger}X^T, \tilde{Y} = \tilde{XY}$ ，公式（5）转化为：

$$
\arg\min_ {\gamma} \frac{1}{2} \|\tilde{Y} - \tilde{X}\gamma\|_ F^2 + P(\gamma; \lambda),
$$

这是一个标准的稀疏线性回归问题，用于 $\gamma$ 。注意，在实践中我们几乎不可能选择一个在所有情况下都能很好地工作的适当 $\lambda$ 。此外，从惩罚回归问题和 Huber 的 M-估计之间的等价性来看， $\gamma$ 的解是以软阈值返回的。因此，寻找单个 $\gamma$ 的精确解并不值得。相反，我们使用块下降算法 [39] 来解决 $\gamma$ ，使用一系列 $\lambda$ 并生成解路径。当 $\lambda$ 从 $\infty$ 变为 $0$ 时，稀疏惩罚的影响减小， $\gamma_ i$ 逐渐以非零值被模型选择，换句话说，被模型选择，如图 2 所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/0762bdcae0074207b21cf0bad4090e51.png#pic_ center" width="70%" />
</div>

由于早期选择的实例更可能是噪声，我们根据它们被选择的时间定义为：

$$
Z_ i = \sup \{\lambda : \gamma_ i(\lambda) \neq 0\},
$$

较大的 $Z_ i$ 表示更早选择的 $\gamma_ i$ 。然后选择顶部样本作为噪声数据，其他作为清洁数据。在没有关于清洁比例的知识的情况下，我们在实践中选择50%的数据作为清洁数据。

## C. SPR中噪声集恢复的理论
SPR 在可识别条件 [33] 下，具有理论上的保证，可以以高概率完全恢复噪声数据集。具体来说，考虑公式（6）的向量化版本：

$$
argmin \frac{1}{2} \|\vec{y} - \hat{X}\vec{\gamma}\|^2 + \lambda \|\vec{\gamma}\|_ 1,
$$

其中 $\vec{y}, \vec{\gamma}$ 是从公式（6）中的 $Y, \gamma$ 向量化的； $\hat{X} = I_ c \otimes \tilde{X}$ ， $\otimes$ 表示 Kronecker 积运算符， $I_ c$ 是 $c \times c$ 单位矩阵。记 $S := \text{supp}(\vec{\gamma}^\*)$ ，它是噪声集 $C^c$ 。我们进一步记 $\hat{X}_ S$（分别 $\hat{X}_ {Sc}$）为 $\hat{X}$ 的列向量，其索引在 $S$（分别 $S_ c$）中， $\mu_ {\hat{X}} = \max_ {i \in S_ c} \|\hat{X}_ i\|^2$ 。

然后我们有：

**定理1（噪声集恢复）**：假设：C1，限制性特征值： $\lambda_ {\min}(\hat{X}_ S^T \hat{X}_ S) = C_ {\min} > 0$ ；C2，不可表示性：存在 $\eta \in (0, 1]$ ，使得 $\|\hat{X}_ {Sc}^T \hat{X}_ S(\hat{X}_ S^T \hat{X}_ S)^{-1}\|_ {\infty} \leq 1 - \eta$ ；C3，大误差： $\vec{\gamma}^\*_ {\min} := \min_ {i \in S} |\vec{\gamma}^\*_ i| > h(\lambda, \eta, \hat{X}, \vec{\gamma}^\*)$ ，其中 $\|A\|_ {\infty} := \max_ i \sum_ j |A_ {ij}|$ ，并且 $h(\lambda, \eta, \hat{X}, \vec{\gamma}^\*) = \frac{\lambda \eta}{\sqrt{C_ {\min} \mu_ {\hat{X}}} + \lambda \|(\hat{X}_ S^T \hat{X}_ S)^{-1}\text{sign}(\vec{\gamma}^\*_ S)\|_ {\infty}}$ 。假设 $\lambda \geq 2\sigma\sqrt{\frac{\mu_ {\hat{X}}}{\eta}}\sqrt{\log cn}$ ，则以概率大于 $1 - 2\frac{cn}{1}$ ，模型（8）有一个唯一解 $\hat{\vec{\gamma}}$ ，使得：1）如果 C1 和 C2 成立， $\hat{C}^c \subseteq C^c$ ；2）如果 C1，C2 和 C3 成立， $\hat{C}^c = C^c$ 。

我们在附录中提供证明，遵循 [32]，[40] 中的处理。在这个定理中，C1 是获得唯一解的必要条件，在我们的案例中，通常在清洁数据是训练数据中的大多数的自然假设下得到满足。如果 C2 成立，估计的噪声数据是真正噪声数据的子集。这个条件是确保 SPR 成功的关键，它要求清洁数据和噪声数据之间的差异足够大，以至于我们不能用噪声数据表示清洁数据。如果 C3 进一步成立，估计的噪声数据就是所有的真正噪声数据。C3 要求通过 $\gamma_ i$ 测量的误差足够大，以便从随机噪声中被识别出来。

# Ⅲ. 控制清洁样本选择

在上一节中，我们通过停止解的路径来选择数据，使得50%的样本被选为干净数据。如果这恰好是干净数据的比率，定理1表明我们的SPR可以在不可表示性条件下识别出干净数据集C。然而，不可表示性条件和真实干净集C的信息在实践中是未知的，这使得这个理论在实际应用中难以使用。特别是，当|Cc|未知时，算法可能会在不适当的时间停止，导致选定的干净数据的噪声率仍然很高，使得下一轮训练的模型仍然受到噪声模式的严重污染。

为解决SPR中的假选问题，我们在本节提出了一种自适应的早期停止方法，该方法针对控制选定数据中预期噪声率的目标，即错误选择率（False-Selection-Rate, FSR）在期望水平q（0 < q < 1）以下：

$$
\text{FSR} = E  [ \frac{ \{ j : j \notin H_ 0 \cap \hat{C} \}}{ \{ j : j \in \hat{C} \} \cup 1}  ]
$$

其中 $\hat{C}=\{j:\hat{\gamma}_ j=0\ }$ 是恢复的干净集， $H_ 0 : \gamma_ i^\*=0$ 表示零假设，即样本i属于干净数据集。因此，上述(9)中的FSR旨在控制选定的零假设中的假率，这也称为在假设检验中的预期类型II错误率。

## A. Knockoffs-SPR

在SPR中，我们比较来自噪声数据指示器 $\gamma$ 的不同样本的统计量。同时，探索一个替代视角也是有益的：与随机排列的标签相比，标注标签的可信度如何？这一概念促使我们开发一种新的统计量，它不仅与其他数据相比具有可信度，而且与排列标签保持一致性。具体来说，这种统计量使我们能够通过比较每个数据的选定时间来有效地控制FSR。

为了实现FSR控制，我们提出了Knockoffs-SPR进行干净样本选择。我们的方法受到统计学中knockoff方法的启发，但关注点不同，我们通过排列而不是构建knockoff特征来选择干净标签。具体来说，在模型(4)下，我们对每个数据的标签进行排列，并构建排列 $\tilde{y}$ 。然后在y和 $\tilde{y}$ 上解决模型(4)，分别获得解的路径 $\gamma(\lambda)$ 和 $\tilde{\gamma}(\lambda)$ 。我们将展示这种构建可以通过比较 $\gamma(\lambda)$ 和 $\tilde{\gamma}(\lambda)$ 的选择时间来挑选出干净数据。基于此构建，我们提议将整个数据集划分为两个不相交的部分，一部分用于估计 $\beta$ ，另一部分用于学习 $\gamma(\lambda)$ 和 $\tilde{\gamma}(\lambda)$ 。我们将展示这种数据划分的独立结构使我们能够构建比较统计量，其备择假设中的符号(噪声数据)是独立的伯努利过程，这对于FSR控制至关重要。

具体来说，我们将整个数据集D划分为D1:=(X1, Y1)和D2:=(X2, Y2)，其中$n_ i := |Di|$ ，并在D1和D2上分别实施Knockoffs-SPR。下面，我们只介绍D2上的程序，因为D1上的程序具有相同的精神。该程序由三个步骤组成：i) 在D1上估计 $\beta$ ；ii) 在D2上估计 $(\gamma(\lambda), \tilde{\gamma}(\lambda))$ ；iii) 构建比较统计量和选择过滤器：我们将在第三节B中详细讨论每个步骤。

步骤i)：在D1上估计 $\beta$ 。我们的目标是提供一个独立的D2的 $\beta$ 估计。最简单的策略是使用标准的OLS估计来获得 $\hat{\beta}_ 1$ 。然而，由于噪声样本的干扰，这个估计可能不准确。为此，我们首先在D1上运行SPR以获得干净数据，然后通过OLS在估计的干净数据上解决 $\beta$ 。

步骤ii)：在D2上估计 $(\gamma(\lambda),\tilde{\gamma}(\lambda))$ 。在获得D1上的解 $\hat{\beta}_ 1$ 后，我们在D2上学习 $\gamma(\lambda)$ ：

$$
\arg\min_ {\gamma} \frac{1}{2} \|Y_ 2 - X_ 2\hat{\beta}_ 1 - \gamma_ 2\|_ F^2 + P(\gamma_ 2; \lambda)
$$

对于每个one-hot编码向量 $y_ {2,j}$ ，我们随机排列1的位置并获得另一个one-hot向量 $\tilde{y}_ {2,j} \neq y_ {2,j}$ 。对于干净数据j， $\tilde{y}_ {2,j}$ 变成了噪声标签；而对于噪声数据， $\tilde{y}_ {2,j}$ 以概率 $\frac{c-2}{c-1}$ 变为另一个噪声标签，以概率 $\frac{1}{c-1}$ 变为干净标签，其中c表示类别数。获得排列矩阵 $\tilde{Y}_ 2$ 后，我们使用与SPR相同的算法学习解的路径 $(\gamma_ 2(\lambda), \tilde{\gamma}_ 2(\lambda))$ ：

$$
\begin{cases} 
\arg\min_ {\gamma_ 2} \frac{1}{2} \|Y_ 2 - X_ 2\hat{\beta}_ 1 - \gamma_ 2\|_ F^2 + \sum_ j P(\gamma_ {2,j}; \lambda), \\
\arg\min_ {\tilde{\gamma}_ 2} \frac{1}{2} \|\tilde{Y}_ 2 - X_ 2\hat{\beta}_ 1 - \tilde{\gamma}_ 2\|_ F^2 + \sum_ j P(\tilde{\gamma}_ {2,j}; \lambda).
\end{cases} 
$$

步骤iii)：比较统计量和选择过滤器。在获得解的路径 $(\gamma_ 2(\lambda), \tilde{\gamma}_ 2(\lambda))$ 后，我们分别定义与 $y_ {2,j}$ 和 $\tilde{y}_ {2,j}$ 相关的样本显著性分数，作为选定时间： $Z_ j := \sup\{\lambda : \|\gamma_ {2,j}(\lambda)\|_ 2 \neq 0\}$ 和 $\tilde{Z}_ j := \sup\{\lambda : \|\tilde{\gamma}_ {2,j}(\lambda)\|_ 2 \neq 0\}$ 。有了 $Z_ j, \tilde{Z}_ j$ ，我们定义 $W_ j$ 为：

$$
W_ j := Z_ j \cdot \text{sign}(Z_ j - \tilde{Z}_ j)
$$

基于这些统计量，我们定义一个数据依赖的阈值T：

$$
T = \max\{t > 0 : 1 + \{j : 0 < W_ j \leq t\} \leq q \cdot \{j : -t \leq W_ j < 0\} \vee 1\}
$$

或者如果这个集合为空，则T = 0，其中q是预定义的上限。我们的算法将选择由以下方式识别的干净子集：

$$
C_ 2 := \{j : -T \leq W_ j < 0\}
$$

在实践中，计算完 $\{W_ j\}_ {j=1}^{n_ 2}$ 后，我们根据它们的幅度 $|W_ j|$ 降序排列。给定q，我们首先将初始T设置为最大幅度，即T = $\max_ j |W_ j|$ 。然后我们评估(13)中的条件是否满足。如果没有满足，我们从考虑中移除最大值， $\max_ j |W_ j|$ ，并重新定义T为剩余值中的最大幅度。这个过程迭代继续，直到我们找到一个可行的T，使得不等式成立。这确保了我们已经找到了一个可实现的T，在期望水平q下控制FSR。

从经验上看，如果阈值q足够小，T可能等于0。在这种情况下，没有干净数据被选择，这是没有意义的。因此，我们从一个较小的q开始，逐渐增加q并计算T，直到找到一个可实现的T使得T > 0，以尽可能小地限制FSR。在实践中，当FSR不能通过q = 50%来限制时，我们将结束选择，简单地通过 $\{W_ j\}$ 选择最可能是干净的示例的一半。

整个Knockoffs-SPR的过程在算法1中展示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/e81c626d13d2424c8960b1a92020f30d.png#pic_ center" width="70%" />
</div>

Knockoffs-SPR构建随机排列的标签作为对照，以选择真正干净的样本，同时控制FSR，即所选干净样本中噪声样本的预期比率。直观地说，它选择那些其标注标签比其副本（即随机排列的标签）更可信的干净样本。为了衡量可信度，我们计算了Zj和 $\tilde{Z}_ j$ 。较小的Z表示标签Y的可信度更高。因此，我们选择那些W := Z $\cdot$ sign(Z -  $\tilde{Z}$ )的负值较小的作为干净样本。基于W，我们然后计算一个数据依赖的阈值T来控制FSR。

FSR的严格证明依赖于由 $\hat{\beta}$ 确定的幅度|W|和由( $\gamma, \tilde{\gamma}$ )确定的sign(W)之间的独立结构。这激发了我们将完整数据集划分为两个独立部分，第一部分用于估计 $\hat{\beta}$ ，第二部分用于计算( $\gamma, \tilde{\gamma}$ )。

总之Knockoffs-SPR需要将数据集分割为两部分并计算W和T。具体来说，在步骤i中，我们通过数据分割来分解β和γ的估计，引入一个独立的结构。我们首先使用第一部分D1来计算 $\hat{\beta}$ ；然后进入步骤ii，我们构建随机置换的标签 $\tilde{Y}$ （第2行），作为仿制品并使用第二部分D2（第3行）来计算W。我们通过逐步增加q直到能够选出清洁样本集（第4-7行）。最终，我们得到清洁样本集 $C_ 2 := \{i : -T \leq W_ i(t) < 0\}$ 。注意，我们通过模型实现 $\tilde{Y}$ 作为最有信心的置换标签，详见第IV-A节。

## B. 关于Knockoffs-SPR的统计分析

在这部分中，我们将介绍Knockoffs-SPR中每一步的动机和直觉。

数据划分。Knockoffs-SPR将数据集D划分为两个子集D1和D2。这一步分解了β和γ估计之间的依赖性，我们使用D1/D2分别来估计β/γ。然后，如果D1和D2是不相交的，那么 $\hat{\beta}(D1)$ 与 $\hat{\gamma}(D2)$ 是相互独立的。这种结构引入了独立的估计 $\{ \text{sign}(W_ j) \}_ {j=1}^{n_ 2}$ ，这使得在D2上对FSR的控制成为可能。

排列。正如我们在步骤ii中讨论的，当原始标签是干净的时候，其排列后的标签将是一个噪声标签。另一方面，如果原始标签是噪声的，那么其排列后的标签以 $\frac{1}{c-1}$ 的概率变为干净标签，以 $\frac{c-2}{c-1}$ 的概率变为另一个噪声标签，其中c表示类别的数量。注意到，在解路径中，噪声数据的γ通常比干净数据的γ更早被选择。这意味着噪声数据的Z值通常比干净数据的Z值大。因此，根据W的定义，一个干净的样本理想情况下将有一个小的负W值： $W := Z \cdot \text{sign}(Z - \tilde{Z})$ ，其中Z和 $\tilde{Z}$ 分别对应干净标签和噪声标签。相比之下，噪声样本的W倾向于有大的幅度，并且当 $\tilde{y}_ 2^j$ 变为另一个噪声标签时，有几乎相等的概率为正或负。这种W在干净和噪声数据之间的不同行为可以帮助我们从噪声数据中识别出干净的样本。

不对称比较统计量W。定义比较统计量的典型方式是以对称的方式，即 $W_ j := Z_ j \vee \tilde{Z}_ j \cdot \text{sign}(Z_ j - \tilde{Z}_ j)$ 。通过这种方式，具有噪声排列标签的干净样本倾向于有大的 $|W_ j|$ ，因为我们期望噪声标签有大的 $\tilde{Z}_ j$ 。然而，这与我们的目标相悖，因为我们只要求干净样本具有小幅度。因此，我们设计了不对称统计量，只考虑原始标签的幅度。

为了看到W对于噪声和干净数据的不对称行为，我们考虑(11)中关于( $\gamma_ {2,j}, \tilde{\gamma}_ {2,j}$ )的Karush-Kuhn-Tucker (KKT)条件：

$$
\gamma_ {2,j} + \frac{\partial P(\gamma_ {2,j}; \lambda)}{\partial \gamma_ {2,j}} = x_ {2,j}^T(\beta^\* - \hat{\beta}_ 1) + \gamma_ {2,j}^\* + \epsilon_ {2,j} \quad (15a)
$$

$$
\tilde{\gamma}_ {2,j} + \frac{\partial P(\tilde{\gamma}_ {2,j}; \lambda)}{\partial \tilde{\gamma}_ {2,j}} = x_ {2,j}^T(\beta^\* - \hat{\beta}_ 1) + \tilde{\gamma}_ {2,j}^\* + \tilde{\epsilon}_ {2,j} \quad (15b)
$$

其中 $\epsilon_ {2,j} \sim \text{i.i.d } \tilde{\epsilon}_ {2,j}$ ，如果 $y_ {2,j}$ 和 $\tilde{y}_ {2,j}$ 都是噪声的，那么 $\|\gamma_ {2,j}^\*\| = \|\tilde{\gamma}_ {2,j}^\*\|$ ，并且 $P(\gamma_ {2,j}; \lambda) := \lambda \|\gamma_ {2,j}\|$ 作为一个例子。通过条件化 $\hat{\beta}_ 1$ 并表示 $a_ j := x_ {2,j}^T(\beta^\* - \hat{\beta}_ 1)$ ，我们有：

$$
P(W_ j > 0) = P(\|a_ j + \gamma_ {2,j}^\* + \epsilon_ {2,j}\| > \|a_ j + \tilde{\gamma}_ {2,j}^\* + \tilde{\epsilon}_ {2,j}\|)
$$

然后可以看到，如果j是干净的，我们有 $\gamma_ {2,j}^\* = 0$ 。然后 $Z_ j$ 趋于小，此外，如果 $\hat{\beta}_ 1$ 能够很好地估计$\beta^\*$ ，那么很可能有 $Z_ j < \tilde{Z}_ j$ 。因此， $W_ j$ 趋于是一个小的负数。另一方面，如果j是噪声的，那么 $Z_ j$ 趋于大，以便于γj解释噪声模式，并且除此之外，当 $\tilde{y}_ {2,j}$ 变为另一个噪声标签时， $Z_ j < \tilde{Z}_ j$ 和 $Z_ j \geq \tilde{Z}_ j$ 之间的概率大致相等，概率为 $\frac{c-2}{c-1}$ 。所以 $W_ j$ 趋于有大的值，并且除此之外，

$$
P(W_ j > 0) = P(W_ j > 0|\tilde{y}_ {2,j} \text{ is noisy})P(\tilde{y}_ {2,j} \text{ is noisy}) + P(W_ j > 0|\tilde{y}_ {2,j} \text{ is clean})P(\tilde{y}_ {2,j} \text{ is clean}) = \frac{1}{2} \cdot \frac{c-2}{c-1} + P(W_ j > 0|\tilde{y}_ {2,j} \text{ is clean}) \cdot \frac{1}{c-1}
$$

这落在区间 $[\frac{1}{2} \cdot \frac{c-2}{c-1}, \frac{1}{2} \cdot \frac{c}{c-1}]$ 内。也就是说， $P(W_ j > 0) \approx \frac{1}{2}$ 。从这个角度来看，干净数据对应于理想情况下W的小的负数，这可以帮助我们用大的W与几乎相等的概率为正或负来区分噪声数据。


Remark。对于噪声 $y_ {2,j}$ ，我们假设 $\|\gamma_ {2,j}^\*\| = \|\tilde{\gamma}_ {2,j}^\*\|$ ，因此有 $P(W_ j > 0|\tilde{2,j} \text{ is noisy}) = 1/2$ 。然而，在实践中，当 $y_ {2,j}$ 对应于模型已学习的噪声模式时，这可能不成立。在这种情况下，可能存在 $|\gamma_ {2,j}^\*| < |\tilde{\gamma}_ {2,j}^\*|$ ，对于一个随机排列的标签 $\tilde{y}_ {2,j}$ ，它可能没有被模型学习，这违反了 $P(W_ j > 0|\tilde{y}_ {2,j}) = 1/2$ ，因此 $P(W_ j > 0) \approx 1/2$ 。为了解决这个问题，我们改为将排列标签设置为模型提供的最有信心的候选项，详见第IV-A节的细节。此外，如果 $\hat{\beta}_ 1$ 能够准确估计 $\beta^\*$ ，根据(15)中的KKT条件，我们有$P(W_ j > 0) < 1/2$ 。也就是说，对于干净数据， $W_ j$ 趋于是负数，这对干净样本的选择是有益的。

数据自适应阈值。我们提出的数据自适应阈值T直接设计用来控制FSR。具体来说，定义在(9)中的FSR等同于

$$
\text{FSR}(t) = \mathbb{E}  [ \frac{  \{j : \gamma_ j \neq 0 \text{ and } -t \leq W_ j < 0\}}{  \{j : -t \leq W_ j < 0\} \lor 1}  ] \quad (18)
$$

其中分母表示根据(14)选定的干净数据的数量，分子表示错误选定的噪声数据的数量。(18)的形式可以进一步分解为：

$$
\begin{aligned}
&\mathbb{E}  [ \frac{  \{ \gamma_ j \neq 0, -t \leq W_ j < 0\}}{1 +   \{ \gamma_ j \neq 0, 0 < W_ j \leq t\}} \cdot \frac{1 +   \{0 < W_ j \leq t\}}{  \{-t \leq W_ j < 0\} \lor 1}  ] \\
&\leq \mathbb{E}  [ \frac{  \{ \gamma_ j \neq 0, -t \leq W_ j < 0\}}{1 +   \{ \gamma_ j \neq 0, 0 < W_ j \leq t\}} \cdot q  ]
\end{aligned}
$$

其中最后一个不等式来自于T在(13)中的定义。为了控制FSR，只需要限制 $\mathbb{E}  [ \frac{  \{ \gamma_ j \neq 0, -t \leq W_ j < 0\}}{1 +   \{ \gamma_ j \neq 0, 0 < W_ j \leq t\}} \cdot q  ]$ 。

简单来说，这个项意味着噪声数据中负W的数量与正W的数量之比。由于如前所述，噪声数据的W大约有一半的概率为正/负，直观上我们有这个项约等于 $\frac{1}{2}$ 。为了形式化，我们构造了一个关于噪声数据中 $1(W_ i > 0)$ 的鞅过程。我们把细节留在附录中。

## C. Knockoffs-SPR的FSR控制

我们的目的是展示在我们的数据自适应阈值T下，可以保证 $\text{FSR} \leq q$ 。我们的主要结果如下：

定理 2 (FSR控制): 在模型(4)下，对于c类分类任务，对于所有 $0 < q \leq 1$ ，Knockoffs-SPR的解满足

$$
\text{FSR}(T) \leq q \quad (20)
$$

其中两个子集的阈值T分别定义为：

$$
T_ i = \max_ {t \in W}  \{ \frac{1 +   \{j : 0 < W_ j \leq t\}}{  \{j : -t \leq W_ j < 0\}} \lor 1 \leq \frac{c - 2 + 2\kappa_ i}{2(c - 2\kappa_ i)} q  \}
$$

对于多类设置 $c > 2$ ，我们也有明确定义的 $T_ i$ 为：

$$
T_ i = \max_ {t \in W}  \{ \frac{1 +   \{j : 0 < W_ j \leq t\}}{  \{j : -t \leq W_ j < 0\}} \lor 1 \leq \frac{c - 2}{2c} q  \}
$$

我们在附录中提供证明。系数 $1/2$ 来自于我们在两个D1和D2上运行Knockoffs-SPR的子集划分策略，而    $c - 2 + 2\kappa / (c - 2\kappa)$ 来自于(19)中第一部分的上界。这个定理告诉我们，可以使用Knockoffs-SPR的过程通过给定的阈值q来控制FSR。与SPR相比，这个过程在现实世界实验中更加实用和有用，我们在第VI节中展示了它的效用。

# IV. 利用Knockoffs-SPR进行学习

在本节中，我们将介绍如何将Knockoffs-SPR整合到神经网络的训练中。我们首先介绍Knockoffs-SPR的几个实现细节，然后我们提出了一个分割算法，使得Knockoffs-SPR能够扩展到大规模数据集。最后，我们讨论了一些训练策略，以便更好地利用选定的干净数据。

## A. Knockoffs-SPR在实践中

我们介绍了几种提高FSR控制能力和选择干净样本能力的策略，这些策略受到W在噪声和干净样本之间不同行为的启发。理想情况下，对于一个干净的样本j，Wj应该是一个小的负数；如果j是噪声数据，Wj倾向于有大的幅度，并且大约有50%的概率为正或负，如(17)所示。为了实现这些属性以更好地选择干净样本，我们提出了以下策略，在特征提取器、数据预处理、标签排列策略、在D1上估计β以及在(13)、(14)中识别干净数据的过程中。

特征提取器：一个好的特征提取器对干净样本选择算法至关重要。在我们的实验中，我们采用了自监督训练方法SimSiam[42]来预训练特征提取器，使X能够在早期阶段很好地编码训练数据的信息。

数据预处理：我们对神经网络提取的特征实施PCA进行降维。这可以使X成为全秩矩阵，确保SPR中 $\hat{\beta}$ 的可识别性。此外，这样的低维特性可以使模型更准确地估计β。根据KKT条件(15)，我们有干净数据j的Wj趋于负，幅度小。因此，模型可以有更好的干净样本选择能力，即在选择更多干净样本的同时控制FSR。

标签排列策略：与随机排列策略不同，我们的Knockoff-SPR将标签排列为模型提供的最有信心的候选项，特别是当噪声率高或某些噪声模式在数据中占主导地位时，出于FSR的考虑。具体来说，如果一些噪声标签y2,j的模式已被模型学习，那么对于一个随机排列的标签 $\tilde{y}_ {2,j}$ ，可能 $\gamma_ {2,j}^\*$ 的幅度比 $\tilde{\gamma}_ {2,j}^\*$ 小，违反了 $P(W_ j > 0|\tilde{y}_ {2,j}) = 1/2$ ，因此在实践中 $P(W_ j > 0) \approx 1/2$ 。最有信心的排列缓解了这个问题，因为最有信心的标签 $\tilde{y}_ {2,j}$ 自然可以有小幅度的 $\tilde{\gamma}_ {2,j}^\*$ 。

在D1上估计β：我们实施SPR作为第一步，在D1上学习β。与普通最小二乘法OLS相比，SPR可以从数据中移除一些噪声模式，从而实现β的准确估计。与数据处理步骤类似，这样的准确估计可以提高选择干净样本的能力。

在(13)、(14)中识别干净数据：我们为每个类别计算W的T，并识别每个类别的干净子集，以提高每个类别的干净数据能力。在实践中，由于某些类别可能比其他类别更容易学习，这些类别中的Wj具有较小的幅度。因此，如果我们要计算所有类别中的T并识别C2，这些类别的数据将占据主导地位。有了这个设计，干净数据更加平衡，这有助于下一个时期的训练。

## B. 可扩展至大型数据集

样本选择算法的计算成本随着训练样本的增长而增加，使其无法扩展至大型数据集。为了解决这个问题，我们提出将整个训练集分割成许多小块，每个小块包含一小部分训练类别和少量训练数据。通过这种分割策略，我们可以并行运行Knockoffs-SPR在几个小块上，并显著减少运行时间。对于分割策略，我们注意到识别干净数据的关键是利用W的幅度和符号方面的不同行为。如果干净类的模式与噪声类的模式相似，这种差异可能会减轻，可能导致识别干净集的召回率/能力不满意。

具体来说，我们定义类别i和j之间的相似性为：

$$
s(i, j) = p_ i^T p_ j \quad (21)
$$

其中p代表类别原型。为了获得类别i的pi，我们采用网络在训练迭代过程中提取的每个类别的干净特征xi，并将它们平均以在当前训练周期结束时获得类别原型pc，公式如下：

$$
p_ c = \frac{\sum_ {i=1}^{n} x_ {i1}(y_ i = c, i \in C)}{\sum_ {i=1}^{n} 1(y_ i = c, i \in C)} \quad (22)
$$

然后，我们将最相似的类别组合在一起。在初始化步骤中，当干净集尚未估计时，我们简单地使用所有数据来计算类别原型。在我们的实验中，每个组被设计为包含10个类别。

对于每个组中的实例，我们以平衡的方式分割每个类别的训练数据，使得每个小块包含每个类别相同数量的实例。这个数量被确定为确保干净模式在块中占多数，以便可以轻松进行优化。在实践中，我们从每个类别选择75个训练数据来构建小块。

我们的分割算法流程在算法2中描述。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/513d37f4f022469e85dc99b561657f0f.png#pic_ center" width="70%" />
</div>

## C. 与Knockoffs-SPR结合的网络学习

当使用Knockoffs-SPR进行训练时，我们可以进一步通过将Knockoffs-SPR与半监督算法结合来利用噪声数据的支持。在本文中，我们在干净数据和噪声数据之间插值部分图像，如CutMix[38]中所述，

$$
\tilde{\text{img}} = M \odot \text{img}_ {\text{clean}} + (1 - M) \odot \text{img}_ {\text{noisy}} \quad (23a)
$$

$$
\tilde{y} = \lambda y_ {\text{clean}} + (1 - \lambda)y_ {\text{noisy}} \quad (23b)
$$

其中M ∈ {0, 1}^W×H是一个二进制掩码， $\odot$ 是逐元素乘法， $\lambda \sim \text{Beta}(0.5, 0.5)$ 是插值系数，干净和噪声数据由Knockoffs-SPR识别。然后我们使用插值数据训练网络，使用

$$
L(\tilde{\text{img}}, \tilde{y}) = L_ {\text{CE}}(\tilde{\text{img}}, \tilde{y}), \quad (24)
$$

其中LCE表示交叉熵损失。在实践中，我们可以在估计的干净数据上使用标准监督训练和半监督训练之间切换。

$$
L(\text{img}_ i, y_ i) = 1(i \in C) \cdot L_ {\text{CE}}(\text{img}_ i, y_ i), \quad (25)
$$

其中1(i ∈ C)是指示函数，这意味着只有估计的干净数据的交叉熵损失用于计算损失。我们进一步存储一个带有EMA更新权重的模型。我们的完整算法在算法3中说明。使用这个流程训练的神经网络在几个合成和真实世界的噪声数据集上具有强大的识别能力。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/87b5d96c1543411dbf31a3d7ad435e15.png#pic_ center" width="70%" />
</div>

# VI. 实验

在本节中，我们将验证Knockoffs-SPR在合成噪声数据集CIFAR-10和CIFAR-100 [63]，以及真实世界噪声数据集WebVision [64]和Clothing1M [2]上的有效性。我们考虑了CIFAR数据集上的两种类型的噪声标签：i) 对称噪声：每个类别都以统一的方式被其他所有标签污染；ii) 不对称噪声：标签被类似的（在模式上）类别污染。WebVision拥有从互联网收集的240万张图像，其类别列表与ImageNet ILSVRC12相同。Clothing1M拥有从互联网收集并由周围文本标记的100万张图像。

骨架网络：对于CIFAR，我们使用ResNet-18 [65]作为我们的骨架网络。对于WebVision，我们使用Inception-ResNet [66]提取特征，以遵循先前的工作。对于Clothing1M，我们使用ResNet-50作为骨架网络。对于CIFAR和WebVision，我们分别使用SimSiam [42]进行自监督预训练100个周期和350个周期。对于Clothing1M，我们使用ImageNet预训练权重，以遵循先前的工作。

超参数设置：我们使用SGD训练所有网络，动量为0.9，采用余弦学习率衰减策略。初始学习率设置为0.01。权重衰减对于Clothing1M设置为1e-4，对于其他数据集设置为5e-4。我们对所有实验使用批量大小为128。我们使用随机裁剪和随机水平翻转作为增强策略。网络分别在CIFAR上训练180个周期，在WebVision上训练300个周期，在Clothing1M上训练5个周期。网络训练策略在算法3的第6行中选择p = 0.5（Clothing1M），而对于其他数据集，我们只使用CutMix训练。对于Knockoffs-SPR中使用的特征，我们将X的维度降低到类别的数量。对于Clothing1M，这是14，而对于其他数据集，降低的维度是10（CIFAR-100和WebVision的每个小块包含10个类别）。我们还运行了SPR，结合我们的新网络训练算法（算法3），并报告了相应的结果。

## A. 对称噪声和不对称噪声标签的评估

竞争者：我们使用标准交叉熵损失（Standard）作为两个数据集的基线算法。我们比较了Knockoffs-SPR与其他算法，包括Forgetting [67]（使用dropout策略训练网络），Bootstrap [68]（使用bootstrapping训练），Forward Correction [56]（修正损失函数以获得鲁棒模型），Decoupling [69]（使用元更新策略来解耦更新时间和更新方法），MentorNet [12]（使用教师网络帮助训练网络），Co-teaching [11]（使用两个网络相互教学），Co-teaching+ [15]（进一步使用通过不一致性更新策略来改进Co-teaching），IterNLD [52]（使用迭代更新策略），RoG [53]（使用生成的分类器），PENCIL [60]（使用概率噪声校正策略），GCE[7]和SL[8]（标准交叉熵损失函数的扩展），以及TopoFilter [18]（使用特征表示来检测噪声数据）。对于每个数据集，所有实验都使用相同的骨架网络进行，以进行公平比较。我们对每个数据集随机生成噪声标签进行了五次实验，并计算了最后一个周期准确率的平均值和标准差。竞争者的结果在[18]中报告。

如表I所示，Knockoffs-SPR在CIFAR上相比其他竞争者享有更高的性能，验证了Knockoffs-SPR在不同噪声场景下的有效性。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/bfab9c6cd5484ceb8e085c3e1df40229.png#pic_ center" width="70%" />
</div>

SPR在CIFAR-100上更高的对称噪声率下表现更好。这可能归因于手动选择数据的50%作为阈值。然后SPR将选择更多的数据，例如在Sym. 80%噪声场景中，SPR将选择24816个干净数据，而Knockoffs-SPR将选择18185个。这导致了更好的干净数据恢复（召回率为94.22%，而Knockoffs-SPR为81.20%）以及更好的识别能力。

## B. 在真实世界噪声数据集上的评估

在这部分中，我们在真实世界噪声数据集WebVision和Clothing1M上比较了Knockoffs-SPR与其他方法。我们遵循先前的工作，在WebVision的前50个类别上进行训练和测试。我们还评估了在WebVision上训练的模型在ILSVRC12上的跨数据集准确性。

竞争者：对于WebVision，我们与使用交叉熵损失（CE）训练的CE、Decoupling [69]、D2L [70]、MentorNet [12]、Co-teaching [11]、Iterative-CV [13]和DivideMix [50]进行比较。对于Clothing1M，我们与Fcorrection [56]、M-correction [57]、Joint-Optim [49]、MetaCleaner [71]、Meta-Learning [72]、P-correction [60]、TopoFilter [18]和DivideMix [50]进行比较。

真实世界数据集的结果在表II和III中显示，竞争者的结果在[50]中报告。我们的算法Knockoffs-SPR在几乎所有竞争者中享有优越的性能，显示了处理真实世界挑战的能力。与SPR相比，Knockoffs-SPR也实现了更好的性能，表明了在现实世界中学习噪声标签问题的FSR控制在实际应用中的益处。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/72fd4908ed154bd59c4c646f8d9c53e3.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/cc8d4a0fd5c7444982b992a3f2bf1e8d.png#pic_ center" width="70%" />
</div>

## C. 样本选择质量的评估

为了测试Knockoffs-SPR是否带来了更好的样本选择质量，我们在CIFAR-10上测试了不同的噪声场景下的以下统计数据，包括Sym. 40%，Sym. 80%和Asy. 40%。i) FSR：估计的干净数据中错误选定的噪声数据的比例，这是Knockoffs-SPR旨在控制的目标；ii) 召回率：在全部真实干净数据中选定的真实干净数据的比例，这表明了样本选择算法的能力；iii) F1分数：精确度（1-FSR）和召回率的调和平均值，它衡量了FSR控制和能力平衡的性能。我们在图3中绘制了每个算法沿训练周期的相应统计数据。我们进一步可视化了Knockoffs-SPR估计的FSR，q，以与真实FSR进行比较。由于我们使用了分割算法，其中每个小块包含10个类别，每个类别包含数据的一个子集，我们估计每个小块的FSR，并报告它们的平均值和标准差。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/8d6965954cb34b1496c2ce6ab8ef924d.png#pic_ center" width="70%" />
</div>

图3. 在不同噪声场景下CIFAR 10上沿训练路径的样本选择性能(%)比较。在FSR中，我们还可视化了Knockoffs-SPR估计的FSR（q），这是我们用于选择干净数据的阈值。

FSR控制实践：i) 当噪声率不高时，例如在Sym. 40%和Asy. 40%场景中，真实FSR很好地被估计的FSR上界限制（不超过一个标准差）。当噪声率高时，例如在Sym. 80%噪声场景中，FSR在早期阶段不能得到控制。然而，随着训练的进行，FSR可以很好地被Knockoffs-SPR限制，表明样本选择和网络训练之间的循环正确地进化了。

ii) 当训练集不是很嘈杂时，例如在Sym. 40%场景中，真实的FSR远低于估计的q。这种差距可以由小噪声率下的良好β估计来解释。当 $\hat{\beta}_ 1$ 能够准确估计 $\beta^\*$ 时，(15)中的 $\tilde{\gamma}^\*_ {2,j}$ 占主导地位。因此， $P(W_ j > 0|\tilde{y}_ {2,j} \text{ is clean}) > 1/2$ ，使得  $P(W_ j > 0) > 1/2 > \frac{c-2}{2(c-1)}$ 。由于真实的FSR界限与 $P(W_ j > 0)$ 成反比（FSR ∝ max $_ {j \in C_ c} 1/P(W_ j > 0) - 1$ ），它比理论界限q小。

样本选择质量比较：我们比较了Knockoffs-SPR与SPR和TopoFilter [18]的样本选择质量。i) Knockoffs-SPR在所有噪声场景中几乎拥有最佳的FSR控制能力，特别是在高噪声率设置中。其他算法可能无法控制FSR（例如在Sym. 80%场景中）。ii) Knockoffs-SPR的能力与Sym. 40%和Asy. 40%场景中的最佳算法相当。对于Sym. 80%案例，Knockoffs-SPR为了FSR控制牺牲了一些能力。iii) Knockoffs-SPR在样本选择质量的F1分数上拥有最佳表现，这很好地证明了其在控制FSR的同时选择干净数据的优越性。

值得注意的是，SPR算法具有显著的理论性质，允许我们在特定条件下识别所有噪声数据。然而，一个主要的缺点在于我们无法事先访问这些条件是否会成立，以及由于训练数据集的未知噪声率，我们无法确定适当的选择比例。在实际应用中，我们通常将SPR的选择比例设置为50%。当实际噪声率接近这个比例时，我们观察到出色的选择性能和有效的FSR控制，表明在大多数情况下理论条件得到满足。相反，当噪声率显著偏离选择比时，SPR可能导致高FSR。在这种情况下，我们新提出的方法Knockoff SPR证明了FSR控制的显著改进，正如Sym中所验证的那样-80%设置如图3所示。

## D. 进一步分析

Knockoffs-SPR策略的影响：我们将Knockoffs-SPR与几种变体进行比较，包括：SPR（原始SPR算法）、\*-random（使用随机排列标签的Knockoffs-SPR）、\*-multi（没有类别特定选择的Knockoffs-SPR）、\*-noPCA（没有使用PCA预处理特征的Knockoffs-SPR）和\*-NN（直接使用额外的线性层来降低特征维度的Knockoffs-SPR）。实验在CIFAR-10上进行，噪声场景不同，如表IV所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/4b4d8bfd03f0457db4b75048d708e97a.png#pic_ center" width="70%" />
</div>

我们观察到以下结果：

i) 如图3所示，SPR可以在Sym. 40%和Asy. 40%中控制FSR，但在Sym. 80%中失败。这可能是因为当噪声模式不明显时，噪声样本和干净样本之间的共线性较弱，如附录图1中的irrepresentable值的分布 $\{ \|(X^T_ S X_ S)^{-1} X^T_ S X_ j \|_ 1 \}_ {j \in \mathcal{S}_ c}$ 所示。

在这种情况下，解路径中较早（较晚）选择的样本倾向于是噪声（干净）样本。当存在强烈的多重共线性并且irrepresentable条件被严重违反时，我们提出的Knockoff过程可以帮助控制FSR。Knockoffs-SPR比SPR的准确度更高，可以通过样本选择能力的F1分数的一致性改进来解释，如图3所示。

ii)与随机排列策略相比，使用最有信心排列的Knockoffs-SPR在Sym. 40%和Asy. 40%噪声场景中拥有更好的FSR控制，并且工作得更好。在Sym. 80%噪声场景中，准确度是可比的，但最有信心的排列仍然拥有更好的FSR控制。这个结果从实证上证明了最有信心排列优于随机排列。

iii)分别对每个类别运行Knockoffs-SPR有助于FSR控制能力和识别能力。当噪声率高时，例如在Sym. 80%噪声场景中，通过多个类别运行Knockoffs-SPR不能通过q正确控制FSR。

iv)使用PCA预处理特征在所有情况下都有助于FSR控制，并在某些情况下会增加识别能力，特别是当噪声率高时。

v)我们可以在网络内引入一个额外的线性层来降低特征维度。这种方法在处理中等噪声场景时与使用PCA时的结果类似。然而，在高噪声场景中，它会导致FSR控制和识别能力的降低。这一观察突出了PCA作为Knockoffs-SPR降维技术的鲁棒性。此外，它将Knockoffs-SPR定位为一个易于集成的样本选择模块，适用于各种学习框架，无需修改。

可扩展性的影响：在我们的框架中，我们提出了一个分割算法，将整个训练集分成小块，以便并行运行Knockoffs-SPR。在这部分中，我们比较了使用分割算法和不使用它的运行时间。结果如表V所示。我们可以看到，分割算法可以显著减少计算时间。这在大规模应用中很重要。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/8391553f9f06493b8b78454f0df01b15.png#pic_ center" width="70%" />
</div>

虽然对整个训练数据应用Knockoffs-SPR是不切实际的，但我们对其在小块上的能力进行了分析。

i)多数干净假设的破坏：由于我们的采样策略，我们可能无法保证干净数据在每个小块中始终占多数。然而，这种偏差并不破坏我们的样本选择过程的完整性。
(1)由于我们对分割采用均匀数据采样，违反多数干净假设的小块只占少数。即使我们的算法在这些小块中遇到挑战，它只影响少数训练数据。因此，当考虑跨小块的预期性能时，FSR仍然受到控制。有关说明性示例，请参见图3中q的平均值和标准差。此外，由于我们在每个训练周期中采用随机数据洗牌，错误选择的数据影响有限。
(2)随着训练的进展，特征与真实标签之间的线性关系加强，这通过随时间提高的测试准确率得到证明。因此，即使在特定小块中干净数据不是多数，这种线性关系也可以持续存在，这可以减轻具有挑战性案例的影响。

ii)FSR控制能力：我们评估了两个关键因素对FSR控制能力的影响，即每个组中的类别数量和每个类别中的样本数量。关于类别数量，注意我们有 $P(W_ j > 0 | \gamma_ j^\* = 0) = \frac{1}{2} \cdot \frac{c-2}{c-1} + \kappa_ j \cdot \frac{1}{c-1}$ 。由于 $\kappa_ j$ 通常可以大于1/2，因为噪声标签倾向于比干净标签不可信，较小的c倾向于使 $W_ j < 0$ 的概率较小。因此，对于任何t，集合 $\{j : 0 < W_ j \leq t\}$ 的数目趋于较大，而 $\{j : -t \leq W_ j < 0\}$ 的数目趋于较小，导致T为零，从而清洁集为空，如果q太小。这意味着我们需要一个更大的q值来使清洁集非空。这样的较大q值可能导致更高的FSR。此外，每个类别中更多的样本可以改善 $\hat{\beta}$ 的估计，有利于Knockoffs-SPR的FSR控制能力。总的来说，更多的类别数量和每个类别中更多的样本提高性能。为了验证这些原则，我们在CIFAR-10上进行了不同噪声场景下的实验。为了确保可比性，我们在所有实验中使用相同的自监督预训练主干，只在每个组中的类别数量和每个小块中的样本数量上有所不同。结果如图4所示，清楚地表明更多的类别数量和每个小块中更多的样本导致更低的FSR。在实践中，我们通常将每个组中的类别数量设置为10，每个类别中的样本数量设置为75，以硬件限制为指导。如果更多的计算资源或更有效的算法变得可用，这些超参数可以增加，我们将其留作未来研究的潜在途径。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/ab89c8138227481c8e0f776705d4be49.png#pic_ center" width="70%" />
</div>

网络训练策略的影响：为了更好地训练网络，我们采用了自监督预训练主干和半监督学习框架，以及EMA更新模型。在这部分中，我们在CIFAR-10上测试了这些策略在不同噪声场景下的影响。具体来说，我们将完整框架与Knockoffs-SPR - Self（使用随机初始化的主干）、Knockoffs-SPR - Semi（使用监督训练）和Knockoffs-SPR - EMA（不使用EMA更新模型）进行了比较。结果总结在表VI中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/2b938a680fcd4208942b95e052f3d937.png#pic_ center" width="70%" />
</div>

我们可以发现：
i) 自监督预训练对于高噪声率场景很重要，而在其他设置中，它不是那么重要；
ii) 半监督训练持续提高识别能力，表明利用噪声数据的支持是有用的；
iii) EMA模型将略微提高识别能力。

定性可视化：我们在图5中随机可视化了一些CIFAR-10的错误选择实例。大多数这些案例都具有一些模式，这些模式混淆了噪声标签和真实标签，从而使Knockoffs-SPR错误地将它们识别为干净样本。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/b522051af832449ba2075bdbcbdd08ef.png#pic_ center" width="70%" />
</div>

# VII. 结论

本文提出了一个统计样本选择框架——可扩展的惩罚回归与Knockoff过滤器（Knockoffs-SPR），以控制假选择率选择干净数据。具体来说，我们提出了一个等价的留一法t检验方法作为惩罚线性模型，在该模型中，零均值偏移参数可以被诱导作为干净数据的指标。我们提出了一个精致的Knockoffs-SPR算法，以一种用户指定的上限控制假选择率的方式来识别干净样本。这样的上限在理论上得到了证明，并且在实证结果中表现良好。在几个合成和真实世界数据集上的实验表明了Knockoff-SPR的有效性。
# 声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
