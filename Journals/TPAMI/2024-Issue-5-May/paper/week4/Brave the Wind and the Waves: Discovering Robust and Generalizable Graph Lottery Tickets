# 题目：[Brave the Wind and the Waves: Discovering Robust and Generalizable Graph Lottery Tickets](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10356750)  
## 乘风破浪：发现稳健且具有泛化能力的图彩票
**作者：Kun Wang； Yuxuan Liang；Xinglin Li；Guohao Li；Bernard Ghanem；Roger Zimmermann；Zhengyang Zhou；Huahui Yi；Yudong Zhang；Yang Wang** 

****
# 摘要
当图神经网络（GNN）扩展到大规模图时，其训练和推理的成本非常高。图彩票（GLT）首次尝试通过联合剪枝图结构和模型权重来加速大规模图上的GNN推理。尽管前景看好，但GLT在实际应用中遇到了稳健性和泛化问题，这也是深度学习理念中长期存在的重要问题。在实际场景中，未见测试数据的分布通常是多样的。我们将分布外（OOD）数据上的失败归因于无法识别因果模式，这些模式在分布变化中保持稳定。在传统稀疏图学习中，当图/网络稀疏性超过某个高水平时，模型性能会急剧下降。更糟糕的是，剪枝后的GNN由于训练集有限，很难泛化到未见的图数据。为了解决这些问题，我们提出了稳健图彩票（RGLT），以在GNN中找到更稳健和更具有泛化能力的GLT。

具体而言，我们在每个剪枝点通过瞬时梯度信息重新激活一部分权重/边。在充分剪枝之后，我们进行环境干预以外推潜在的测试分布。最后，我们进行最后几轮的模型平均化，以进一步提高泛化能力。我们提供了多个实例和理论分析，以支持我们提案的普遍性和可靠性。此外，RGLT已经在各种独立同分布（IID）和分布外（OOD）图基准上得到了实验验证。

# 关键词
- 深度学习
- 图卷积网络
- 彩票假说
- 节点分类
- 分布外泛化


## I. 引言

图神经网络（GNN）在各种图学习任务中表现出巨大的潜力。GNN的成功主要源于其强大的局部感知能力，即消息传递，其中每个节点通过聚合其邻居的信息来更新其表示。然而，当GNN扩展到具有密集连接的大规模图时，计算成本是不可承受的，这大大限制了它们的实际应用。特别是，随着过去几年图规模（从数百万到数十亿节点）的显著增长，GNN在模型训练和推理过程中经历了巨大的计算开销。

处理大规模图的研究主要有两个方向，一是简化图，二是压缩GNN模型。在第一个方向中，提出了各种图采样策略或稀疏化方法，以减轻消息传递的计算负担。相反，关于第二个方向，即剪枝GNN，的研究相对较少，因为与其他领域的深度神经网络（DNN）相比，GNN的参数通常较少，例如计算机视觉领域。

最近，图彩票假说（GLT）首次统一了上述两个研究方向。简而言之，GLT旨在在GNN中识别一个图彩票，即一个具有出色性能的核心子图和稀疏子网络的组合，以加速GNN的训练和推理。这一假说受到彩票假说（LTH）的启发，后者表明在随机初始化的稠密网络中存在稀疏但出色的子网络，就像彩票池中的中奖票一样。为了在GNN中发现这些中奖票，GLT设计了一种统一的GNN稀疏化（UGS）方法，通过可微掩蔽机制同时且迭代地剪枝输入图和网络权重。


![](https://img-blog.csdnimg.cn/direct/9e39325a11e4479782db089c0c35e819.png)



尽管很有吸引力，GLT仍有很多改进空间，尤其是在以下两种情况下：
- 稳健性丧失：在GLT中，当图（或网络）稀疏性达到某个水平（例如，超过70%）时，GNN的性能会急剧下降。概念上，GLT通过基于幅度的剪枝来识别“幸运”的图彩票，这可以看作是极化剪枝，而不会为中等幅度的权重或边在后续训练中留下余地。在高稀疏性下，模型难以探索整个权重空间，并且由于稀疏性约束，模型更新路径被切断。
- 泛化能力丧失：分布外（OOD）数据在实际世界中普遍存在。训练数据集可能无法代表在实际数据中可能遇到的所有变化。此外，由于各种因素，如时间变化、趋势演变或数据获取过程的变化，输入数据可能会发生变化。对于图数据，从全图到子图的分布变化通常有助于揭示因果模式，并丢弃暂时的、非必要的成分，如节点度分布和领域特定约束。

在图1中，我们用一个实际实例说明了我们的理念。红框中标注的有毒子结构醌亚胺，表示为 $C_6H_4ON^-$，在各种情景中保持一致，决定了分子的毒性。同样值得注意的是，含有醌亚胺毒性结构的分子可能在边、节点或连接上存在差异。网络剪枝（例如LTH，GLT）被认为是一种不仅可以减轻深度网络计算成本，还可以防止过拟合的强大工具。然而，在图上进行剪枝可能会降低模型的泛化能力，因为GNN与深度学习网络（例如卷积神经网络）一样，数据需求量很大。此外，已发现一种相反的现象——在超稀疏和一些中等稀疏现象下，网络剪枝有时甚至会降低泛化能力。这一意外问题使GLT在具有多样化样本和实例的实际应用中变得复杂。



![](https://img-blog.csdnimg.cn/direct/6d90a70ef62e4bfbbf2b08d53a1d89ce.png)



实际上，GLT在部署过程中会遭遇稳健性和泛化能力的丧失，这两个棘手的问题严重阻碍了模型的最终落地。具体而言，稳健性确保系统的安全性，使其在各种训练数据下不会出现严重抖动。泛化能力使模型能够在有限的训练数据下外推潜在的测试分布，确保模型的稳定性。这两个挑战限制了稀疏GNN在大规模数据集上的表示能力。在本文中，我们旨在在学习图彩票中乘风（即高稀疏性）破浪（即泛化能力），释放GNN在实际使用中的全部潜力。具体而言，我们提出了一个联合学习框架，其中包含两个算法：a）稳健彩票搜索（LoRS）以增强在高稀疏性下的稳健性，b）彩票图干预（LoGI）以增强在未见数据上的泛化能力。与GLT相比，通过共同提高GNN的稳健性和泛化能力，我们构建了更具弹性的图彩票。因此，我们将集成LoRS和LoGI的框架称为稳健图彩票（RGLT）。

首先，我们从在训练DNN时常见的基于梯度优化的重启技术中汲取灵感，并引入LoRS以发现稳健的图彩票。以带有温重启的随机梯度下降（SGDR）为例，如图2（a）所示。在每次迭代中（例如10个周期），SGDR逐渐降低学习率以找到局部最小值，并最终执行重启以在陷入陡峭低谷时从一个局部最小值跳到另一个。在每一轮RGLT中，我们同样剪枝具有最低幅度的一部分权重/边，然后通过具有最大梯度的前k名重新激活被丢弃的权重/边，如图2（b）所示。通过这种方式，我们使所有权重/边都有机会再次“证明”自己，并使图彩票能够在每次迭代结束时从局部最优中逃脱，从而在高稀疏性约束下实现更稳健的结果。

有趣的是，目前的一些动态稀疏训练算法具有类似于我们的过程。例如，RigL和ITOP等技术从随机稀疏网络开始，并在训练期间不断探索稀疏连接性，以弥合稀疏训练和密集训练之间的差距。然而，这些方法主要集中在权重剪枝上，而没有深入研究图数据的复杂性。我们的LoRS在图剪枝领域迈出了初步的步伐。通过采用迭代剪枝和重新激活策略，我们仔细识别了最终聚合中最重要的邻接矩阵元素。这个方向成为了具有轻量级存储图的动态稀疏训练的基石。

我们的第二个创新是从因果角度提高剪枝GNN的泛化能力，我们将发现大图中的核心子图与识别复杂数据中的因果模式类比。在这种因果假设下，全图的剪枝边作为保留边和预测之间的混淆变量（也称为环境），而获得的子图可以看作是原始图的基本原理，有助于决策。为了找到核心子图，我们通过继承不变图学习技术提出了LoGI。我们的关键思想是对原始图进行干预以生成多样的环境，鼓励模型探索训练集之外的未见分布。之后，我们最小化干预环境上的损失和方差，以推动模型在实际应用中的更好泛化。从本质上讲，我们的LoGI可以看作是子图稀疏性和测试性能的联合优化器。

总之，本文的贡献如下：
1. 我们设计了一种新颖的稳健图彩票方法，以找到稳健且具有泛化能力的图彩票。
2. 我们提供了关于不变因果学习和权重更新计划的理论和直观分析，以保证RGLT的优越性和卓越性。
3. 我们进行了广泛的实验，评估了我们的RGLT在各种GNN架构中的表现。它实现了5% ∼ 15%的稀疏性增益，同时在多个基准上大幅超越了之前的方法。




## III. 方法
图3展示了我们框架的流程。首先，我们执行稳健彩票搜索（LoRS）以生成稀疏网络和图的组合。在每次迭代中，我们根据其幅度剪枝边和权重，然后重新激活具有最大梯度的前k个权重。之后，我们在核心子图上利用彩票图干预（LoGI）来外推测试分布，并将增强的图传递给剪枝后的模型进行下一轮训练。在最后几轮中，我们进行模型平均化以进一步提高模型的泛化能力。值得注意的是，LoRS可以独立运行以发现稳健的图彩票，而LoGI算法依赖于LoRS识别的核心子图。我们提出的两个算法共同作用，以促进大规模GNN应用的落地。



![](https://img-blog.csdnimg.cn/direct/4267bd8daa4442ebb1abdcc5dce8f422.png)


### A. 问题描述
给定一个无向图 $G = \{V, E\}$，节点为 $V$，边为 $E$，GNN旨在根据节点特征 $X \in \mathbb{R}^{|V| \times F}$ 和邻接矩阵 $A \in \mathbb{R}^{|V| \times |V|}$ 学习每个节点的表示向量。例如，提出一个具有可训练参数 $\Theta = \{\Theta^{(0)}, \Theta^{(1)}\}$ 的两层GNN用于节点分类：

$$
Z = S \left( \hat{A} \sigma \left( \hat{A} X \Theta^{(0)} \right) \Theta^{(1)} \right),
$$

其中 $Z$ 是GNN的预测； $\sigma(\cdot)$ 表示激活函数。 $\hat{A}$ 是从 $A$ 中归一化得到的带自环的邻接矩阵。为了训练这个GNN，我们最小化所有标记节点的交叉熵损失：

$$
L (G, Y) = -\sum_{v \in \text{train}\{V\}} y_v \log (z_v),
$$

其中 $z_v$ 和 $y_v$ 表示节点 $v$ 的预测和标签。 $\text{train}\{V\}$ 表示训练节点集。在本文中，我们致力于解决一个更具挑战性的问题，即在高网络稀疏性和有限训练数据的情况下提高我们模型的泛化能力。假设 $S$ 是环境的支持， $f(\cdot)$ 是预测函数，我们的目标是在不同数据分布下最小化经验风险：

$$
\min_{f} \max_{e \in S} \mathbb{E}_{(G, Y) \sim p(G, Y | e)} [L (f (G), Y) | e].
$$

由于训练环境不足和未见的测试分布，这个问题很难解决。

### B. 稳健彩票搜索（LoRS）
寻找稳健彩票：为了解决GLT的高稀疏性问题，我们理想地将SGDR的“温重启”策略推广，并在每个更新点（即剪枝点）同时重新激活图边和权重，通过使用梯度信息。如算法1所示，LoRS由三个步骤组成：

1. 初始化：我们随机初始化一个GNN模型，并采用两个可微掩码 $m_g$ 和 $m_\theta$ 来表示边和权重的重要性分数。
2. 更新策略（剪枝和重新激活）：我们将幅度最低的边和权重剪枝，通过在每 $Q$ 迭代后将掩码中的相应条目设为0（见第1-9行）。剪枝后，我们通过使用一个top-k函数，即 $\text{ArgTopk}_ {i \notin \Theta_{M/Iact}}(|\nabla_{\Theta_{M}} L(G, \Theta)|, k)$ 将零元素的一部分重置为1，以重新激活具有最大梯度的丢弃权重或边（见第10行），其中 $\Theta_{M/Iact}$ 是两个可训练掩码中仍为1的元素。 $\text{ArgTopk}(v, k)$ 表示向量 $v$ 的前k个元素。
3. 停止：我们重复更新计划，直到达到期望的稀疏性 $s_g$ 和 $s_\theta$（假设 $K$ 次迭代）（见第1-13行的循环）。

修改的更新策略：我们进一步提出了一个新的更新函数 $\text{Pro}_ {i \notin \Theta_{M/Iact}} N (|\nabla_{\Theta_{M}} L (G, \Theta)|)$，以在掩码中重新激活零元素，其中我们对梯度的绝对值进行极小-极大归一化 $N(\cdot)$，并以概率方式激活相应的位置。与使用最大梯度元素的硬选择不同，这种方式也给一些小梯度的条目一个机会，让它们参与到下一轮训练中，使训练更加弹性。值得注意的是，LoRS可以被视为识别稳健图彩票的独立插件。

### C. 彩票图干预（LoGI）
我们将GLT的令人沮丧的泛化归因于有限的环境来感知训练集外的数据分布。受目前流行的不变因果图学习的启发，我们旨在识别对图至关重要的因果模式。之后，我们对补充子结构（即环境）添加扰动，以提高模型在未见环境中的外推能力。在这里，我们做了两个基本假设：
1. 基于迭代剪枝发现的子图可以视为因果模式。
2. 原始图的一部分可以表示为混淆变量或环境，我们可以对其进行干预，以构建不同的环境，以提高在未见数据上的泛化能力。


![](https://img-blog.csdnimg.cn/direct/481eaa82f1724b4da1fd1572e9bcea8a.png)



然而，上述定义在大多数情况下没有意义，因为在节点级预测任务中，通常只有一个输入图，包含大量的节点或链接。感谢EERM，它为有限训练图提供了探索多个虚拟环境的合理解决方案，我们提出了彩票图干预（LoGI）方案，以提高最终获得的子网络的泛化能力。LoGI计划基于以下术语定义：
1. 自我图 $G_v$：节点 $v$ 及其 $L$ 跳邻居 $N_v$ 作为自我图 $G_v$；
2. 自我特征： $X_v = \{x_u | u \in N_v\}$；
3. 自我邻接矩阵： $A_v = \{a_{uw} | u, w \in N_v\}$。

剖析上述定义，我们可以将整个图分割为一组实例 $\{(G_v, y_v)\}_ {v \in V}$，其中 $y_v$ 是节点 $v$ 的标签。当给定 $G_v$ 时，它独立于图中的其他节点，我们可以获得条件分布 $p(Y | G, e) = \prod_{v \in V} p(y | G_v, e)$。


![](https://img-blog.csdnimg.cn/direct/3e4e02bbda7c45aeadf4544999809a57.png)



#### 泛化问题的正式定义
考虑到上述努力和（3），我们将图链接或节点级OOD预测任务正式定义为：给定训练数据 $\{(G_v, y_v)\}_ {v \in V}$ 来自 $p(Y | G, e)$，我们的目标是最小化来自 $p(Y | G, e')$ 的测试数据 $\{(G_v, y_v)\}_{v \in V'}$ 上的经验风险。因此，我们可以将（3）重写为：

$$
\min_{f} \max_{e \in S} \mathbb{E}_ {(G, Y) \sim p(G, Y | e)} \left[ \frac{1}{|V|} \sum_{v \in V} \mathbb{E}_{y \sim p(y | G_v, e)} [l (f (G_v), y)] \right]
$$

这里我们主要关注最常见的情况，即单个输入图包含密集连接。多图场景不在我们的研究范围内。

#### 分布干预者
一旦我们获得了核心子网络和子图，我们就对图的琐碎部分进行环境干预，以形成多样的环境，从而提高泛化能力。具体而言，我们引入环境生成器，从训练分布中构建一些模拟环境。我们鼓励模型捕捉每个自我图中的因果特征，并在这样的虚拟环境中缓解虚假关联。我们认为，虚假关联在节点分类任务（或链接预测任务）中普遍存在，并且节点的局部结构可能存在差异，例如，节点邻居的标签可能不同。遵循EERM，我们在这里给出一个正式定义。

**定义1. （自我图中的因果性）：** 假设输入特征 $G_v$ 的维度为 $d_0$，我们希望学习一个映射函数 $y_v = f_\theta(G_v)$，它可以从 $G_v$ 学习到一个对环境不变的表示 $z_v$。然后我们将 $z_v$ 视为因果部分，并且 $z_v$ 满足：
1. 不变性条件：给定任何环境 $e$，分类器给出的预测分布保持不变，即 $p(y_v | z_v, e) = p(y_v | z_v)$。
2. 充分性条件：表示 $z_v$ 包含足够的信息来预测标签 $y_v$，即存在一个投影函数 $\phi$ 满足 $y_v = \phi(z_v) + n$，其中 $n$ 是独立噪声。

此外，我们展示了一个与节点级因果性相关的例子。如图4所示，存在一个引用网络，其中 $x_1 \to y$ 表示一个论文的发表途径是决定论文子领域的不变特征。 $y \to x_2$ 表示论文的影响力（引用指数）通常与论文的子领域有关。 $e \to x_2$ 表示论文的引用指数也与论文发表的时间有关（研究方向的流行度会随时间变化）。在这个例子中， $x_2$ 会同时与 $y$ 和 $e$ 相关。换句话说，当环境改变时， $x_2$ 和 $y$ 之间的关系也会改变。因此，如果模型在训练集上学习了这部分相关性，当它迁移到测试集时，无法获得满意的结果（因为环境的变化导致 $x_2$ 和 $x_1$ 之间的关系发生变化）。相反，如果模型在训练集上学习了 $x_1$ 和 $y$ 之间的关系，即使环境发生变化，这种关系也是稳定的。第二个实例表明，我们应该教模型在各种环境中学习不变的关系。

然后我们提出我们的节点级干预方案——我们在剪枝后的图上随机添加边，使用函数 $-\text{Pro}_ {i \notin m_g} N(|\nabla_{m_g} L(G, \Theta)|)$ 在 $K$ 次迭代结束时添加。类似于之前的修改更新策略， $\text{Pro}$ 表示以概率方式添加边。值得注意的是，这一过程适用于邻接矩阵掩码 $m_g$ 中的所有元素。在我们的实现中，增强不包含删除边操作，因为我们选择的核心子图（从因果角度称为基本原理）已经包含最小数量的边。



![](https://img-blog.csdnimg.cn/direct/e4409167149441c78dd8540391e1847b.png)




**从因果角度的理论分析：** 我们提出的分布干预者对原始图进行EI，以模拟多样的环境，这也可以与因果理论中的do-calculus操作相关联。为了从理论上验证我们的方法，我们从因果角度呈现了我们操作的基本原理，这里我们采用了表征变量之间因果关系的结构因果模型（SCM）。

如图5所示，假设 $G_i$ 表示输入自我图， $C_i$ 是 $G_i$ 的关键子集，由LoRS识别，并最能指导模型预测。 $S_i$ 是环境或混淆变量，可能会打开 $C_i$ 和预测 $\hat{Y_i}$ 之间的后门路径。我们的目标是屏蔽GNN模型免受 $S_i$ 的影响，并赋予模型外推能力。我们可以通过分析 $P_m(\hat{Y_i} | C_i) = P(\hat{Y_i} | \text{do}(C_i))$ 利用 $C_i$ 上的do-calculus 来消除后门路径。具体来说，我们可以通过以下方程探索自我图中的因果性：

$$
P(\hat{Y_i} | \text{do}(C_i)) = P_m(\hat{Y_i} | C_i) = \sum_{S_i \in T_i} P_m(\hat{Y_i} | C_i, S_i) P_m(S_i | C_i) = \sum_{S_i \in T_i} P(\hat{Y_i} | C_i, S_i) P(S_i)
$$

这里 $T_i$ 表示自我图 $G_i$ 的混淆变量集合。第二个等式是因为贝叶斯规则。第三个等式是因为在因果干预下 $C_i$ 和 $S_i$ 是独立的（即 $P_m(S_i | C_i) = P_m(S_i) = P(S_i)$）。方程5也称为后门调整，它是一种消除混淆效应的特殊工具。考虑到真实场景中图的结构复杂多变，如图4所示，通过固定核心子结构并探索环境部分的结构，我们可以提高模型在分布外场景中的表达能力，这个过程可以被视为结构级别上的后门调整。从超越后门调整的角度来看，我们只对最具干扰性的环境进行采样，以提高训练效率，这些干扰性环境可以帮助我们的模型在更真实的场景中良好运行。

**环境干预（EI）与后门调整：** 我们的EI操作可以被视为后门调整机制和训练效率之间的折衷。理想情况下，后门调整可以探索数据的所有潜在测试分布。然而，在真实场景中，后门调整机制的一个显著限制是环境的高复杂性。例如，假设一个图的环境部分有200个节点，它可能导致 $2^{200}$ 环境可能性。对于真实场景训练来说，这种计算规模是不可行的，导致巨大的计算资源消耗。此外，由于我们的测试数据集是有限的，过度的环境增强可能会产生过于庞大的模拟测试分布。一些细微的分布变化可能不会显著影响结果。鉴于这些挑战，我们的EI选择性地采用最具干扰性的数据增强，以提高其稳健性和泛化能力。

**环境多样性：** 我们鼓励模型在一定范围内探索尽可能多样和复杂的环境。这里我们设置边的添加比例在一个小范围内，并将其作为一个正则化项来控制环境干扰，因为分布干预者倾向于添加更多的边。此外，我们需要使用一个距离度量来校准训练分布 $P_{\text{tr}}$ 和生成分布 $P_{\text{gen}}$。根据之前的研究，表示空间中的距离通常对应于语义距离。因此，我们在表示空间中定义了成本函数，并给出了以下运输成本： $c(P_{\text{tr}}, P_{\text{gen}}) = ||h(P_{\text{tr}}) - h(P_{\text{gen}})||_2^2$，其中 $h$ 表示嵌入表示的隐藏层，将数据（训练数据或生成数据）输入剪枝后的GNN（训练 $K$ 次迭代）。为了获得多样的环境，我们提出了数据增强的原则：

**原则1：** 给定图 $G$ 中所有自我图 $G_v$ 的分布 $P$，设 $T(\ast)$ 表示一个增强函数，将图 $\{T(G)\}$ 增强到分布 $P̃$。然后我们鼓励 $c(P_{\text{tr}}, P_{\text{gen}})$ 尽可能大，在固定比例 $p\%$ 的添加边的情况下。

原则1中的比例 $p\%$ 可以被视为限制扰动的正则化项。为了实现这一原则，我们首先采用分布干预者策略生成 $\psi$ 增强图 $G̃ = \{G̃_1, G̃_2 . . . G̃_\psi\}$，并挑选出距离原始图最远的 $S$ 图（通过运输成本函数测量）。然后我们将这些图传递给剪枝后的GNN进行进一步训练。在下一轮训练中，我们不会丢弃模型参数，并在最后几轮权重中采用随机权重平均，以找到一个更稳健的模型泛化中心点。


![](https://img-blog.csdnimg.cn/direct/56dbefec2cc14dda84036e9ad840b28c.png)




在我们的框架内，EI在给定指定扰动比例的情况下，促使模型深入到复杂的环境中。我们利用已训练的GNN隐藏层的输出作为距离测量手段。这种整合不会干扰模型的当前训练阶段。相反，它会暂时暂停，让并行GNN完成其环境评估，然后继续。这整个过程提供了一个流畅的端到端体验。

### D. 稳健图彩票（RGLT）
我们结合稳健彩票学习（LoRS）和彩票图干预（LoGI）形成了稳健图彩票（RGLT）框架，改进了图彩票的稳健性和泛化能力。我们的RGLT框架还可以解释为加速野外GNN应用的多功能优化器。为了在各种干预分布上实现风险最小化，我们提出了RGLT的原则2，以识别其与标签关系在不同分布中稳定的稳健彩票图：

**原则2：** 稳健彩票图满足RGLT框架原则，如果它在多样和复杂环境中最小化（1）所有经验风险，并同时最小化（2）这些环境中的方差。

在所提出的原则2的指导下，我们设计了RGLT的学习策略：

$$
\min R_{\text{RGLT}} = \min_{f} \left[ \mathbb{E}_ {e \in (S \cup \sim S)}  l (f (G), Y) \right] + \min_{f} \left[ \eta \cdot \text{Var}_{e \in (S \cup \sim S)} [l (f (G), Y)] \right],
$$

其中 $R_{\text{RGLT}}$ 表示RGLT框架的经验风险， $S \cup \sim S$ 表示训练和增强分布环境集合。 $\text{Var}(\cdot)$ 表示方差， $\eta$ 是超参数。RGLT算法详见算法2。


## IV. 实验
在本节中，我们进行广泛的实验以回答两个关键研究问题（RQ）：
- RQ1：我们提出的彩票可靠性学习（LoRS）算法的效果如何？
- RQ2：RGLT能很好地解决OOD问题吗？环境干预对GNN泛化有多大帮助？
- RQ3：RGLT能在真实世界的图基准上表现良好吗？

### A. 实验设置
**数据集：** 按照GLT，我们采用五个GNN基准来评估我们的RGLT。具体来说，我们选择了三个流行的IID图数据集，包括Cora、Citeseer和PubMed，用于节点分类或链接预测，以及两个大规模图数据集Ogbn-Proteins和Ogbl-Collab，用于节点分类和链接预测。为了进一步检验RGLT处理分布偏移的能力，我们遵循EERM考虑：
1. Cora和Amazon-photo上的人工转化。
2. Twitch-explicit和Facebook-100上的跨域转移。
3. Ogb-Arxiv上的时间演变。

**OOD图的描述：** 我们遵循EERM考虑三种类型的分布偏移。如表I所示，“AT”代表“人工转化”，意味着我们添加合成的虚假特征。“CDT”代表“跨域转移”，意味着数据集中的每个图对应不同的域。“TE”代表“时间演变”，意味着数据集是一个动态的，具有演变性质的。

**人工转化：** 我们选择Cora和Amazon-Photo进行人工转化。在这两个图中，可用的节点特征与节点标签有很强的相关性。为了构建模拟的OOD场景，我们使用提供的节点特征构建节点标签和虚假环境敏感特征。具体来说，以节点特征 $X_1$ 和邻接矩阵为输入，我们利用随机初始化的GNN生成节点标签 $Y$。同时，我们采用一个并行随机初始化的GNN生成虚假节点特征 $X_2$（以 $Y$ 和环境id的连接为输入）。然后，我们将真实节点特征 $X_1$ 和虚假节点特征 $X_2$ 连接起来构建新特征 $X = [X_1, X_2]$，作为训练和评估的输入。在我们的实现中，我们为每个图构建了十个具有不同环境id的图。类似于EERM，我们使用一个图进行训练，一个图进行验证，并报告其余图上的准确性。

**跨域转移：** 图相关数据中的跨域转移在实际中非常普遍。例如，在社交网络中，域可以实例化为网络收集的地点或时间。我们考虑两个最近流行的图数据集Twitch-Explicit和Facebook-100来描述跨域问题。Twitch-Explicit包含七个网络，其中节点表示Twitch用户，边表示它们的相互友谊。每个网络都来自特定区域，包括DE、ENGB、ES、FR、PTBR、RU和TW。统计信息见表II。为了便于比较，我们使用2层GCN和GAT作为Twitch-Explicit图的骨干网络，并训练模型不同策略（即RGLT和EERM）以观察结果。我们在一个图DE上训练模型（类似于EERM实验设置），并报告另一个图ENGB的节点上的最高ROC-AUC。Facebook-100包括来自2005年9月100个美国机构的Facebook网络的完整用户集（节点）及这些用户页面之间的所有“友谊”链接。我们在实验中采用十四个网络：John Hopkins、Caltech、Amherst、Bingham、Duke、Princeton、WashU、Brandeis、Carnegie、Cornell、Yale、Penn、Brown和Texas（与EERM相同）。我们使用Penn、Brown和Texas进行测试，Cornell和Yale进行验证，并使用其余图的三个不同组合进行训练。由于这些图的大小、密度和度分布各不相同，FB-100的实验可以视为跨域OOD问题。

![](https://img-blog.csdnimg.cn/direct/0ad149de18074655b8b71b1fe2544474.png)


![](https://img-blog.csdnimg.cn/direct/7a195fec7cc446d990f6b3f2ac6d247e.png)



**时间演变：** 时间飞逝，现实世界中的时间图会随着时间的推移而动态演变。引用网络经常通过发表新论文进行时间增强。我们采用Ogb-Arxiv进行实验，并通过放大训练数据和测试数据之间的时间差异引入分布偏移：我们选择2011年之前发表的论文进行训练，2011-2014年之间的论文进行验证，2014-2016年、2016-2018年和2018-2020年之间的论文进行测试。这种数据划分方法可以更好地放大挑战，使分布偏移问题更加明显。类似于EERM，我们控制测试节点在训练期间严格未见，以模拟更现实和通用的场景。最后，我们选择GraphSAGE和GPR-GNN作为骨干网络来验证模型性能（准确性）。

**IID骨干网络：** 为了在独立同分布（IID）图上识别图彩票，我们将LoRS算法与GLT和随机剪枝在相同的网络设置下进行比较。具体来说，对于Cora/Citeseer/PubMed数据集，我们采用GCN、GIN和GAT作为骨干网络。对于大规模数据集，例如Ogbl-Collab和Ogbn-Proteins，我们使用28层深的ResGCNs作为链接预测和节点分类的骨干网络。

**OOD骨干网络：** 对于OOD图，我们将RGLT与EERM进行比较，以验证我们提出算法的泛化能力。
1. 对于人工转化的图，我们采用GCN或GAT作为骨干网络，并生成10倍的具有不同环境的图数据。我们使用1:1:8的比例进行训练/验证/测试。
2. 对于跨域转移数据集，我们选择GCN或GAT作为骨干网络。具体来说，对于Twitch-Explicit数据集，我们采用DE图进行训练，ENGB图进行验证，其余五个图（ES、FR、PTBR、RU、TW）进行测试。在FB-100中，我们使用Penn、Brown和Texas进行测试，Cornell和Yale进行验证，并使用其余图的三个不同组合进行训练。
3. 对于Ogb-Arxiv上的时间演变，我们选择GraphSAGE和GPR-GNN，并选择2011年之前发表的论文进行训练，2011-2014年之间的论文进行验证，2014-2016年、2016-2018年和2018-2020年之间的论文进行测试。在本文中，我们还利用了真实世界的比特币交易数据集Elliptic。我们将在IV-G节中详细介绍该数据集的特点并展示相应的结果。

**骨干网络设置：** 对于常规规模的数据集Cora、Citeseer和PubMed，我们采用GCN/GIN/GAT骨干网络进行节点分类和链接预测任务。在我们的实现中，我们分别采用3层GCN、3层GIN和3层GAT。对于Ogbl-Collab的链接预测，我们采用28层ResGCNs。对于OOD图相关数据集，我们在人工转化数据集和跨域转移数据集上采用2层GCN/GAT，并选择2层GraphSAGE/GPR-GNN作为基线。

**超参数配置：** 在IID图中，我们将迭代权重剪枝率设置为0.2，边剪枝率设置为0.05。对于Cora、Citeseer和PubMed，我们将 $\text{pre}\% = 1\%$ 用于通过在每个更新点使用更新计划重新激活零元素。对于Ogbn-Proteins和Ogbl-Collab，我们将 $\text{pre}\% = 1\%$ 用于通过在每个更新点使用更新计划重新激活零元素。在OOD图中，我们在每个更新点重新激活 $\text{pre}\% = 0.005$ 零元素。为了便于理解，我们在补充材料中的表X和表XI中列出了训练细节和超参数配置。

### B. LoRS算法的有效性
为了回答RQ1，我们严格检验了基于梯度的重新激活策略在IID图数据集上的效果。我们将LoRS算法与GLT和随机剪枝Cora/Citeseer/PubMed数据集上的节点分类和链接预测任务上进行比较。在我们的实现中，我们首先控制权重稀疏性为零，反之亦然。结果如图6和图7所示。从这些图中，我们有以下有趣的发现：


![](https://img-blog.csdnimg.cn/direct/99ec1038e70d43faaa2a4762b3cb3ea9.png)

![](https://img-blog.csdnimg.cn/direct/12e96325aee445949f8e2f195e1e498f.png)


- **观察1：** LoRS在所有IID图上的相同图/权重稀疏性下，始终优于GLT和随机剪枝，验证了其卓越的性能。如图6所示，我们可以在接近58%、69%和65%的图稀疏性和95%的权重稀疏性下获得图彩票，这比GLT（图稀疏性提高5% ∼ 10%，权重稀疏性提高5% ∼ 15%）和随机剪枝稀疏得多。这种现象也可以在Cora和PubMed上发现。
- **观察2：** 基于梯度信息的“重新激活”在训练的中后期起着重要作用。在早期阶段重新激活参数不一定会立即产生影响，因为在早期阶段被剪枝的参数并不是很重要，通过梯度信息作为判断条件重新激活的参数在中后期有显著影响。对于多个组合（例如，图6中的Citeseer+GIN、Citeseer+GAT），LoRS在稀疏性增加的中后期显示出上升趋势，这有助于模型找到图彩票。

### C. LoRS的消融研究
**消融研究：** 我们进一步研究了一个更复杂的情况，其中我们控制迭代剪枝率 $p_g$ 或 $p_\theta$ 在一个固定比例下，并观察另一项的不同剪枝率下的模型表现。在这里，我们控制每个曲线包含20轮迭代剪枝。从图8中可以发现，当我们将 $p_g$ 控制在一个小范围内时，更容易找到图彩票，例如 $p_g = 5\%， p_\theta = 10\%$。同时， $p_\theta$ 的值对结果影响不大，并且可以在所有权重剪枝率下找到图彩票。

**扩展LoRS到大规模数据集：** 为了进一步研究我们提出的LoRS在大规模数据集上的有效性，我们使用28层深的ResGCNs进行节点分类（Ogbn-Proteins）和链接预测（Ogbl-Collab）。我们控制 $p_g = 5\%， p_\theta = 20\%$ 并记录在找到图彩票时的图/权重稀疏性在表IV中。结果表明，在没有“重新激活”策略帮助的情况下，发现的图彩票在Ogbn-Proteins上通常带来8.75% ∼ 10.86%的累赘边或权重，在Ogbl-Collab上带来7.96% ∼ 11.43%的累赘。这些结果表明，LoRS是可扩展的，并且可以帮助模型找到比GLT更高稀疏性的图彩票。

### D. RGLT算法的有效性
在本节中，我们验证了我们RGLT的泛化能力。为了进行全面比较，我们考虑了多种真实世界的分布偏移情况，即人工转化、跨域转移和时间演变。

![](https://img-blog.csdnimg.cn/direct/f0b0ff64c8474846bfdbb0747053f872.png)



![](https://img-blog.csdnimg.cn/direct/41200b2110544df891bd12b34564d7c0.png)




![](https://img-blog.csdnimg.cn/direct/403ce8c0416947e98c5444c1cd9e2939.png)




**人工转化：** 我们控制 $p_g = 5\%， p_\theta = 20\%$ 并在Cora（AT）和Amazon-Photo（AT）上进行 $T$ 次剪枝。在这里，我们运行环境干预（RGLT或RGLT-EI）的有无，并将八个增强测试数据集的平均性能与EERM进行比较。我们在图9、图10和表V中报告了结果，从中可以观察到：
- **分布干预器** 可以帮助我们的模型更好地模拟测试集中可能存在的分布，从而提高模型的泛化能力。例如，在图9和图10中，“RGLT”的平均性能显著超越了“RGLT-EI”。
- **RGLT** 在节点级OOD任务上显示出比EERM更好的泛化能力。例如，RGLT在Cora（AT）上超过了EERM 15%，在Amazon-Photo（AT）上超过了EERM 6.80% ∼ 8.96%。
- 有趣的是，由于增强的不可控性，我们观察到在Cora（AT）数据集上，RGLT的性能在某些情况下略逊于RGLT-EI。为了解决这个问题，我们采用了更可控的增强方法。我们用预训练的代理GNN模型替换了之前用于生成标签 $Y$ 的随机GNN，从而增强了生成过程的可控性。然后我们将环境id与这些生成的特征连接，随后与原始特征合并。我们观察到，在八个测试图中，RGLT实现了1.3% ∼ 9.2%的性能提升，没有出现性能下降的迹象。这进一步证明了我们RGLT算法的有效性。


![](https://img-blog.csdnimg.cn/direct/4ca31059e49e44f99e95d8c63ca98669.png)

![](https://img-blog.csdnimg.cn/direct/7aa31905a2d2472da4c5d892c43aa166.png)


![](https://img-blog.csdnimg.cn/direct/18706ea4955b4d758fb2509645faf96c.png)


![](https://img-blog.csdnimg.cn/direct/f6ab3e4c394c42f1891ac23629416296.png)



**跨域转移：** 我们采用了两个公共社交网络Twitch-Explicit和Facebook-100。在Twitch-Explicit中，我们使用DE进行训练，ENGB进行验证，其余五个网络（ES、FR、PTBR、RU、TW）进行测试。如图11所示，RGLT在多个骨干上始终优于EERM，类似的现象也可以在FB-100数据集中发现（表3）。简而言之，这些结果坚定地证明了我们的模型在跨域转移场景中的泛化能力。

**处理时间增强图中的新节点：**我们最后在一个时间评估网络上测试了我们的提案，即一个引文网络，该网络经常通过发表新论文进行时间增强。遵循EERM，我们严格控制归纳设置（测试节点在训练期间不可见），并观察2014-2016年、2016-2018年和2018-2020年三个间隔的性能（表6）。令人惊讶的是，RGLT在所有时间间隔内均优于EERM，验证了我们提案的有效性。值得注意的是，当关闭EI时，RGLT始终出现约5%的性能下降，这进一步支持了我们的分布干预器的重要性。这些实验结果证明了我们的模型在处理时间分布转移方面的能力，强调了RGLT的稳健性。

### E. 超参数 $H$ 和 $\eta$ 的实验
**最终 $H$ 权重的模型平均：** 为了研究 $H$ 对泛化性能的影响，我们将 $p_g, p_\theta$ 控制为0，并观察不同 $H$ 下的模型性能。对于Twitch-Photo数据集，我们选择ES图进行测试。对于Facebook-100图，我们选择“John Hopkins + Caltech + Amherst”组合和Penn进行测试。如表8所示，我们列出以下观察结果：

![](https://img-blog.csdnimg.cn/direct/23f227d4843f47bab3fac4fcd5a6b8c0.png)


- **权重平均** 可以提高模型的泛化能力：当 $H$ 等于0时，模型的性能比 $H$ 不等于0时更差。这证实了我们的假设，即权重平均可以帮助模型提高其泛化能力。
- **$H$ 的具体值取决于图的性质：** 虽然模型平均实现了更高的性能，但在小数据集（例如Cora）上的改进并不明显。我们做出以下猜测：（1）在小数据上训练迅速收敛，并且数据信息有限，因此可以学习的知识不足以支持更广泛的场景；（2）小数据可以在小学习率下有效地学习最佳点，而大数据集具有高维和复杂分布，需要匹配模型平均以避免一次性学习错误。

**方差损失的超参数 $\eta$：** 为了进一步探讨 $\eta$ 对泛化性能的影响，我们还将 $p_g, p_\theta$ 控制为0，并观察不同 $\eta$ 下的模型性能。对于Twitch-Photo数据集，我们选择ES图进行测试。对于Facebook-100图，我们选择“John Hopkins + Caltech + Amherst”组合和Penn进行测试。如表7所示，我们控制 $H = 6$ 并列出观察结果：
- **添加方差项** 可以提高模型的表现能力：类似于模型平均，当 $\eta$ 等于0时，模型的性能比 $\eta$ 不等于0时更差。这再次支持了我们认为方差损失可以帮助模型提高模型泛化能力的观点。然而， $\eta$ 的具体值也取决于图的性质。

### F. 现实世界图基准上的实验
在这一部分中，我们还添加了一个现实世界的交易图基准，即Elliptic，以验证我们RGLT算法的稳健性和泛化性。Elliptic数据集包含49个连续的图快照。每个快照表示比特币交易网络，其中节点表示单个交易，边表示支付流。大约20%的这些交易被标记为合法或非法，目标是在后续网络观测中检测非法交易。在原始数据集中，最初的六个快照显示出明显的类别不平衡，非法交易占数千个节点中的不到10个。因此，我们排除这些快照，使用第7-11、第12-17和第17-49快照进行训练、验证和测试。鉴于每个图快照中的正标签率较低，我们将33个测试快照合并为9个按时间顺序排列的测试集。在这里，我们选择GraphSAGE和GPR-GNN作为骨干，以验证RGLT的性能。

如图12所示，我们按时间顺序将测试图快照分为9组。为了更好地比较RGLT和EERM的性能，我们取消了权重平均模块。我们的模型设置为以5%的比例剪枝，进行10次剪枝迭代，随后增强被剪枝的环境组件。在两种配置下，GraphSAGE和GPR-GNN，我们观察到我们的模型在9个图（T1到T9）上均优于最先进的EERM的最佳结果。这进一步证明了RGLT在现实世界场景中的潜在适用性和多功能性。

### G. 每个单独组件的贡献
虽然我们系统地验证了RGLT算法的有效性，但仍有一些值得讨论的有趣方面。我们的算法引入了多个模块，包括重新激活、干预和权重平均组件。在本节中，我们将深入探讨每个模块的贡献，以更好地理解我们模型的分布外处理能力的来源。我们选择了之前实验中使用的两个实验设置，分别是GCN+Cora和GraphSAGE+OGB-Arxiv（2016-2018）。在保持实验参数优化的情况下，我们单独移除重新激活、干预和权重平均模块，以观察性能下降值。

在GCN+Cora配置中，移除重新激活、干预和权重平均组件后，我们观察到模型性能在不同程度上的下降。值得注意的是，移除干预模块后，模型性能下降了近6%，这突显了干预组件的重要性。这种现象在OOD数据集中特别明显。在GraphSAGE+OGB-Arxiv设置中，移除干预模块也导致了最显著的性能下降（↓ ∼ 5%）。有趣的是，移除干预模块后，RGLT算法的性能甚至可能低于EERM。这间接地证明了该模块在我们分布外泛化中的核心地位。我们认为，在OOD场景中，如果模型没有接触到更广泛的数据分布，它就无法展示分布外泛化的能力。

### H. 与动态稀疏化方法的比较
值得注意的是，在剪枝过程中重新激活被剪枝元素的技术在动态稀疏训练（DST）中得到了广泛探索。稀疏进化训练（SET）涉及移除具有最小幅度值的权重，然后在每个训练周期结束时随机生长回相同数量的权重。RigL在训练过程中使用类似的基于幅度的权重丢弃方法更新稀疏网络的稀疏性拓扑，但使用绝对值最大的梯度重新生长权重。值得一提的是，我们的方法在多个方面与现有的DST方法明显不同：
1. **研究领域：**RGLT专注于图和权重的联合剪枝，而传统DST方法专注于CNN和MLP中权重的剪枝和恢复。我们认为我们是第一个在图数据领域测试重新激活过程的。
2. **实现方法：**我们的方法通过迭代剪枝和重新激活在改进的稀疏性下找到更好的中奖票。相比之下，传统方法在固定稀疏性水平上进行剪枝和恢复。例如，在RigL中，剪枝和生长的权重数量始终相同，但我们的方法倾向于恢复较少的权重。

综上所述，这些方法并不是专门为GLTs设计的，它们无法在图上尝试剪枝，因为它们主要处理权重剪枝和重新激活。为了评估我们提出的方法在GNNs背景下的效率，我们在Citeseer+GCN和PubMed+GCN上进行了LoRS和RigL的比较评估。我们分别控制权重部分，使用RigL和我们的LoRS。对于RigL和ITOP，我们将预定义的稀疏性设置为初始目标，控制最终稀疏性与初始稀疏性相同，并将动态恢复参数设置为初始稀疏性的10%。如图13所示，LoRS在GNN场景中发现更高极端权重稀疏性的中奖票方面表现出色。


![](https://img-blog.csdnimg.cn/direct/b0bdaeac584145e9a916dc76d13b274c.png)



### 实验总结
我们对IID（或OOD）图进行了广泛的实验，以审计我们的提案。从这些结果中可以看出，RGLT不仅在高稀疏性情况下表现良好，还能解决泛化性缺乏的繁重问题，为大规模图的计算和泛化提供了可行的解决方案。从更微观的角度来看，我们还尝试观察激活时重要边的模型表现能力。以Cora+GCN的组合为例，实验结果如图14所示。值得强调的是，我们的研究在同时考察“图彩票研究线”和OOD图领域方面具有开创性。除了在图剪枝范式中实现最先进的成果外，我们还揭示了将剪枝策略与因果发现框架融合的潜力。这展示了前沿剪枝技术如何与因果发现方法和谐融合。

**可重复性：**在本文中，我们引入了多个超参数。为了更好地帮助读者进行参数选择，我们对两个最关键的超参数，即 $\eta$ 和 $H$ 进行了详细分析。根据表7和表8，我们观察到，对于 $\eta$，应控制在0.4至0.8之间。这个参数的影响可能比主要损失函数（交叉熵损失）略小。至于 $H$，应控制在3到9之间。鉴于不同数据集具有不同的特性，我们认为这两个超参数的设置可能会因特定数据集而异。其值的选择可能与数据集的独特特性相关。




## V. 讨论与未来工作
虽然RGLT在各种数据集上优于EERM，并且可以在高权重稀疏性和图稀疏性下获得出色的图彩票，但我们也谨慎反思我们方法的一个局限性：如何解决链接预测任务中的OOD问题？我们认为时间评估现象也存在于链接预测中。在实际社交网络场景中，不同实体之间的关系会随着时间的推移而变化。如何构建一个可行的解决方案来解决这一问题，是我们未来的研究方向之一。



## VI. 总结
在这项工作中，我们探索了一种称为RGLT的新范式，以提高GLT算法在实际应用中的潜力，即稳健性和泛化性。为了实现稳健性，我们将学习优化器中的“温暖重启”概念推广到剪枝行，通过梯度信息重新激活部分权重/边。在多轮选择之后，我们停止剪枝，并从因果视角进行环境干预，以进一步提高泛化性。多个例子和证明支撑了我们提案的普遍性和可靠性，广泛的实验验证了我们提案在多个现实世界数据集上的各种网络中的有效性。


#声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。

