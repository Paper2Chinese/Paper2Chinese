# [Anti-UAV410: A Thermal Infrared Benchmark and Customized Scheme for Tracking Drones in the Wild](https://ieeexplore.ieee.org/document/10325629/)
## 题目：Anti-UAV410: 一种用于野外追踪无人机的热红外基准测试与定制化方案
**作者：Bo Huang; Jianan Li; Junjie Chen; Gang Wang; Jian Zhao; Tingfa Xu**  
**源码：https://github.com/HwangBo94/Anti-UAV410**

****
# 摘要
无人机（Unmanned Aerial Vehicles，UAVs），也称为无人飞行器，在红外视频中的感知对于有效的反无人机任务至关重要。然而，现有的无人机跟踪数据集在目标尺寸和属性分布特征方面存在局限性，无法完全代表复杂的现实场景。为了解决这个问题，我们引入了一个名为Anti-UAV410的通用红外无人机跟踪基准。该基准包含总共410个视频，超过438 K个手动注释的边界框。为了应对复杂环境中无人机跟踪的挑战，我们提出了一种新的方法，称为孪生无人机跟踪器（SiamDT）。SiamDT结合了双语义特征提取机制，明确地模拟了动态背景杂波中的目标，使得小型无人机的有效跟踪成为可能。SiamDT方法包括三个关键步骤：双语义区域提议网络（DS-RPN）、多功能R-CNN（VR-CNN）和背景干扰抑制。这些步骤分别负责生成候选提议、基于双语义特征细化预测分数，并增强对动态背景杂波的跟踪器的辨别能力。通过在Anti-UAV410数据集和三个其他大规模基准上进行的广泛实验，展示了所提出的SiamDT方法与最近的最先进跟踪器相比的优越性能。

# 关键词
- Anti-UAV
- 孪生网络
- 单目标跟踪
- 热红外跟踪数据集
- 小目标跟踪

# I. 引言
随着深度学习和自动化技术的快速发展，无人机（UAVs）已经变得无处不在，并在各种领域如航拍摄像和环境监测中得到广泛应用。然而，随着它们的广泛采用，无人机也对公共安全构成了潜在威胁。因此，监控它们的操作，包括它们的位置和轨迹，以确保安全和安全至关重要。然而，由于无人机的小尺寸和周围环境的复杂性，定位和跟踪无人机仍然是一个具有挑战性的问题，需要仔细考虑。

传统的热红外目标跟踪数据集[2][3][4][5][6]主要强调大规模目标的跟踪，这可能不适用于如无人机这样的小目标跟踪场景。尽管已经引入了Anti-UAV数据集[2]来解决无人机跟踪问题，但它在现实场景表示方面仍然存在局限性。该数据集中的无人机由于其大尺寸和干净的背景，通常容易观察，这并没有完全捕捉到现实世界跟踪情况的复杂性。

为了解决这个限制，我们开发了一个新的数据集，称为Anti-UAV410，这是目前最大的热红外（TIR）领域中无人机单目标跟踪的基准。该数据集包含410个序列，总共超过438 K个边界框，专门设计用于解决无人机跟踪挑战。Anti-UAV410专注于恢复现实场景中的反无人机跟踪问题，即远距离成像下的小无人机目标跟踪。如图1（左）所示，Anti-UAV410涵盖了野外的各种跟踪场景，如森林、山脉、湖泊，这可能会引入过多的背景噪声，并使跟踪器从背景区域学习。因此，Anti-UAV410在野外跟踪无人机方面带来了新的挑战，即微小目标和具有杂波的动态背景（DBC）。如图1（右）所示，数据集包括77个与DBC挑战相关的视频序列和100多个包含小型无人机的视频序列，为反无人机任务提供了更好的数据支持，并作为训练和评估跟踪算法的全面平台。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/8b4b828edc54417aa64164830feff9b4.png" width="70%" /> </div>


作为解决微小目标在动态和模糊背景下跟踪挑战的解决方案，我们提出了一个定制的多分支跟踪架构，称为SiamDT（孪生无人机跟踪器）。由于热红外（TIR）图像中缺少颜色特征，传统的TIR跟踪方法通常使用轮廓等浅层特征来表示目标[7][8][9][10][11]，这些特征具有高度的可解释性。然而，鉴于无人机通常尺寸较小并在杂乱的环境中运行，这些浅层手工制作的特征不足以准确地将无人机与具有相似视觉外观的背景干扰物区分开来。

为了弥补这些差距，我们设计了一种新颖的双语义提取机制，以捕获目标的语义显著性，这些特征在搜索模板中具有辨别性并且容易定位。双语义提取机制由两个阶段的模块组成：i）双语义RPN提议（DS-RPN），通过构建一个模拟目标区域与模板之间关系以及前景对象存在概率的孪生分支RPN来预测候选提议；ii）多功能R-CNN（VR-CNN），根据通过共享权重的R-CNNs融合的信息来细化预测提议。与传统的孪生跟踪器[12][13][14]不同，后者仅在训练期间学习模板和目标候选区域之间的匹配语义，SiamDT还学习了一个单独的前景概率语义，以确定当前目标候选区域包含前景对象的概率。具体来说，我们引入了一个额外的分支来输出当前目标区域中前景语义的概率，当目标候选区域没有语义对象时，该概率接近零。基于鲁棒的特征表示，我们进一步引入了第三个分支iii）背景干扰抑制，通过存储所有可能的负样本的手工艺图来增强跟踪器对动态背景干扰物的辨别能力。通过步骤1和步骤2的联合作用，可以以优越的方式获得关于小目标的明确语义的归纳表示。因此，我们的SiamDT在现实场景中跟踪无人机时，应对了两个主要挑战：尺寸过小的目标问题和模糊的背景问题。

我们进行了广泛的实验，以分析最先进的跟踪器在解决各种挑战方面的性能。总结来说，这项工作的贡献如下：

- 我们引入了一个大规模的热红外（TIR）基准，称为Anti-UAV410，它是反无人机系统和跟踪方法的宝贵资源。此外，我们在Anti-UAV410上评估了现有最先进跟踪器的性能，并为未来的比较提供了全面的基线。
- 我们提出了一种新的孪生无人机跟踪器，名为SiamDT，它利用强大的双语义特征来增强微小目标的辨别能力，并包括一个背景抑制分支，以减轻动态背景杂波的影响。SiamDT为TIR小型目标跟踪提供了一种新的方案。
- 我们在新提出的Anti-UAV410基准上取得了新的最先进跟踪性能，并且在Anti-UAV[2]数据集上展示了其泛化能力，并在其他通用数据集（如LaSOT[15]和GOT-10k[16]）上进行了演示。

# III. Anti-UAV410 基准

传统的数据集通常优先考虑在干净背景下对大型物体的跟踪，这可能无法完全捕捉到无人机在混乱背景下作为小型物体操作的真实世界场景。为了解决这个限制，我们提出了 Anti-UAV410，这是一个旨在更具代表性地展现现实场景的数据集，其中包括许多具有微小目标和动态背景的跟踪场景。

## A. 数据收集

为了在真实世界环境中创建反无人机跟踪挑战的真实表示，我们在多样化和复杂的情况下捕获了跟踪视频。这些场景包括两种不同的照明条件（白天和夜晚）、两个季节（秋天和冬天），以及广泛的背景，如建筑（30%）、山脉（20%）、森林（5%）、城市地区（30%）、云（10%）、水面（3%）等。这些获取的视频序列以每秒 25 帧（FPS）的帧率在中波红外光谱中录制。从这些序列中，我们选择了 100 分钟的视频进行细致的逐帧注释，总共超过 150,000 帧。

为了进一步增加数据集的规模，我们还整合了来自 1st Anti-UAV Challenge 网站 [34] 和 Anti-UAV 数据集 [2] 的视频。这些视频被裁剪和清洗以确保一致性和质量，从而创建了 Anti-UAV410 数据集。i) 由于一些视频序列的边框上有文字，我们采用了裁剪操作来去除这些干扰。ii) 由于 Anti-UAV 是一个双模态数据集，一些视频片段不适合单独的 TIR 跟踪（例如，一些 TIR 视频在第一帧中没有目标，而相应的可见光视频却有）。我们丢弃这样的帧，以便它可以用于独立的 TIR 跟踪。我们称这个过程为“清洗”操作。Anti-UAV410 数据集中视频的平均长度是 1069 帧，这对跟踪器具有鲁棒的目标重新检测能力提出了挑战。

## B. 注释

按照 [2] 中描述的注释过程，我们最初手动注释了每个序列的属性，包括无人机的大小和是否存在无人机。随后，我们使用外部矩形边界框作为真实目标注释了 UAV 目标。记录了边界框的左上角坐标、宽度和高度，以表示目标的真实目标。在某些帧中如果没有目标出现，则真实目标被表示为空。

## C. 统计

数据集分割：Anti-UAV410 数据集被分为三个集合：训练集，包含 200 个序列；验证集，包含 90 个序列；测试集，包含 120 个序列。与以前的数据集不同，我们根据序列的属性仔细地将数据集划分为三个集合。图 2 显示了训练集、测试集和验证集在每个挑战属性下的属性分布，三个子集在每个挑战属性上相对均衡分布，此时使用训练集可以更好地学习无人机在野外场景中面临的挑战。没有特别的技术，我们使 Anti-UAV410 数据集展现出这样的分布，通过手动调整实现。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/f41e052951084540bdabde5772ed453a.png" width="70%" /> </div>


此外，训练集和验证集来源于同一序列的不重叠剪辑，而测试集则是完全独立的，确保了对跟踪器性能的严格评估。

尺度分布：为了在现实场景中复制反无人机跟踪的挑战，我们专注于增加 Anti-UAV410 数据集中小型目标的比例。Anti-UAV410 中所有序列的帧大小设置为 640×512，我们将目标大小定义为边界框的对角线长度。为了比较其他广泛使用的 TIR 数据集（如 PTB-TIR [26]、LSOTBTIR [6]、VOT-TIR2015 [35]、VOT-TIR2016 [5]、Anti-UAV [2] 和 VOT-RGBTIR2019 [4]）的目标大小分布，我们分析了目标大小的分布。与其他跟踪任务不同，在反无人机跟踪任务中，很少有无人机目标的尺度大于 70×70 像素。鉴于无人机固有的小尺寸，我们更严格地定义了微小尺寸的 UAV 目标。我们首先将微小和小目标的大小分隔符设置为 10 像素。为了尽可能均匀地分布不同的尺度属性，我们将尺寸范围定义为 4 个间隔：微小 [2, 10)、小型 [10, 30)、中型 [30, 50) 和正常 [50, inf)。比较结果呈现在表 II 中。值得注意的是，Anti-UAV410 数据集展示了大量小型目标的比例，超过一半的目标大小小于 50 像素，甚至包括一定比例的微小目标（大小小于 10 像素），这在其他数据集如 VOT-TIR2015 [35]、VOT-TIR2016 [5]、PTB-TIR [26] 和 LSOTB [6] 中被遗漏了。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/cf62c128cd12460dbd1df26599c085b7.png" width="70%" /> </div>
<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/1ba27d180e4e4a898028cb6a2681c520.png" width="70%" /> </div>


属性定义：为了全面评估跟踪器的性能，我们在数据集中为每个序列标记了六个属性，即视场外（OV）、遮挡（OC）、热交叉（TC）、快速运动（FM）、尺度变化（SV）和动态背景混乱（DBC），如表 I 所示。Anti-UAV410 数据集包含了大量的热交叉情况，这在 TIR 序列中很常见。此外，由于无人机的运动特性，我们的数据集包括了大量的快速运动，使跟踪任务更具挑战性。此外，Anti-UAV410 涵盖了大量的动态背景混乱，这通常出现在真实世界场景中。值得注意的是，Anti-UAV410 中的目标大小主要是微小、小型和中型尺寸，这比其他数据集中的目标尺寸显著更小，从而为跟踪器提出了巨大的挑战。

## D. 与 Anti-UAV 数据集的比较
Anti-UAV 数据集 [2] 是一个多模态数据集，包括 318 对视频。该数据集旨在解决不同模态下的反无人机跟踪挑战，例如在低光照条件下，基于视觉的跟踪器可能表现不佳。然而，我们提出的 Anti-UAV410 数据集专门针对长距离反无人机跟踪问题。它旨在提高跟踪器对背景混乱的鲁棒性，并增强其对小型 UAV 目标的区分能力。与 Anti-UAV 数据集中相对较大的目标尺寸（平均对角线长度为 40 像素）和均匀背景（主要由天空和城市建筑组成）不同，我们收集了大量的野外反无人机跟踪视频，以复制具有多样化背景和具有挑战性的跟踪条件的真实世界场景。

# IV. SiamDT 跟踪器

## A. 概述
受到 Siamese 跟踪器如 SiamATL [36]、SiamFC [37]、SiamRPN [13]、DaSiamRPN [14]、SiamBAN [38] 和 SiamCAR [39] 等成功的启发，我们开发了自己的 Siamese 无人机跟踪器（SiamDT），使用如图 3 所示的多分支架构。具体来说，SiamDT 使用了一个包含注意力机制的 Siamese 特征提取子网络，并采用 Swin Transformer [40] 作为主干特征提取器。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/3e8dc81f1b9c49f4882b246eb5229fd8.png" width="70%" /> </div>


与传统的 Siamese 跟踪器不同，SiamDT 的决策子网络由三个专门设计的分支组成。一个分支旨在抑制背景噪声，另一个分支预测目标区域中存在语义信息目标的先验概率。最后一个分支执行检测图像与模板之间的相似性评估。重要的是，这些分支由三个特别设计的模块支持：双语义 RPN 提议（DS-RPN）、多功能 R-CNN（VR-CNN）和查询卷积模块（该模块对模板进行编码到候选区域，并通过组合 VR-CNN 预测相似性得分）。

在以下各节中，我们将详细介绍 SiamDT 架构的每个模块。

## B. 用于 Proposals 生成的双语义 RPN
大多数单阶段 Siamese 跟踪器 [13]、[14]、[41] 依赖普通的 RPN 网络来建立搜索图像与模板之间的关联。尽管这些普通的 RPN 网络在大多数情况下表现良好，但当搜索图像显著大于模板图像时，它们往往会失败或做出不适当的跟踪决策，这是由于它们固有的区域搜索策略所致。为了克服这一限制，我们提出了一种新的双语义 RPN（DS-RPN）网络，该网络具有一个执行全局搜索的额外分支。实验结果表明，我们的方法能够准确预测最优候选 proposals。

**全局 RPN Proposals**：受到 GlobalTrack [42] 和 Siam R-CNN [12] 中使用的方法的启发，我们引入了一个 RoI 池化层，以实现全局 RPN 生成。具体来说，在模板分支中，我们提取目标区域的特征，并通过一个 RoI 对齐层处理它们。在检测分支中，从整个测试图像中提取全局特征，并使用 RPN 网络生成大量候选提议。然后，将每个提议与目标特征对齐到相同的大小，以便与模板目标进行全局匹配。

**双语义特征提取**：设 $z$ 和 $x$ 分别代表模板和搜索区域的图像块。DS-RPN 网络结合了两个语义信息源。第一个是目标区域的前景概率语义，表示为 $\phi(x) \in \mathbb{R}^{h \times w \times c}$ ，它指示目标区域中是否存在包含语义信息的目标。第二个是模板和目标区域之间的匹配语义。表示模板区域特征为 $\phi(z) \in \mathbb{R}^{k \times k \times c}$ ，匹配语义 $\phi_{corr}(x, z)$ 可以计算为：

$$
\phi_{corr}(x, z) = (Conv_{out} (Conv_x(\phi(x)) \odot Conv_z(\phi(z)))+b),
$$

其中 $\odot$ 表示深度卷积运算符 [41]，用于计算 $\phi(z)$ 和 $\phi(x)$ 之间的相似性。 $Conv_z$ 在 $\phi(z)$ 上应用一个 $k \times k$ 的卷积层，带有零填充，将特征转换为 $1 \times 1$ 的卷积核。 $Conv_x$ 表示在 $\phi(x)$ 上应用一个 $3 \times 3$ 的卷积层，带有 1 像素的填充。 $Conv_{out}$ 表示一个 $1 \times 1$ 的卷积层，将通道数转换回 $c$ 。 $b$ 表示偏置项。

**双语义提议**：基于前景概率语义和匹配语义，如式（1）中所定义，它们被连接并输入到 DS-RPN 网络中，以生成候选提议 DSprs，使用 RPN 头部如下：

$$
DSprs = RPNHead (Concat (\phi_{corr}(x, z), \phi(x))) .
$$

其中 Concat 表示连接操作，RPNHead 表示 RPN 头部模块，它将连接的特征作为输入，并生成候选提议 DSprs，以便在跟踪器中进一步处理。

最后，利用 ROI 池化层 [42] 获取对齐的全局 RPN 提议 DSalg：

$$
DSalg = RoIPooling(DSprs).
$$

其中 RoIPooling 指的是 ROI 池化操作。

**双语义 RPN 损失函数**：与 [43] 类似，我们的 DS-RPN 的损失函数定义为：

$$
L_{DS-RPN} = L_{RPN} (Concat (\phi_{corr}(x, z), \phi(x))) = \frac{1}{N_{cls}} \sum_{i} L_{cls}(p_i, p_i^* ) + \lambda \frac{1}{N_{reg}} \sum_{i} p_i^* L_{reg}(b_i, b_i^*),
$$

其中 $p_i^* \in \{0, 1\}$ 和 $p_i \in [0, 1]$ 分别表示第 $i$ 个锚点的地面真实标签和预测分数。 $b_i^*$ 和 $b_i$ 分别表示地面真实和预测边界框的 4 个参数化坐标。这两个项分别由 $N_{cls}$ 和 $N_{reg}$ 归一化，并由平衡参数 $\lambda$ 加权。

# C. Versatile R-CNN 模块用于结果精炼

先前的研究 [12], [42] 已经证明，在跟踪任务中，双阶段网络结构优于单阶段网络。受到这一发现的启发，我们整合了 R-CNN [44] 的第二阶段，并引入了一个多功能的 R-CNN 头部，能够有效处理第 IV-B 节中提取的对齐的双语义特征。

*Versatile R-CNN 输入*：我们的目标是评估候选提议与模板特征的相似性，同时保留无人机目标的固有语义信息。为了实现这一点，我们首先将目标信息编码到每个提议中。设 Ψ(x) ∈ Rn×k×k×c 为 RPN 对齐提议的特征矩阵，其中 n 表示提议的数量。我们通过以下方式计算新的匹配特征 Ψcorr(x, z) ∈ Rn×k×k×c，将模板区域特征 Ψ(z) ∈ R1×k×k×c 编码：

$$
Ψcorr(x, z) = Conv'_ {out} (Conv'_ {x}(Ψ(x)) \odot Conv'_{z}(Ψ(z))) + b,
$$

其中 ⊙ 表示哈达玛积，用于融合两个分支的信息。 $Conv'_ {x}$ 指的是在 Ψ(x) 的每个通道上执行 3 × 3 卷积，填充 1 像素。 $Conv'_ {z}$ 在 Ψ(z) 上执行与 $Conv'_ {x}$ 相同的操作，不同之处在于 $Conv'_ {z}$ 在卷积后自动将 Ψ(z) 扩展到 n 维。 $Conv'_{out}$ 是一个 1 × 1 卷积层，具有 c 个输出通道，b 表示偏置项。

*Versatile R-CNN 头部*类似于双语义 RPN，我们可以将 Ψcorr(x, z) 和 Ψ(x) 连接起来创建一个双语义 R-CNN 头部，展现出强大的辨别能力。然而，在跟踪阶段，独立预测目标区域中语义信息目标的存在与否以及模板与目标区域之间的相似性是可取的。这种方法减少了单一语义错误导致完全跟踪失败的风险。因此，我们设计了一个多功能的 R-CNN 头部，可以输出两个分数。一个分数确定目标区域中是否存在具有语义信息的目标，另一个表示模板与目标区域之间的相似性。这两个过程独立进行，但共享相同的权重。

*Versatile R-CNN 损失函数*在训练阶段，我们首先将原始特征 Ψ(x) 输入到 R-CNN 头部，并为无人机的分类获得损失 LR-CNN(Ψ(x))。接下来，我们将编码的特征 Ψcorr(x, z)（值得注意的是，Ψ(x) 和 Ψcorr(x, z) 具有相同的大小和通道数）输入到 R-CNN 头部，并获取与模板分支匹配的损失 LR-CNN(Ψcorr(x, z)）。Versatile R-CNN 的总体损失函数然后计算如下：

$$
LV_{R-CNN} = LR-CNN(Ψcorr(x, z)) + LR-CNN(Ψ(x)) = \frac{1}{N_{prop}} \sum_{i} (Lcls(p_{i,corr}, p_{i}^{* }) + Lcls(p_{i,orig}, p_{i}^{* })) + \lambda_{p_{i}^{* }} (Lreg(b_{i,corr}, b_{i}^{* }) + Lreg(b_{i,orig}, b_{i}^{*}))
$$

其中 Nprop 是候选提议的总数。 $p_{i,corr}$ 和 $p_{i,orig}$ 分别是匹配语义和前景概率语义的预测置信度分数。与公式 (4) 中的 bi 类似，bi,corr 和 bi,orig 分别是匹配语义和前景概率语义的预测边界框。

# D. 三分支网络用于决策制定

我们的方法中的跟踪过程包括三个分支，这些分支汇聚在一起进行最终的决策制定：

*背景干扰抑制分支*与传统的孪生网络框架不同，后者仅计算搜索分支的 RPN 提案，我们的方法对两个分支都执行 RPN 候选提议提取。在模板分支中，我们基于高置信度分数识别背景区域中的干扰物。具体来说，我们强制执行干扰物的边界框与真实边界框之间的零重叠率。设 D 表示背景干扰物的集合，包含 K 个提议，其中 D = {d1, d2, ..., dK}。我们将干扰物的数量限制在最多 50 个，即 K ≤ 50。在搜索分支中，由于背景干扰物的存在，R-CNN 头部的输出可能会出现多个预测，这使得在它们之间进行区分变得具有挑战性。设 P 表示 N 个难以区分的候选预测的集合，其中 P = {p1, p2, ..., pN}。我们使用以下公式计算预测结果与背景干扰物之间的相关性分数：

$$
G(D, P) = \sum_{i} R - CNNHead(Ψcorr(D, pi)),
$$

其中 G(D, P) 计算预测候选 P 与背景干扰物 D 之间的相似性。我们使用 R-CNN 预测的最大置信度分数 G(D, pi) 作为 pi 与 D 的相似性输出。G(D, pi) 的值越高，表明 pi 是背景干扰物的概率越大。因此，我们利用 G(D, pi) 作为负反馈来调整最终的预测结果。集合 D 使用第一帧的干扰物进行初始化，并且每个背景干扰物的特征存储在序列记忆中。如果我们在某个帧上获得了可靠的跟踪结果，我们将相应地更新 D；否则，D 保持不变。

*匹配语义分支*遵循传统孪生跟踪器 [12], [42] 的方法，我们使用第一帧的模板图像和当前帧的搜索图像作为输入，对 DS-RPN、查询卷积模块和 VR-CNN 进行前向传递。随后，我们从输出中提取顶部 N 个提议。

*前景概率语义分支*考虑到提取具有有限像素占用的微小目标的有效特征表示的挑战，我们引入了第三个分支用于前景概率语义。这个分支旨在输出一个介于 0 到 1 之间的先验概率值，指示当前提议包含语义 UAV 目标的可能性。随后，我们选择这个分支的顶部 M 个提议进入最终决策过程。

**备注 1：** 在最终决策阶段，我们从匹配语义分支获得 N 个提议，每个提议都有匹配语义分数，以及从背景干扰物抑制分支获得的背景干扰物的相似性分数。此外，前景概率语义分支输出可能包含语义 UAV 目标的 M 个提议，并计算这些提议与前述 N 个提议之间的 IoU 分数。这三个分数线性组合后，得分最高的提议被选为最终的跟踪结果。

# V. 实验

我们对提出的SiamDT跟踪器和25种最先进的跟踪器在Anti-UAV410数据集上进行了定性和定量比较。我们还详细分析了每个跟踪器在不同属性挑战下的性能，并讨论了它们对野外反无人机跟踪进展的潜在贡献。此外，我们在其他RGB数据集上进行了实验，以验证SiamDT在RGB跟踪中的泛化能力。

## A. 实验设置

**实现细节：** 对于孪生特征提取子网络，我们使用Swin Transformer架构作为骨干。超参数包括移位窗口的大小、每个头的查询维度和每个多层感知（MLP）的扩展层设置为7、32和4。SiamDT默认采用Swin-Tiny作为骨干，其隐藏通道设置为96，所选层数为{2, 2, 6, 2}。我们使用COCO数据集预训练的骨干权重，并训练了总共12个周期。

分类损失 $L_{cls}$ 和回归损失 $L_{reg}$ 分别使用二元交叉熵和平滑L1损失计算。我们的模板分支和搜索分支是镜像的，以确保一致性。我们首先用模板图像对网络进行喂送，然后用搜索图像进行喂送，然后反之亦然。这个双向过程的总损失被用作最终的完整损失。

当VR-CNN输出两个具有最高置信度分数 $S_1 \in [0, 1]$ 和 $S_2 \in [0, 1]$ 的边界框bbox1和bbox2时，如果bbox1和bbox2之间的交并比（IoU）大于0.8，并且 $S_1 + S_2 > 1.9$ ，则更新模板分支和背景干扰提议D。

**评估指标：** 使用一次通过评估（OPE）通过三个常用评估指标，即精度图、成功率图和状态精度，来评估所有跟踪器的性能。具体来说，精度图计算在估计的目标位置与真实位置给定距离阈值内相符的帧的百分比。我们使用20像素的阈值来对跟踪器进行排名。成功率图测量预测边界框与真实位置的IoU大于从0到1变化的阈值的成功帧的比例。成功率图的曲线下面积（AUC）用于对跟踪器进行排名。状态精度，如Anti-UAV[2]中定义的，反映了所有序列中预测边界框与真实位置之间的平均重叠比率。这个指标不仅要求跟踪器准确预测目标的位置和尺度，还要确定目标在当前帧中的存在状态，并在目标从视野中消失时做出判断。

## B. 在Anti-UAV410上的实验

**评估的跟踪器：** 为了评估，共选择了25个公开可用的跟踪器，包括最新的RGB跟踪器，即SiamFC++、PrDiMP、Super_DiMP、KYS、GlobalTrack、SiamCAR、SiamBAN、Siam R-CNN、ROAM、TrDiMP、TransT、STMTrack、HiFT、Stark、KeepTrack、RTS、Unicorn、AiATrack、OSTrack、SLTTransT、TCTrack、ToMP、SwinTrack、JointNLT、SeqTrack、ARTrack、DropTrack、GRM、ROMTrack、MixFormerV2和一些TIR跟踪器，即MLSSNet、CMD-DiMP、MMNet。在评估实验中使用了这些跟踪器作者提供的默认参数。注意，为了实现JointNLT跟踪器，我们为Anti-UAV410数据集中的每个视频序列分配了一个自然语言参考“在红外场景中飞行的无人机”。

**不使用Anti-UAV410训练：** 表III显示了不使用Anti-UAV410训练集的原始跟踪性能结果，按状态精度排名。从这个表中，我们可以得出以下结论：

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/a56795984c4a4c089eca4feee40935d6.png" width="70%" /> </div>


i) 一些使用更深网络进行特征提取的跟踪器，如Stark-ST101、SwinTrack-Base和SeqTrack-B384，并没有显著优于使用更浅层特征的跟踪器，如Stark-ST50、SwinTrack-Tiny和SeqTrack-B256。这归因于目标的小尺寸和它在红外图像中占用的像素数量有限，这使得深层网络难以有效利用其语义表示能力。

ii) 值得注意的是，采用全局检测方法的跟踪器，如Siam R-CNN和GlobalTrack，表现异常出色。我们认为这是因为它们能够处理相机运动并重新检测从屏幕上丢失的目标，从而提高整体跟踪性能。

iii) 在传统跟踪数据集中取得领先地位的跟踪器，如SwinTrack和MixFormerV2，并不一定在TIR视频中的反无人机跟踪任务中表现出色。因为反无人机跟踪的挑战与传统跟踪不同，对跟踪器的要求也会有所不同。

iv) 为TIR视频序列设计的跟踪器，如MMNet、MLSSNet和CMD-DiMP，在反无人机跟踪任务中表现不佳。这是因为这些跟踪器只强调补偿TIR视频中颜色信息的丢失，而没有增强捕获小目标和抑制背景热噪声干扰的能力。

**使用Anti-UAV410训练：** 为了验证我们提出的训练集在提高TIR无人机目标跟踪跟踪器性能方面的有效性，我们在代表性的深度跟踪器上进行了使用Anti-UAV410训练集的比较实验。所有重新训练的跟踪器保留默认设置和默认预训练权重，实验结果如表IV所示。具体来说，表中左侧的数字表示使用作者提供的原始模型获得的结果，而右侧的数字表示在用我们提出的训练集训练后的结果。通过包含我们的Anti-UAV410训练集，跟踪器在验证集和测试集上的性能都有所提高。值得注意的是，有六个跟踪器在两个集合上的性能提高了10%以上，这清楚地证明了我们的数据集在提高反无人机应用跟踪器性能方面的价值。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/434d310bd5ca4b45885660c09b57d35d.png" width="70%" /> </div>


提出的SiamDT方法在测试集和验证集上分别以68.19和71.65的分数排名第一。SiamDT在全球两阶段跟踪方法GlobalTrack和Siam R-CNN上略有性能提升，并与TCTrack跟踪器相比实现了近30%的最大精度提升。值得注意的是，SiamDT在测试集上超过了最近基于Transformer的跟踪算法Stark、TransT和ToMP超过10%，以及基于Swin Transformer的跟踪器SwinTrack超过10%的性能提升。

**每属性评估：** 如图4所示，我们提供了基于不同属性的跟踪器性能的全面评估，使用成功和精度图。我们选择了六种代表性的跟踪器进行比较，所有这些跟踪器都使用Anti-UAV410训练集进行了训练。我们的SiamDT在所有六个属性评估中始终表现最佳。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/7750ca5a2e0e49fbb81b5ef72ee70a08.png" width="70%" /> </div>


快速运动会使目标模糊，遮挡或视野外会使目标模型污染，如果不采取措施消除这种干扰，将导致不可逆转的错误。SiamDT在这三个挑战中表现良好，并与比较的跟踪器相比取得了较大的性能提升。目标大小在反无人机跟踪期间通常会发生变化，从图中我们可以看到，所提出的SiamDT跟踪器可以更准确地估计无人机的大小变化。

值得注意的是，在动态背景杂波和热交叉属性中，我们的SiamDT在成功率图和精度图中分别以超过12%和14%的优势超过了先进的基于Swin Transformer的跟踪器SwinTrack。这证明了我们的双语义特征在减轻热杂背景的影响方面的效果，从而在具有复杂背景和动态环境的现实世界跟踪场景中提高了跟踪性能。它展示了我们的方法在处理具有复杂背景和动态环境的现实世界跟踪场景中的潜力。

**基于尺度的评估：** 我们进一步分析了不同尺度的无人机跟踪性能。视频根据目标的对角线长度被分为四组，即正常尺度、中等尺度、小尺度和微小尺度。跟踪方法的精度和成功率图如图5所示。值得注意的是，SiamDT在所有尺寸属性中均排名第一，并在第二排名的跟踪器AiATrack上取得了显著的优势。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/cc1e4c6f6b634f48975b4f1aa2235a90.png" width="70%" /> </div>


值得一提的是，随着无人机尺度的减小，SiamDT相对于其他跟踪器的领先优势变得更加明显。这强调了我们方法在处理长距离小目标跟踪场景中的优越性，这在不受控制环境中的反无人机任务中是常见的。在微小尺度类别中，SiamDT在精度和成功率方面分别超过了基于Swin Transformer的跟踪器SwinTrack 23.3%和18.4%。

**定性比较：** 我们选择了一组代表性的跟踪场景，以直观展示我们的跟踪方法的性能。如图6所示，SiamDT在有效处理现实世界反无人机任务中常见的具有挑战性的跟踪情况方面展现了其优越性。这强调了我们方法的实际应用性，它在实际部署中具有重要的潜力。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/1d90927d108e448894804e6003e0a25b.png" width="70%" /> </div>


## C. 消融研究

为了验证我们SiamDT的不同组件的有效性，我们进行了全面的消融实验并进行了详细分析。重要的是，我们在训练期间保持了超参数的一致性，以确保公平比较。所有实验都在Anti-UAV410测试集和验证集上进行。我们使用状态精度（SA）来评估跟踪器，有关SA指标的详细信息可以在[2]中找到。

我们在实验中使用了以下缩写：GS代表全局搜索，MS代表第一帧的匹配语义，FS代表无人机的前景概率语义，BDS代表背景干扰抑制模块。此外，我们创建了两种基线方法，SiamMS和SiamFS。SiamMS类似于传统的孪生跟踪器，只利用目标和模板之间的匹配语义，而SiamFS类似于忽略序列的时空信息的检测方法。

*全局搜索策略的效果*： SiamNGS（非全局搜索，NGS）代表与SiamDT相同的算法，但采用与SiamRPN相同的邻域搜索策略来替代SiamDT的全局搜索。没有全局搜索，SiamDT将面临12.5%的跟踪性能损失，这证明了全局搜索在反无人机跟踪任务中的重要性。由于无人机目标通常非常小，这导致邻域搜索区域与完整图像的比例较小，快速移动的无人机很容易从这样的搜索区域逃脱，使跟踪器完全失效。

*背景干扰抑制模块的效果*： SiamBDS代表将BDS模块引入到SiamMS中的方法。如表VI所示，借助BDS模块，SiamBDS在Anti-UAV410测试集上获得了1.6%的精度提升。这表明我们的BDS模块有效地抑制了背景干扰，增强了反无人机跟踪的鲁棒性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/a53dfbe71b2d4b5ba62914f8ff70d01e.png" width="70%" /> </div>


*双语义模块的效果*： 我们进行了实验，以验证双语义信息对跟踪性能的改进。SiamDS表示结合了SiamMS和SiamFS的算法，但没有BDS模块。从SiamDS与SiamMS、SiamFS的比较中可以看出，SiamDS借助更强大的特征学习机制，分别在Anti-UAV410测试集上优于SiamMS（0.9%）和SiamFS（1.3%）。这充分证明了双语义信息对跟踪性能的改进，它可以处理微小目标的语义信息较少的挑战，并促进TIR跟踪的发展。

*不同骨干网络的效果*： 我们进一步研究了不同骨干网络对TIR跟踪性能的影响。表VII显示了使用不同骨干网络的SiamDT的性能。我们可以观察到，SiamDT得益于最近流行的Swin Transformer骨干。此外，我们还可以从表中看到，更深层的网络并不一定带来更好的跟踪结果。这是因为小目标占据的像素较少，更深层的特征具有更低的分辨率，可能导致不准确的跟踪结果。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/c5a3a28abc5349cd9877e7aecbcd9e6e.png" width="70%" /> </div>


*不同损失函数的效果*： 我们进一步比较了不同损失函数对SiamDT的影响，如L1、Smooth L1、GIOU和DIOU。比较结果如表VIII所示，我们可以看到不同的损失函数对跟踪器的性能影响很小。因此，SiamDT对损失函数的使用没有严格的限制。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/f1a7772eb5be47e2aaac38d0b1e5a5a0.png" width="70%" /> </div>


## D. 在其他数据集上的实验
我们还在三个流行的大规模数据集上进行了实验，即Anti-UAV[2]、LaSOT[15]和GOT10k[16]，以验证我们跟踪器的泛化能力。我们在Anti-UAV、LaSOT和GOT-10 k训练集上分别训练了SiamDT和其他列表中的跟踪器，并使用每个训练好的模型在其相应的数据集上进行评估。我们使用状态精度（SA）评估Anti-UAV测试集上的跟踪器，在LaSOT上使用成功率（AUC）、精度（P）和归一化精度（PNorm），在GOT-10 k上使用平均重叠（AO）、成功率（SR50）和成功率（SR75）。这些指标的更详细定义可以在Anti-UAV[2]、LaSOT[15]和GOT-10k[16]中分别找到。

如表V所示，借助双语义特征提取和背景干扰抑制机制，我们的SiamDT在处理多类别目标跟踪的GOT10 k和LaSOT数据集上排名第七。这证明了我们提出的方法在处理多样化的跟踪场景和目标类别方面的泛化能力和有效性。在Anti-UAV数据集上，SiamDT排名第一，并在大多数比较算法上实现了超过10%的精度提升。由于我们的双语义RPN和多功能RCNN都是为跟踪无人机目标而设计的，我们的跟踪器对单类/少类跟踪任务非常有效，而在跟踪通用目标方面的应用潜力将不会显著。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/60331d7b952649bdb39f2ae8e91cb3c3.png" width="70%" /> </div>

# VI. 结论
在本文中，我们专注于反无人机跟踪问题。我们首先提出了一个名为Anti-UAV410的新的大规模TIR数据集，其中包含各种实际无人机视频，为评估反无人机跟踪算法提供了基准。此外，我们提出了一种名为SiamDT的孪生跟踪方法，可以有效处理反无人机跟踪场景中的微小目标和动态背景杂波的挑战。在Anti-UAV410和其他流行数据集上进行的广泛实验证明了我们提出的方法在反无人机跟踪中实现最先进的性能的有效性。

在未来的工作中，我们计划通过添加有关相机的更多信息，如方位角和俯仰角，来进一步增强数据集，以促进运动模型的建立和改进反无人机系统的设计。这些额外信息有可能更好地理解无人机的运动模式，从而实现更鲁棒的跟踪算法。我们相信，我们的工作将有助于反无人机行业的发展，并为这一领域的进一步进步铺平道路。

# 声明

本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
