# 题目：[Principal Uncertainty Quantification With Spatial Correlation for Image Restoration Problems](https://ieeexplore.ieee.org/document/10360418/)  
## 图像恢复问题的空间相关主不确定性量化
**作者：Omer Belhasin; Yaniv Romano; Daniel Freedman; Ehud Rivlin; Michael Elad** 

****

# 摘要

在成像逆问题中，不确定性量化近期受到了极大的关注。现有的方法基于每个像素可能的值来定义不确定性区域，却忽略了图像内部的空间相关性，从而导致了不确定性体积的夸大。在本文中，我们提出了一种名为PUQ（Principal Uncertainty Quantification）的新颖定义和相应的分析方法，该方法考虑了图像内的空间关系，从而提供了更小体积的不确定性区域。利用生成模型的最新进展，我们推导出围绕经验后验分布主成分的不确定性间隔，形成一个模糊区域，该区域保证了以用户定义的置信概率包含真实的未观测值。为了提高计算效率和可解释性，我们还确保只使用少数主方向来恢复真实的未观测值，从而产生更具信息量的不确定性区域。我们通过图像上色、超分辨率和修复等实验验证了我们的方法；通过与基线方法的比较，证明了其有效性，显著地缩小了不确定性区域。

# 关键词

- 不确定性和概率推理
- 概率与统计
- 恢复、逆问题
- 随机过程
- 相关性与回归分析

# I. 引言

图像恢复任务在包括细胞摄影、监控、实验物理和医学成像等多个学科中广泛遇到。这些逆问题广义上定义为需要从已知的损坏测量值中恢复未知图像。例如，上色、超分辨率和修复等问题通常是不适定的，意味着存在多种解可以解释未知的目标图像。在这种情况下，不确定性量化旨在表征可能解的范围、分布和变异性。这在天文和医学诊断等应用中尤其重要，因为需要为可能的灰度值偏差建立统计边界。因此，表征带有伴随统计保证的可允许解范围已成为本文解决的重要且有用的挑战。

先前的工作[1], [2]通过分位数回归[3]或其他启发式方法（例如，每个像素残差的估计）构建了每个像素可能值的区间来解决不确定性评估问题。虽然这种方法因其简单性而具有吸引力，但它忽略了图像内的空间相关性，因此提供了夸张的不确定性范围。[4]中的研究通过在潜在空间中量化不确定性改进了上述方法，从而考虑了空间依赖性。然而，该方法依赖于一个非线性的、不可逆的和不确定性不敏感的转换，因此受到解释性限制——见第二节的进一步讨论。

在本文中，我们提出了主不确定性量化（PUQ）——一种新颖的方法，它在图像域内考虑空间关系，从而能够全面清晰地解释量化的不确定性区域。PUQ使用经验后验概率密度函数的主成分，这些成分描述了可能解的分布。PCA本质上通过高斯分布紧密近似这个后验，从而减少了不确定性体积，如图1所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5e053a3ee8d3415dbbd7d75551a26e24.png#pic_ center" width="70%" />
</div>

该图展示了我们提出的精确PUQ过程（见第IV-B1节）与先前工作[1], [2]的比较，显示出随着考虑的图像块大小增加，不确定性体积进一步减小的期望趋势。我们的工作旨在通过利用最近在生成模型方面的进步来提高不确定性体积的量化，这些模型作为逆问题的随机求解器。虽然我们提出的方法可以使用任何此类求解器（例如，条件GAN[5]），但本工作中我们专注于基于扩散的技术，这些技术最近作为领先的图像合成方法出现，超越了GANs和其他替代生成器[6]。扩散模型提供了一个系统和有动机的算法路径，通过训练的图像去噪器[7], [8]的重复应用，从先验概率密度函数（PDF） $P_ y$ 进行抽样。这些模型的一个重要扩展允许采样器变成条件性的，从后验PDF $P_ {y|x}$ 中抽取样本，其中 $x$ 代表观测到的测量值。这种方法最近受到了[6], [9], [10], [11]的极大关注，为逆问题提供了一个迷人的视角，其中获得了各种候选的高感知质量解决方案。

在本工作中，我们推广了像素级不确定性评估，如[1], [2]中所开发的，以纳入像素之间的空间相关性。这种推广是通过考虑一个图像自适应基来实现的，该基替换了像素级方法中的标准基。为了优化输出不确定性区域的体积，我们提出了一种基于扩散采样器得到的后验的统计分析（例如，[10], [11]），考虑了一系列候选的恢复。我们的方法可以全局应用（在整个图像上）或局部应用（在选定的部分或块上），从而更紧密、更准确地封装了统计上有效的不确定性区域。为了适应基，我们计算并利用了候选恢复的主成分。如图2所示，对于简单的2维PDFs，像素级区域效率较低，可能包含大片空白区域，特别是当像素表现出强相关性时。显然，随着维度的增加，标准和自适应不确定性量化之间的差距进一步放大。

我们提出的方法提供了两种基于校准预测的[12], [13], [14]校准选项（具体来说，使用学习然后测试[15]方案），供用户选择，精确度和复杂性之间存在权衡。这些包括（i）使用整个主成分集，（ii）使用它们的预定子集。提出的校准程序确保不确定性区域的有效性，以包含用户指定置信概率的未知真实值，同时还确保当仅使用子集时，通过选定的主成分恢复未知的真实值。应用这些方法允许在高度可能的解的不确定性区域内有效导航。

我们进行了各种局部和全局实验来验证我们的方法，考虑了三个具有挑战性的任务：图像上色、超分辨率和修复，所有这些都在第V节中描述，并展示了所提出方法的优势。例如，当在8×8×3块上局部应用时，我们的实验表明，与先前方法相比，保证的不确定性体积减少了约10-100倍，如图1所示。此外，局部方法可以在保持统计保证的同时大大减少计算复杂性，通过抽取更少的后验样本并使用一小部分主成分。另一个例子是，在全球颜色化任务上的测试提供了前所未有的紧密的不确定性体积。这是通过减少绘制样本的数量来实现的，同时也允许在解集内进行有效导航。

总结来说，我们的贡献如下：

1) 我们引入了一种新颖的广义不确定性区域定义，利用适应的线性空间基底以获得更好的后验覆盖。
2) 我们提出了一种新的方法来量化逆问题的不确定性，该方法考虑了空间相关性，从而提供了紧凑的不确定性区域。
3) 我们提出了两种新颖的不确定性量化校准程序，为未知数据提供了包含在不确定性区域中所需覆盖比率的统计保证，同时通过选定的线性轴以小误差恢复。
4) 我们提供了三个具有挑战性的图像到图像翻译任务：上色、超分辨率和修复的全面实证研究，证明了所提出方法在所有模式中的有效性。

# III. 问题表述

设 $P_ {X,Y}$ 是在输入空间 $X$ 和输出空间 $Y$ 上的概率分布，这里 $X$ 和 $Y$ 分别代表当前逆问题中的输入和输出。例如，在图像上色任务中， $Y$ 可以代表全彩高质量图像，而 $X$ 代表它们的无色版本以供操作。我们假设 $X, Y \subset [0, 1]^d \subset \mathbb{R}^d$ ，其中 $d$ 是假设为两个空间的维度，可以无损失地假设为一般性。

在给定输入测量值 $x \in \mathbb{R}^d$ 的情况下，我们的目标是量化逆问题可能解决方案的不确定性，如通过估计的 $d$ 维后验分布 $\hat{P}_ {Y|X}$ 所表现。我们的想法是通过整合像素之间的空间相关性来增强像素级不确定性间隔的定义，从而得到一个结构更好的不确定性区域。为了实现这一点，我们建议使用一组正交基向量来构建不确定性间隔，而不是在单个像素上的间隔。我们用 $\hat{B}(x) = \{\hat{e}_ 1(x), \hat{v}_ 2(x), ..., \hat{v}_ d(x)\}$ 来表示这个集合，其中 $\hat{v}_ i(x) \in \mathbb{R}^d$ 。这些向量是实例依赖的，因此最好适应它们的任务。这类基的一个直观例子是标准基， $\hat{B}(x) = \{e_ 1, e_ 2, ..., e_ d\}$ ，其中 $e_ i \in \mathbb{R}^d$ 是只有一个条目为1的one-hot向量。在我们的工作中，我们使用 $\hat{P}_ {Y|X}$ 的主成分，这将在第IV节中详细讨论。

类似于[1], [2]，我们使用以条件均值图像为中心的基于间隔的方法，即 $E[y|x] \in \mathbb{R}^d$ 的一个估计，由 $\hat{\mu}(x)$ 表示。正式地，我们使用以下间隔值函数在每个基向量周围的估计条件均值构建预测间隔：

$$
T(x; \hat{B}(x))_ i := \left( \hat{e}_ i(x)^T \hat{\mu}(x) - \hat{l}(x)_ i, \hat{v}_ i(x)^T \hat{\mu}(x) + \hat{u}(x)_ i \right).
$$

在上面的公式中， $i \in \{1, 2, ..., d\}$ 是基向量索引， $\hat{l}(x)_ i \in \mathbb{R}^+$ 和 $\hat{u}(x)_ i \in \mathbb{R}^+$ 分别是从 $\hat{P}_ {Y|X}$ 中出现的候选解投影值的下限和上限间隔。也就是说，如果 $\hat{y} \sim \hat{P}_ {Y|X}$ 是这样的一个解， $\hat{v}_ i(x)^T \hat{y}$ 是它的第 $i$ 个投影，这个值应该以很高的概率落在 $T(x; \hat{B}(x))_ i$ 内部。回到标准基的例子，上述公式不过是像素级预测间隔，这正是[1], [2]中采用的方法。通过利用这种概括，使用这些基向量形成的不确定性间隔构成一个 $d$ 维超矩形，称为不确定性区域。

重要的是，我们提出间隔值函数 $T$ 应该产生有效的间隔，包含用户指定的部分投影真实值在风险水平 $\alpha \in (0, 1)$ 内。换句话说，超过 $1 - \alpha$ 的投影真实值应该包含在间隔内，类似于在像素域中先前工作中采用的方法。为了实现这一点，我们提出了一个整体表达式，它聚合了所有间隔 $T(x; \hat{B}(x))$ 的效果。这个表达式导致以下条件：

$$
\mathbb{E}\left[ \sum_ {i=1}^{d} \hat{w}_ i(x) \cdot \mathbb{1}\left( \hat{v}_ i(x)^T y \in T(x; \hat{B}(x))_ i \right) \right] > 1 - \alpha,
$$

其中 $y \in \mathbb{R}^d$ 是未知的真实值， $\hat{w}_ i(x) \in [0, 1]$ 且 $\sum_ {i=1}^{d} \hat{w}_ i(x) = 1$ 是权重因子，这些因子设置了沿着每个间隔覆盖投影真实值的重要性。在第IV节中，我们将讨论所提出的整体表达式和这些权重的具体选择。作为一个例子，我们可以设置 $\alpha = 0.1$ 和 $\hat{w}_ i(x) := \frac{1}{d}$ ，表明超过90%的投影真实值包含在基向量上的间隔内，如图2所示，在不同的 $\hat{P}_ {Y|X}$ 种类的2D示例中进行了说明。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5f5e9fa9123f47a1ac4faa295848caaa.png#pic_ center" width="70%" />
</div>

如上所述，并在图2中展示，如果(1)中的正交基被选择为标准基，我们得到的是基于像素的间隔，这些间隔忽略了图像内的空间相关性，从而导致了夸张的不确定性区域。在这项工作中，我们通过过渡到实例适应的 $\mathbb{R}^d$ 的正交基来解决这个限制，允许使用不一定是像素独立的轴来描述不确定性，从而提供更紧凑的不确定性区域。虽然可以通过例如正交小波[36]使用分析方法定义这样的基，但我们建议使用学习的方法，从而得到一个更好的调整。选择使用线性和正交表示进行不确定性量化是像素级方法的自然扩展，保留了分别处理每个轴的简单性和效率。注意，正交性允许通过其投影值在 $\hat{\mu}(x)$ 周围的 $y$ 分解， $y = \hat{\mu}(x) + \sum_ {i=1}^{d}[\hat{v}_ i(x)^T (y - \hat{\mu}(x))]\hat{v}_ i(x)$ ，我们称之为精确重建属性。

为了评估不同不确定性区域的不确定性，我们引入了一种新的度量，称为不确定性体积 $V(x; T(x; \hat{B}(x)))$ ，它表示相对于间隔 $T(x; \hat{B}(x))$ 的不确定性体积的 $d$ 次根，定义如下：

$$
V(x; T(x; \hat{B}(x))) := \sqrt[d]{\sum_ {i=1}^{d} (\hat{u}(x)_ i + \hat{l}(x)_ i)} \approx \exp\left(\frac{1}{d}\sum_ {i=1}^{d}\log(\hat{u}(x)_ i + \hat{l}(x)_ i + \epsilon)\right) - \epsilon,
$$

其中 $\epsilon > 0$ 是一个小的超参数，用于数值稳定性。在第V节中，我们将展示与先前方法相比，我们的方法在这些不确定性体积上显著减少。

当在高维操作时（例如，在完整图像上），为所有 $d$ 维提供不确定性间隔提出了严重的挑战，无论是在复杂性还是可解释性方面。在这种情况下，构建和维护基向量变得不可行。此外，使用这些间隔进行的不确定性量化可能不如传统的像素级方法直观，因为基向量之间的像素依赖性使得向用户传达不确定性变得困难。为了缓解这些挑战，我们提出了一个选项，即使用 $K \ll d$ 个基向量来捕捉不确定性的本质。在第IV节中，我们将讨论如何动态调整 $K$ 以提供更少的轴。

虽然减少基向量的数量在可解释性和复杂性方面都有好处，但这个选项没有满足精确重建属性。因此，我们提出了一个传统的覆盖有效性(2)的扩展，考虑到了分解真实图像的重建误差。具体来说，用户设置了像素比例 $q \in \mathbb{R}$ 和该比例上可接受的最大重建误差 $\beta \in (0, 1)$ 。这种近似允许我们减少用于构建 $\hat{B}(x)$ 的基向量的数量，以便根据以下条件进行重建将是有效的：

$$
\mathbb{E}\left[ \hat{Q}_ q\left( \sum_ {j=1}^{K} \hat{v}_ j(x)^T (\hat{y}_ c - \hat{y}_ c) \right) \right] \leq \beta,
$$

其中 $\hat{y}_ c := y - \hat{\mu}(x)$  是以 $\hat{\mu}(x)$为中心的真实图像， $\hat{Q}_ q(\cdot)$ 是由最小的 $z$ 定义的经验分位数函数，满足 $\frac{1}{d}\sum_ {i=1}^{d} 1\{z_ i \leq \hat{Q}_ q(z)\} \geq q$ 。在第IV节中，我们将讨论用于评估基向量有效性的这个表达式。作为一个例子，设置 $q = 0.9$ 和 $\beta = 0.05$ 将意味着90%的真实像素的最大重建误差不超过[0,1]动态范围的5%。

# IV. PUQ: 主不确定性量化

在本节中，我们介绍了主不确定性量化（PUQ），这是我们提出的一种量化逆问题中不确定性的方法，同时考虑了像素之间的空间依赖性。PUQ利用逆问题解决方案的主成分（PCs）来实现其目标。在在线附录A中，我们提供了选择PCs作为基的直观解释。我们的方法可以全局应用于整个图像（称为全局模式）；或者局部应用于预定义的补丁或感兴趣的片段（称为局部模式）。局部不确定性量化可以应用于任何任务，其中目标空间的维度由用户通过要处理的补丁大小完全控制。相反，全局量化特别适用于像素之间表现出强烈空间相关性的任务。

我们提出的方法包括两个阶段。在第一阶段，称为近似阶段，训练一个机器学习系统来预测可能解决方案的主成分，记为 $\hat{B}(x) = \{\hat{v}_ 1(x), \hat{v}_ 2(x), ..., \hat{v}_ K(x)\}$ （其中 $K \leq d$ ），以及一组重要性权重 $\hat{w}(x) \in \mathbb{R}^K$ ，这些权重指的是 $\hat{B}(x)$ 中的向量。此外，该系统估计了(1)中必要的条件均值 $\hat{\mu}(x) \in \mathbb{R}^d$ 和下限与上限 $\tilde{l}(x) \in \mathbb{R}^K$ 与 $\tilde{u}(x) \in \mathbb{R}^K$ ，这些用于估计在 $\hat{B}(x)$ 上的投影解的传播。所有这些要素都是通过图3中描述的基于扩散的条件采样器获得的。我们将在第IV-A节中提供有关此计算过程的更多细节。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/e39d997f68354af3b9a528c4f42bbad2.png#pic_ center" width="70%" />
</div>

上述描述的近似阶段仅是一个估计，因为(1)中的相应启发式间隔可能不包含以所需比例的投影真实值。此外，当 $K < d$ 时，基向量可能无法在可接受的阈值内恢复真实像素值，或者基集可能包含在变异性方面不重要的轴。因此，在第二阶段，校准阶段，我们在一组保留的校准数据 $\mathcal{S}_ {\text{cal}} := \{(x_ i, y_ i)\}_ {i=1}^n$ 上提供两种校准程序。这些程序评估我们提出的不确定性区域在未见过的数据上的有效性，该区域由(1)中定义的间隔组成。两种校准程序之间的选择取决于用户，考虑到精度和复杂性之间的权衡。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/20087b72cd064b12aa9c58c0f97c7a00.png#pic_ center" width="70%" />
</div>

我们提出的步骤在算法1中进行了总结，两种校准策略如下：

1. 精确PUQ（E-PUQ - 第IV-B1节）：在精确不确定性评估的设置中，假设可以构建并维护d个主成分，满足确切重建属性。因此，校准程序是直接的，只涉及缩放间隔，直到它们包含用户指定的未覆盖偏好 $\alpha \in (0, 1)$ 的投影真实值。这与先前在像素域上的工作类似。

2. 维度自适应PUQ（DA-PUQ - 第IV-B2节，RDA-PUQ - 在线附录D）：在近似不确定性评估的设置中，允许对投影真实实例到全维实例有小的恢复误差，可能是由于复杂性或可解释性原因（见第III节），不再满足确切重建属性。因此，除了上述缩放过程外，我们还必须验证K个主成分可以以小误差分解真实像素值。在此校准过程中，我们还控制最小数量的前 $\hat{k}(x)$ 个主成分，以便可以为未见过的数据保证小的重建误差。这个数字是针对每个输入图像动态确定的，以便相关性更强的实例被分配更多的主成分，相关性较弱的实例则较少。由于手动确定K可能具有挑战性，我们引入了缩减的维度自适应PUQ（RDA-PUQ）程序，它还将控制值作为校准的一部分 - 见在线附录D。

在第V节中，我们展示了与先前工作相比，每种程序的不确定性体积显著减少，无论是全局应用还是局部应用。一方面，E-PUQ程序最简单，可以局部应用于任何任务，并且对于某些任务，如果计算d个主成分是可行的，则可以全局应用。另一方面，DA-PUQ和RDA-PUQ程序更复杂，可以全局或局部应用于任何任务，而在像素表现出强相关性的情况下（例如图像上色任务），这些程序特别有效。我们的方法在图4中以视觉方式说明，显示了使用完整主成分或仅其中一部分的采样方法和校准方案。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/4271b43dad17437ba292a68dc995c717.png#pic_ center" width="70%" />
</div>

## A. 近似阶段的扩散模型
近似阶段，总结在算法1中的红色部分，可以通过多种方式实现。本节中，我们描述了我们用于获得第V节结果的实现方式。虽然我们的目标是以最直接的方式构建不确定性轴和间隔，但对于实现主成分的更先进方法的进一步探索将留待未来的工作。

在我们的实现中，我们利用了基于扩散模型的逆问题的随机回归求解器的最新进展，这使我们能够训练一个机器学习模型从 $\hat{P}_ {Y|X}$ 生成高质量的样本。形式上，我们定义 $f_ {\theta} : X \times Z \rightarrow Y$ 作为全局模式下的逆问题的随机回归求解器，其中Z是噪声种子空间。类似地，在局部模式下，我们考虑 $f_ {\theta} : X \times Z \rightarrow Y_ {\text{patch}}$ 。给定一个输入实例 $x \in \mathbb{R}^d$ ，我们建议生成K个样本，记为 $\{f_ {\theta}(x, z_ i)\}_ 1^K$ ，其中 $f_ {\theta}(x, z_ i) \sim \hat{P}_ {Y|X}$ 。

这些样本用于使用生成样本的奇异值分解（SVD）来估计可能解决方案的主成分及其重要性权重。重要性权重为在投影样本中变化较大的轴分配较高的值，对于变化较小的轴分配较低的值。在第IV-B节中，我们将详细说明这些权重如何在校准阶段中使用。此外，这些样本还用于估计条件均值 $\hat{\mu}(x)$ 和下限与上限 $\tilde{l}(x)$ 和 $\tilde{u}(x)$ ，这些是(1)中必需的。 $\tilde{l}(x)$ 和 $\tilde{u}(x)$ 通过对投影样本到每个主成分上的量化计算得到，具有用户指定的未覆盖比率 $\alpha \in (0, 1)$ 。

为了捕捉 $\hat{P}_ {Y|X}$ 的全部传播和变异性，有必要至少生成K = d个样本以供SVD过程使用，这对于高维数据在计算上是具有挑战性的。作为解决方案，我们建议在补丁上局部工作，其中d很小，并且可以通过用户指定要处理的补丁大小来完全控制。然而，对于像素之间存在强相关性的任务，例如图像上色，少数几个主成分就可以以非常小的误差描述 $\hat{P}_ {Y|X}$ 的变异性。因此，只需要少量样本（即，K ≪ d）来进行SVD过程，以构建整个图像的有意义的主成分，同时捕获 $\hat{P}_ {Y|X}$ 中的大部分丰富性。我们正式总结了我们的基于采样的方法，无论是全局还是局部模式，在算法2中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/daff15b0d0ab433ca3ecb89899e5c849.png#pic_ center" width="70%" />
</div>

## B. 校准阶段
为了完善近似阶段并获得满足(2)和(4)保证的有效不确定性轴和间隔，必须应用校准阶段，总结在算法1中的蓝色部分。这个阶段包括两个基于在构建和维护校准过程中或在推理期间应用全局或局部时主成分数量的特定条件的选项。下面我们更详细地概述每一个选项。

1)精确PUQ: 精确PUQ (E-PUQ) 程序提供了d维后验分布 $P_ {Y|X}$ 的完整不确定性。在这种情况下，第III节中讨论的确切重建属性得到满足，并且(4)以0%的误差（β = 0）在100%（q = 1.0）的像素上得到满足。因此，校准是简单的，只涉及缩放间隔，直到它们以高概率满足(2)，类似于以前在像素域上的工作。

正式地，对于每个输入实例x及其在校准数据中的相应真实值y ∈ ℝ^d，我们使用在近似阶段获得的估计值来获得可能解决方案的d个主成分 $\hat{B}(x)$ ，它们对应的重要性权重 $\hat{w}(x)$ ，条件均值 $\hat{\mu}(x)$ ，以及下限和上限 $\tilde{l}(x)$ 和 $\tilde{u}(x)$ 。然后我们定义缩放间隔为在(1)中指定的，其中上界和下界分别定义为 $\hat{u}(x) := \lambda \tilde{u}(x)$ 和 $\hat{l}(x) := \lambda \tilde{l}(x)$ ，其中λ > 0是控制缩放的可调参数。值得注意的是，随着λ的减小，不确定性间隔的大小减小。我们用 $T_ {\lambda}(x; \hat{B}(x))$ 表示缩放的不确定性间隔。我们使用以下加权覆盖损失函数来指导λ的设计：

$$
L(x, y; \lambda) := \sum_ {i=1}^{d} \hat{w}_ i(x) \cdot \mathbb{1}\left(\hat{v}_ i(x)^T y \notin T_ {\lambda}(x; \hat{B}(x))_ i\right).
$$

这个损失与(2)中的表达式密切相关，虽然一开始看起来可能有些随意，但这个选择是直接扩展到[1], [2]中实践的一个。在在线附录B中，我们为它提供了额外的理由，更符合本文讨论的领域。

我们的目标是确保损失函数L(x, y; λ)的期望低于预设阈值α，以高概率覆盖校准数据。这是通过基于校准预测的校准方案实现的，在我们的论文中，我们使用了LTT [15]程序，它保证了以下条件：

$$
P\left(\mathbb{E}[L(x, y; \hat{\lambda})] \leq \alpha\right) \geq 1 - \delta,
$$

对于一组候选的λ值，给定为集合Λ。δ ∈ (0, 1)是校准集上的错误水平，而 $\hat{\lambda}$ 是在Λ中满足上述条件的最小值，以便在缩放间隔上提供最小的不确定性体积，如(3)中所定义的，我们用V_ λ表示。简单来说，上述保证意味着超过1 - α的投影真实值在λ的不确定性间隔中被包含的概率至少为1 - δ，后者是校准集的随机性。缩放因子考虑到了权重，以确保具有高变异性的不确定性间隔比那些具有低变异性的间隔包含更高比例的投影真实值。这对于像素之间存在强相关性的任务特别重要，其中前几个主成分捕获了可能解决方案中的大部分变异性。我们在算法3中详细描述了E-PUQ程序。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/148b125e331740adb4dc32649e6597c2.png#pic_ center" width="70%" />
</div>

2)维度自适应PUQ: E-PUQ程序假设能够构建和维护d个主成分，这在局部和全局上都可能在计算上具有挑战性。此外，由于涉及的轴数众多，对这些轴的不确定性量化可能不够直观，从而损害了方法的可解释性（见第III节讨论）。为了解决这些问题，我们提出了维度自适应PUQ (DA-PUQ)程序，它使用较少的轴K ≤ d来描述不确定性区域。例如，仅使用前几个主要维度，例如K = 3，可以导致更可解释的不确定性区域，从而在获得的不确定性范围内实现有效的视觉导航。

虽然这种方法不满足确切重建属性（见第III节），但分解的真实值仍然可以通过K个主成分以小的用户定义误差以及覆盖保证来恢复。通过这样做，我们可以以高概率同时实现(2)和(4)中的保证。

为了在提高可解释性的同时满足覆盖和重建保证，我们使用动态函数 $\hat{k}(x) : X \rightarrow \mathbb{N}$ 和一个缩放因子来控制重建和覆盖风险。函数 $\hat{k}(x)$ 确定要包含在不确定性区域内的前K个主成分的数量，重点关注可以同时满足(2)和(4)的最小数量，以增加可解释性。

正式地，对于每个输入实例x及其在校准数据中的相应真实值y ∈ ℝ^d，我们使用在近似阶段获得的估计值来估计可能解决方案的K ≤ d个主成分，记为 $\hat{B}(x)$ ，它们对应的重要性权重记为 $\hat{w}(x)$ ，条件均值记为 $\hat{\mu}(x)$ ，以及下限和上限分别记为 $\tilde{l}(x)$ 和 $\tilde{u}(x)$ 。然后我们引入一个阈值λ1 ∈ (0, 1)，用于在解决方案x的主成分的投影上的重要性权重的衰减。自适应选择要使用的主成分数量定义如下：

$$
\hat{k}(x; \lambda_ 1) := \min_ {1 \leq k \leq K} \{ k \, | \, \sum_ {i=1}^{k} \hat{w}_ i(x) \geq \lambda_ 1 \}.
$$

显然，重要性权重按降序排列，从最重要的轴开始，到最不重要的一个结束。此外，让q ∈ (0, 1)是一个指定的像素比例，β ∈ (0, 1)是在此比例上允许的最大重建误差。要控制的重建损失函数定义为：

$$
L_ 1(x, y; \lambda_ 1) := \hat{Q}_ q \left( \sum_ {j=1}^{\hat{k}(x; \lambda_ 1)} \hat{v}_ j(x)^T (y_ c - \hat{y}_ c) \right),
$$

其中 $\hat{Q}_ q(\cdot)$ 选择重建误差的经验q分位数， $y_ c = y - \hat{\mu}(x)$ 是以 $\hat{\mu}(x)$ 为中心的真实图像。在在线附录C中，我们进一步讨论了这个特定的损失函数，以控制线性子空间捕获完整d维后验分布的能力。

同时，我们还在校准过程中控制覆盖风险，其中α ∈ (0, 1)表示用户指定的可接受未覆盖率，λ2 ∈ ℝ+表示校准因子参数。为了控制这个覆盖风险，我们定义覆盖损失函数与(5)中的相同，但限于前 $\hat{k}(x)$ 个主成分，即：

$$
L_ 2(x, y; \lambda_ 1, \lambda_ 2) := \sum_ {i=1}^{\hat{k}(x; \lambda_ 1)} \hat{w}_ i(x) \cdot \mathbb{1}\left(\hat{v}_ i(x)^T y \notin T_ {\lambda_ 2}(x; \hat{B}(x))_ i\right).
$$

最后，使用(8)中的重建损失函数和(9)中的覆盖损失函数，我们寻求最小化缩放间隔的不确定性体积，其中任何未使用的轴（d个之外的）都被固定为零。我们表示这个不确定性体积为 $V_ {\lambda_ 1, \lambda_ 2}$ 。通过最小化λ1和λ2来实现 $V_ {\lambda_ 1, \lambda_ 2}$ 的最小化，同时确保(2)和(4)的保证以高概率在在校准数据上成立。这可以通过例如LTT [15]校准方案来提供，它保证了以下条件：

$$
P\left(\mathbb{E}[L_ 1(x, y; \hat{\lambda}_ 1)] \leq \beta\right) \geq 1 - \delta, \quad P\left(\mathbb{E}[L_ 2(x, y; \hat{\lambda}_ 1, \hat{\lambda}_ 2)] \leq \alpha\right) \geq 1 - \delta,
$$

其中 $\hat{\lambda}_ 1$ 和 $\hat{\lambda}_ 2$ 是在通过LTT程序获得的有效校准参数结果集合Λ中，不确定性体积的最小化器。换句话说，我们可以在误差不超过β的情况下恢复q比例的真实像素值，并且超过1 - α的投影真实值在前 $\hat{k}(x; \hat{\lambda}_ 1)$ 个 $P_ {Y|X}$ 的主成分上被包含在不确定性间隔内，概率至少为1 - δ。DA-PUQ程序的详细描述在算法4中给出。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/cf00b52102ad440ab42fd8a3213f292a.png#pic_ center" width="70%" />
</div>

上述描述的DA-PUQ程序将主成分的数量减少到K ≤ d，同时使用 $\hat{k}(x; \hat{\lambda}_ 1) ≤ K$ 个主成分，从而在推理过程中提高了时间和空间的效率。然而，手动确定可以保证同时满足(2)和(4)的最小K值可能具有挑战性。为了解决这个问题，我们提出了DA-PUQ程序的扩展；缩减的维度自适应PUQ (RDA-PUQ)程序，它还控制所需的不确定性评估的最大主成分数K。这种方法在推理上是有利的，因为它减少了使用算法2构建主成分所需的样本数量，同时确保(2)和(4)的覆盖和重建保证以高概率成立。RDA-PUQ程序的完整描述在在线附录D中提供。

# V. 实证研究

本节介绍我们提出的PUQ方法在图像着色、超分辨率和修复三项具有挑战性的任务上的全面实证研究，实验基于CelebA-HQ数据集[37]。我们的近似阶段从后验分布的采样开始，在我们的工作中通过SR3条件扩散模型[10]实现。图5展示了这三项任务的典型采样结果，显示了所获得图像的预期多样性。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/4c08112ad7c5429b9f7bef23ab108eb1.png#pic_ center" width="70%" />
</div>

我们的实验验证了我们的方法满足重建和覆盖保证，并证明PUQ与先前的工作，包括im2im-uq[1]和Conffusion[2]相比，提供了更受限制的不确定性区域，通过不确定性体积的进步来证明。此外，通过在恢复真实图像时允许小的重建误差，PUQ用少数几个主成分轴产生紧密的不确定性区域，因此在推理时提高了计算复杂性和可解释性。作为结果，PUQ在图像到图像问题的不确定性量化方面实现了最先进的性能。

在将来的研究中，可以探索更多依赖于最近在随机图像回归模型方面取得的进展的复杂选择，以改善我们提出的近似阶段的复杂性。进一步研究不确定性区域的替代几何形状可能很有趣，以减少提供的不确定性区域与真实后验分布的高密度区域之间的差距。这包括将空间域划分为有意义的段的选项，同时最小化不确定性体积，或考虑估计后验分布样本的高斯混合模型。此外，探索替代的扩散模型和各种条件随机采样器是未来研究的一个有趣途径。这可能涉及比较不同的条件采样器，可能提供一种替代使用FID分数的方法。

## A. 评估指标

在介绍结果之前，我们讨论用于评估不同方法性能的指标。尽管我们的方法被证明对E-PUQ保证了(6)式，对DA-PUQ保证了(10)式（通过LTT[15]），我们也评估了这些保证的有效性和紧密性。

**经验覆盖风险**：我们测量与在不确定性间隔中包含未见过的真实值的投影相关的风险。对于E-PUQ，我们报告平均覆盖损失，定义为(5)式。对于DA-PUQ和RDA-PUQ，我们报告(9)式定义的值。

**经验重建风险**：我们测量使用选定的主成分恢复未见过的真实像素值的风险。对于E-PUQ，根据定义，这个风险是零。然而，对于DA-PUQ和RDA-PUQ，我们报告平均重建损失，定义为(8)式。

**间隔大小**：我们报告校准不确定性间隔的大小(1)，并与基线方法进行比较。对于E-PUQ，我们将整个主成分集的间隔与先前工作中使用的像素域中的间隔进行比较。对于DA-PUQ和RDA-PUQ程序，我们将维度降低到K ≪ d。为了与这些方法在完整d维上的间隔大小进行有效比较，我们假设从降维样本重建真实值的误差可以忽略不计，因此在剩余的d - K维上填充零。

**不确定性体积**：我们报告校准不确定性区域的体积(3)，并与先前的工作进行比较。较小的体积意味着对Py|x的可能解决方案有更高的确信度。在E-PUQ中，我们比较整个主成分集的体积，而对于DA-PUQ和RDA-PUQ程序，我们在剩余维度上填充零。

## B. 局部实验

我们在不同尺寸的RGB块上应用我们提出的方法——1×1、2×2、4×4和8×8——用于图像着色、超分辨率和修复任务。图6和图7展示了获得的结果，其中图6比较了我们的精确程序E-PUQ与基线方法，图7检验了我们的近似程序DA-PUQ和RDA-PUQ。表I展示了在8×8块分辨率下，我们局部应用的PUQ方法的不确定性体积的数值比较。我们在图8中提供了不同分辨率块的不确定性体积图的视觉表示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/20887abb8daa42ec8bb92fd3a7b86c11.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/94b13e0b5a674487b26f48cd0aca3214.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/34849487c5c54636a5d9bc16146f4426.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/ab1ffcb124954660bbe2770a50de8389.png#pic_ center" width="70%" />
</div>

图6显示的结果表明，与所有任务和块分辨率中的先前工作相比，我们的方法提供了更小的不确定性体积，并且在所有情况下都满足相同的统计保证。更具体地说，图6将我们的精确程序E-PUQ与基线方法进行了比较。从这个图中可以看到，使用E-PUQ程序，我们在8×8最高分辨率上的颜色化中获得了约×100的不确定性体积改进，在超分辨率和修复中获得了约×10的改进。此外，随着块分辨率的增加，我们观察到不确定性体积减少的期望趋势，这表明我们的方法考虑了空间相关性以减少不确定性。注意，即使块大小为1×1也会由于在三个颜色通道内利用相关性而在评估体积中带来好处。E-PUQ在应用于标量（1×1×1块）时简化为im2im-uq[1]和Conffusion[2]。

图7检验了我们的近似方法DA-PUQ和RDA-PUQ，我们设置了相对较小的重建风险β = 0.05。观察到获得的显著较小的不确定性体积；这种效果也在表I中总结。图7还描绘了我们的方法使用的不确定性区域的维度，使用两个重叠的条形图表示。外部的黄色条形表示需要构建的主成分数量，分别表示DA-PUQ中的K和RDA-PUQ中的 $\hat{K}$ 。这个数字越小，测试时的计算复杂性越低。内部的绿色条形表示平均选择的主成分数量，表示为 $\hat{k}(x)$ 。较低的 $\hat{k}(x)$ 值表示更好的可解释性，因为在推理时使用的主成分轴少于构建时的主成分轴。例如，在颜色化任务中，可以看到RDA-PUQ程序是最具计算效率的方法，只需要在推理时构建大约12个主成分，而DA-PUQ程序的结果最具可解释性，不确定性区域仅由 $\hat{k}(x) \in \{1, 2, 3\}$ 轴组成。

在图6和图7展示的所有实验中，可以注意到我们方法的间隔大小的标准差高于基线方法。这种效果是因为前几个主成分的一些间隔比其余主成分的间隔宽。然而，大多数间隔大小明显较小，结果是不确定性体积要小得多。有趣的是，图7中的DA-PUQ和RDA-PUQ程序的间隔大小的标准差比图6中的E-PUQ程序要大。我们推测这是由于在用户设置了较小的覆盖率(α=0.1)时，只有少数几个间隔（例如，2个间隔）用于校准过程。以使用2个间隔和校准集中的所有样本为例，必须扩大所有间隔以确保覆盖保证，导致前几个主成分的间隔扩大。

图8中呈现的热图比较了基于块的E-PUQ程序与基线方法的不确定性体积。每个呈现的热图中的像素对应于其相应块上评估的(3)式中的值。结果表明，随着块分辨率的增加，具有强相关结构的像素，如背景区域的像素，在其相应的块中也表现出较低的不确定性体积。这表明所提出的方法确实考虑了空间相关性，从而减少了不确定性体积。

## C. 全局实验

我们转而检验DA-PUQ和RDA-PUQ在完整图像上应用的有效性和有效性，分辨率为128×128。在这种情况下，E-PUQ程序不适用，因为它需要计算和维护d = 128×128×3主成分。我们在此展示颜色化任务的结果，并请读者参考在线附录G[37]，其中有关于超分辨率和修复的类似分析。

虽然所有PUQ程序都可以局部应用于任何任务，但在表现出强像素相关性的全局任务中工作更为现实。在这种情况下，大部分图像变异性可以通过DA-PUQ或RDA-PUQ来表示，同时(i)保持小的重建风险，(ii)仅使用少数几个主成分轴来评估整个图像的不确定性。我们应该注意，超分辨率和修复任务不太适合全局模式，因为它们需要更多的主成分来有效表示不确定性——更多相关内容在在线附录G[37]中讨论。

图9直观地展示了我们近似方法的性能，也在表II中总结。这些结果表明，与我们在图7中的局部结果和先前的工作相比，我们的方法提供了明显更小的不确定性体积，但这是以引入高达β = 0.1的小重建风险为代价的。观察我们的近似方法如何提高可解释性：不确定性区域仅由整个图像的完整维度空间中的2-5个主成分组成。DA-PUQ程序产生了最紧密的不确定性区域；参见表II中的不确定性体积。此外，我们程序的平均间隔大小非常小，几乎等于零，表明由于像素之间的强相关结构，构建的不确定性区域是紧密和狭窄的。然而，与之前的结果类似，间隔大小的标准差跨越了一个宽范围。这是因为前几个主成分有宽间隔。RDA-PUQ程序在计算上最有效，因为在推理时只需要构建大约30个主成分就可以确保统计有效性。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/2b15d5c053f149c1b36116c98716283b.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/f412bde15eb84ea9b84d32b40b0db919.png#pic_ center" width="70%" />
</div>

图10展示了我们提出的RDA-PUQ程序全局应用时提供的选定不确定性区域。可以看到，仅使用 $\hat{k}(x)$ 主成分投影的真实图像与原始图像非常接近。这表明不确定性区域可以用小的重建误差描述解决方案之间的传播和变异性。我们不确定性区域的前两个轴展示语义内容，这与考虑像素空间相关性的方法一致。这些主成分捕获前景/背景或完整对象内容的事实突出了我们方法的独特优势。我们提供了前两个主成分的重要性权重，表明这些分量在投影样本中的变异性比例令人印象深刻（见第IV-A节）。例如，在第三行中，我们观察到77%的变异性由 $\hat{v}_ 1(x)$ 捕获，它主要控制与图像中的帽子相关的像素的线性颜色范围。在图11中，我们通过从相应的估计不确定性区域中均匀采样高维点（即图像），直观地比较了从相应估计不确定性区域生成的样本。有关此研究的更多详细信息，请参见在线附录F[37]。可以看到，从我们的不确定性区域提取的样本具有高感知质量，而im2im-uq[1]和Conffusion[2]则产生了高度不可能的图像。这证明了我们的方法提供了更受限制的不确定性区域，而先前的工作则导致包含不太可能图像的夸大区域。此外，在在线附录J[37]中，我们展示了我们方法产生的不确定性区域的下角和上角的可视化，将其与先前的工作[1]、[2]产生的区域进行了比较。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/0973e8b2289244b0b1e0f4a3d228a761.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/1e3fbf018ed94de5a98783d85b4d143f.png#pic_ center" width="70%" />
</div>

# VI. 结论

本文介绍了“主要不确定性量化”(PUQ)，这是一种新颖有效的量化任何图像到图像任务中不确定性的方法。PUQ考虑像素之间的空间依赖性，以实现明显更紧密的不确定性区域。实验结果表明，PUQ在图像着色、超分辨率和修复方面，通过提高不确定性体积，优于现有的方法。此外，通过在恢复真实图像时允许小的重建误差，PUQ用少数几个轴产生紧密的不确定性区域，从而在推理时提高了计算复杂性和可解释性。因此，PUQ在图像到图像问题的不确定性量化方面实现了最先进的性能。

关于未来研究，可以探索更多依赖于最近在随机图像回归模型方面取得的进展的复杂选择，以改善我们提出的近似阶段的复杂性。进一步研究不确定性区域的替代几何形状可能很有趣，以减少提供的不确定性区域与真实后验分布的高密度区域之间的差距。这包括将空间域划分为有意义的段的选项，同时最小化不确定性体积，或考虑估计后验分布样本的高斯混合模型。此外，探索替代的扩散模型和各种条件随机采样器是未来研究的一个有趣途径。这可能涉及比较不同的条件采样器，可能提供一种替代使用FID分数的方法。
# 声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
