# 题目：[Deep Lossy Plus Residual Coding for Lossless and Near-Lossless Image Compression](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10378746)  
## 深度有损加残差编码用于无损和近无损图像压缩
**作者：Yuanchao Bai; Xianming Liu; Kai Wang; Xiangyang Ji; Xiaolin Wu; Wen Gao** 

****
# 摘要
无损和近无损图像压缩对于许多技术领域的专业用户至关重要，如医学、遥感、精密工程和科学研究。然而，尽管基于学习的图像压缩研究兴趣迅速增长，但没有任何已发表的方法同时提供无损和近无损模式。在本文中，我们提出了一种统一且强大的深度有损加残差 (DLPR) 编码框架，用于无损和近无损图像压缩。在无损模式下，DLPR 编码系统首先执行有损压缩，然后对残差进行无损编码。我们采用 VAEs 方法解决联合有损和残差压缩问题，并添加残差的自回归上下文建模以增强无损压缩性能。在近无损模式下，我们量化原始残差以满足给定的 $\ell_ \infty$ 误差界限，并提出了一种可扩展的近无损压缩方案，适用于可变 $\ell_ \infty$ 界限，而不是训练多个网络。为了加速 DLPR 编码，我们通过一种新颖的编码上下文设计提高了算法并行度，并通过自适应残差区间加速了熵编码。实验结果表明，DLPR 编码系统在无损和近无损图像压缩方面均达到了最先进的性能，并具有竞争力的编码速度。

# 关键词
- 深度学习
- 图像压缩
- 无损压缩
- 近无损压缩
- 有损加残差编码




## I. 引言

在许多重要的技术领域，如医学、遥感、精密工程和科学研究，高空间、光谱和时间分辨率的成像对于发现和创新至关重要。随着现代成像技术可实现的分辨率稳步提高，用户被随之产生的海量图像和视频数据淹没。例如，病理成像扫描仪每个样本可以轻松生成1 GB或更多的数据。为了实现成本效益和系统可操作性（例如，通过云实时访问高保真视觉对象），必须对多维高分辨率获取的原始图像进行压缩。

与消费应用（例如，智能手机和社交媒体）不同，用户主要关注解压缩图像的外观，并且在信号级别上可以对压缩失真视而不见，高保真度的解压缩图像对于许多技术领域的专业用户至关重要。在后者的情况下，目前的金标准是数学上的无损图像压缩。香农的源编码定理确立了无损图像压缩的理论基础，证明了给定图像数据的实际概率分布下预期码长的下限，即信息熵。实际上，任何特定无损图像编解码器的压缩性能取决于它在多大程度上可以逼近未知的实际概率分布，以接近理论下限。尽管研究多年，传统无损图像编解码器的典型压缩比仍然在2:1到3:1之间。另一种在保持解压缩图像高保真的同时提高压缩性能的方法是近无损图像压缩。近无损图像压缩不是数学上的无损，而是对解压缩图像施加严格的 $\ell_ \infty$ 约束，要求每个像素的最大重建误差不大于给定的紧数值界限。通过引入 $\ell_ \infty$ 约束误差界限，近无损图像压缩可以保证每个像素的可靠性，同时打破无损图像压缩的理论压缩限制。当紧误差界限设置为零时，近无损图像压缩等同于无损图像压缩。传统的无损图像编解码器，如 JPEG-LS 和 CALIC，为用户提供无损和近无损图像压缩，以满足各种成像和视觉系统的带宽和成本效益要求。

随着深度神经网络（DNNs）的快速进步，基于学习的图像压缩在过去五年中取得了巨大进展。然而，大多数这些方法是为率失真优化的有损图像压缩设计的，即使在比特率充足的情况下也无法实现无损或近无损图像压缩。最近，许多研究团队开始开发端到端优化的无损图像压缩方法。这些方法利用复杂的深度生成模型，如自回归模型、流模型和变分自编码器（VAE）模型，学习给定图像数据的未知概率分布，并根据学习到的模型将图像数据熵编码为比特流。虽然实现了优于传统无损图像编解码器的出色压缩性能，但现有基于学习的无损图像方法通常编码速度过慢，难以应用于实际全分辨率图像压缩任务。此外，与传统的 JPEG-LS 和 CALIC 不同，除了我们最近的工作之外，没有研究进行基于学习的近无损图像压缩，尽管如上所述，这具有巨大的潜力。

在本文中，我们提出了一种统一且强大的深度有损加残差（DLPR）编码框架，用于无损和近无损图像压缩，较大程度上解决了基于学习的无损图像压缩的挑战。DLPR 编码系统的显著特点包括：最先进的无损和近无损图像压缩性能、单个网络实现的可扩展近无损图像压缩，具有可变的 $\ell_ \infty$ 界限，并在2K分辨率图像上具有竞争力的编码速度。具体而言，对于无损图像压缩，DLPR 编码系统首先执行有损压缩，然后对残差进行无损编码。有损图像压缩器和残差压缩器均设计了先进的神经网络架构。我们采用 VAEs 方法解决联合有损图像和残差压缩问题，并添加残差的自回归上下文建模以增强无损压缩性能。注意，我们的 VAE 模型不同于基于变换编码的 VAE 简单有损图像压缩或基于比特返回编码的 VAEs 无损图像压缩。对于近无损图像压缩，我们量化原始残差以满足给定的 $\ell_ \infty$ 误差界限，并压缩量化的残差，而不是原始残差。为了实现具有可变 $\ell_ \infty$ 误差界限的可扩展近无损压缩，我们通过量化用于无损压缩的学习概率模型，导出量化残差的概率模型，而不是训练多个网络。由于残差量化导致训练和推理之间的上下文不匹配，我们提出了一种具有偏差校正方案的可扩展量化残差压缩器，以校正导出的概率模型的偏差。为了加速 DLPR 编码，瓶颈在于残差和量化残差压缩中的串行自回归上下文模型。因此，我们提出了一种新颖的编码上下文设计，以提高算法的并行度，并通过自适应残差区间进一步加速熵编码。最后，无损或近无损压缩图像包括编码的有损图像、编码的原始残差或量化残差的比特流。

总之，本研究的主要贡献如下：

- 我们提出了一个统一的 DLPR 编码框架，实现无损和近无损图像压缩。该框架可以解释为 VAE 模型并进行端到端优化。尽管传统的无损图像编解码器（如 JPEG-LS 或 CALIC）支持无损和近无损模式，但我们是第一个在基于学习的图像压缩中支持这两种模式的。
- 我们实现了具有可变 $\ell_ \infty$ 误差界限的可扩展近无损图像压缩。给定 $\ell_ \infty$ 界限，我们量化原始残差并从无损图像压缩的学习概率模型导出量化残差的概率模型，而不是训练多个网络。偏差校正方案进一步提高了压缩性能。
- 为了加速 DLPR 编码系统，我们提出了一种新颖的编码上下文设计，以提高算法的并行度而不损害压缩性能。同时，我们进一步引入了自适应残差区间方案，以减少熵编码时间。

实验结果表明，DLPR 编码系统在无损和近无损图像压缩方面均达到了最先进的性能，并在高比特率下实现了竞争力的 PSNR，同时比有损图像编解码器具有更小的 $\ell_ \infty$ 误差。此外，DLPR 编码系统在运行时间方面是实用的，可以在几秒钟内压缩和解压缩2K分辨率图像。

注意，这篇论文是我们最近工作的非平凡扩展。首先，本文专注于无损和近无损图像压缩，而不仅仅是近无损图像压缩。其次，我们改进了有损图像压缩器、残差压缩器和可扩展量化残差压缩器的网络架构，超越了我们之前的工作，导致更强大而简洁的 DLPR 编码系统。第三，为了加速 DLPR 编码系统，我们引入了一种新颖的上下文编码设计，以提高算法并行度，并引入了自适应残差区间方案，以加速熵编码。最后，我们进行了全面的实验，表明最终的 DLPR 编码系统在无损和近无损图像压缩方面达到了最先进的性能，显著优于我们之前工作的原型，同时享有更快的编码速度。

本文的其余部分组织如下。我们在第二节简要回顾了相关工作。在第三节中，我们理论分析了无损和近无损图像压缩问题，并提出了 DLPR 编码框架。第四节介绍了 DLPR 编码框架的网络架构和加速。第五节和第六节分别是实验和结论。


## III. 深度有损加残差编码

在本节中，我们介绍了一个用于无损和近无损图像压缩的 DLPR 编码框架，通过将有损图像压缩与残差压缩相结合。我们在理论上分析了无损和近无损图像压缩问题，并以 VAEs 的形式构建了 DLPR 编码框架。

### A. 用于无损图像压缩的 DLPR 编码

无损图像压缩保证原始图像从压缩的比特流中完美重建。假设原始图像 $x$ 是从未知概率分布 $p(x)$ 中采样的，使用无损图像压缩的压缩图像的最短期望码长在理论上由信息熵下界

$$
H(p) = E_ {p(x)}[- \log p(x)].
$$

实际上，任何特定无损图像压缩方法的压缩性能取决于它如何用底层模型 $p_ \theta(x)$ 逼近 $p(x)$。相应的压缩性能由交叉熵给出

$$
H(p, p_ \theta) = E_ {p(x)}[- \log p_ \theta(x)] \geq H(p),
$$

其中 $H(p, p_ \theta)$ 仅在 $p_ \theta(x) = p(x)$ 时成立。





为了逼近 $p(x)$，广泛使用潜变量模型 $p_ \theta(x)$ 来实现这一目的，并通过边缘分布公式化

$$
p_ \theta(x) = \int p_ \theta(x,y) dy = \int p_ \theta(x|y) p_ \theta(y) dy,
$$

其中 $y$ 是未观察到的潜变量， $\theta$ 表示该模型的参数。由于直接学习 $p_ \theta(x)$ 的边缘分布通常是不可行的，另一种方法是通过 VAEs 优化证据下界（ELBO）。通过引入推理模型 $q_ \phi(y|x)$ 以逼近后验 $p_ \theta(y|x)$，边缘似然 $p_ \theta(x)$ 的对数可以重写为

$$
\log p_ \theta(x) = E_ {q_ \phi(y|x)} \log \frac{p_ \theta(x,y)}{q_ \phi(y|x)} + E_ {q_ \phi(y|x)} \log \frac{q_ \phi(y|x)}{p_ \theta(y|x)},
$$

其中 $D_ {KL}(\cdot \| \cdot)$ 是 Kullback-Leibler（KL）散度。 $\phi$ 表示推理模型 $q_ \phi(y|x)$ 的参数。由于 $D_ {KL}(q_ \phi(y|x) \| p_ \theta(y|x)) \geq 0$ 且 $\log p_ \theta(x) \leq 0$，ELBO 是 $\log p_ \theta(x)$ 的下界。因此，我们有

$$
E_ {p(x)}[- \log p_ \theta(x)] \leq E_ {p(x)} E_ {q_ \phi(y|x)} \left[ - \log \frac{p_ \theta(x,y)}{q_ \phi(y|x)} \right],
$$

并且可以最小化负 ELBO 的期望作为期望码长 $E_ {p(x)}[- \log p_ \theta(x)]$ 的代理。

为了最小化负 ELBO 的期望，我们提出了一个 DLPR 编码框架。我们首先采用基于变换编码的有损图像压缩来压缩原始图像 $x$ 并获得其有损重建 $\tilde{x}$。负 ELBO 的期望可以重新公式化为：

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(r|\tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中 $\hat{y}$ 是连续潜在表示 $y$ 的量化结果， $y$ 是由 $x$ 决定性变换得到的。像以前的工作一样，我们通过从 $U(- \frac{1}{2}, \frac{1}{2})$ 添加噪声来放松 $y$ 的量化，并假设 $q_ \phi(\hat{y}|x) = \prod_ i U(y_ i - \frac{1}{2}, y_ i + \frac{1}{2})$。因此， $\log q_ \phi(\hat{y}|x) = 0$ 从公式中删除。对于简单的有损图像压缩，公式的第二项可以视为 $x$ 和其有损重建 $\tilde{x}$ 之间的失真损失。第三项可以视为有损图像压缩的码率损失。只需将 $\hat{y}$ 编码为比特流并存储。

除了有损图像压缩外，我们还考虑了残差压缩。残差 $r$ 由 $r = x - \tilde{x}$ 计算得到。我们有以下命题 1。

**命题 1**： $p_ \theta(x| \hat{y}) = p_ \theta(\tilde{x}, r| \hat{y}) = p_ \theta(r| \tilde{x}, \hat{y})$。

**证明**：对于每个 $x$ 和所有 $(\tilde{x}, r)$ 对，满足 $\tilde{x} + r = x$，我们有 $p_ \theta(x| \hat{y}) = \sum_ {\tilde{x}+r=x} p_ \theta(\tilde{x}, r| \hat{y})$。根据贝叶斯规则，我们有 $p_ \theta(\tilde{x}, r| \hat{y}) = p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y})$。因此，我们有 $p_ \theta(x| \hat{y}) = \sum_ {\tilde{x}+r=x} p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y})$。由于有损重建 $\tilde{x}$ 是由 $\hat{y}$ 的决定性逆变换计算得到的，只有一个 $\tilde{x}$ 满足 $p_ \theta(\tilde{x}| \hat{y}) = 1$，其他 $\tilde{x}$ 的 $p_ \theta(\tilde{x}| \hat{y}) = 0$。因此，我们可以得到 $p_ \theta(x| \hat{y}) = p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y}) + \sum 0 = p_ \theta(\tilde{x}, r| \hat{y}) = 1 \cdot p_ \theta(r| \tilde{x}, \hat{y}) = p_ \theta(r| \tilde{x}, \hat{y})$。

基于上述公式和命题 1，我们用 $p_ \theta(r| \tilde{x}, \hat{y})$ 替代 $p_ \theta(x| \hat{y})$ 并实现 DLPR 编码公式

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(r| \tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中第一项 $R_ r$ 和第二项 $R_ {\hat{y}}$ 是使用 $p_ \theta(r| \tilde{x}, \hat{y})$ 和 $p_ \theta(\hat{y})$ 熵编码 $r$ 和 $\hat{y}$ 的期望码长。在训练过程中，我们通过从 $U(- \frac{1}{2}, \frac{1}{2})$ 添加噪声来放松 $\tilde{x}$ 的量化，并有 $\log p_ \theta(\tilde{x}| \hat{y}) = 0$，与命题 1 的前提一致。由于上述公式等价于负 ELBO 的期望，所提出的 DLPR 编码框架是期望码长 $E_ {p(x)}[- \log p_ \theta(x)]$ 的上限，并且可以作为代理进行最小化。

注意，上述公式中没有指定有损图像压缩的失真损失。因此，我们可以嵌入任意有损图像压缩器，并最小化公式以实现无损图像压缩。一个特例是以前的无损图像压缩方法，其中 BPG 有损图像压缩器使用学习的量化参数分类器最小化 $- \log p_ \theta(\hat{y})$，基于 CNN 的残差压缩器最小化 $- \log p_ \theta(r| \tilde{x})$。

### B. 用于近无损图像压缩的 DLPR 编码

我们进一步扩展 DLPR 编码框架以实现近无损图像压缩。给定一个紧的 $\ell_ \infty$ 误差界限 $\tau \in \{1, 2, \ldots \}$，近无损方法压缩原始图像 $x$ 满足以下失真约束：

$$
D_ {nll}(x, \hat{x}) = \| x - \hat{x} \|_  \infty = \max_ {i,c} | x_ {i,c} - \hat{x}_ {i,c} | \leq \tau,
$$

其中 $\hat{x}$ 是原始图像 $x$ 的近无损重建。 $x_ {i,c}$ 和 $\hat{x}_ {i,c}$ 是 $x$ 和 $\hat{x}$ 的像素。 $i$ 表示预定义扫描顺序中的第 $i$ 个空间位置， $c$ 表示第 $c$ 个通道。如果 $\tau = 0$，近无损图像压缩等同于无损图像压缩。

为了满足 $\ell_ \infty$ 约束，我们通过量化残差来扩展 DLPR 编码框架。首先，我们仍然通过有损图像压缩获得原始图像 $x$ 的有损重建 $\tilde{x}$。尽管有损图像压缩方法在相对低的比特率下可以实现高 PSNR 结果，但这些方法难以确保 $\tilde{x}$ 中每个像素的紧误差界限 $\tau$。然后我们计算残差 $r = x - \tilde{x}$ 并假设 $r$ 被量化为 $\hat{r}$。令 $\hat{x} = \tilde{x} + \hat{r}$，重建误差 $x - \hat{x}$ 等同于 $r$ 的量化误差 $r - \hat{r}$。因此，我们采用均匀残差量化器，其箱大小为 $2\tau + 1$，量化值为

$$
\hat{r}_  {i,c} = \text{sgn}(r_ {i,c}) \cdot (2\tau + 1) \left\lfloor \frac{|r_ {i,c}| + \tau}{2\tau + 1} \right\rfloor,
$$

其中 $\text{sgn}(\cdot)$ 表示符号函数。 $r_ {i,c}$ 和 $\hat{r}_ {i,c}$ 是 $r$ 和 $\hat{r}$ 的元素。通过上述公式，对于 $\hat{r}$ 中的每个 $\hat{r}_ {i,c}$，我们现在有 $|r_ {i,c} - \hat{r}_ {i,c}| \leq \tau$，满足紧误差界限。由于残差量化是确定性的，用于近无损图像压缩的 DLPR 编码框架可以公式化为

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(\hat{r}| \tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中第一项 $R_ {\hat{r}}$ 是使用 $p_ \theta(\hat{r}| \tilde{x}, \hat{y})$ 而非原始残差 $r$ 熵编码 $\hat{r}$ 的期望码长。最后，我们将 $\hat{r}$ 的比特流与 $\hat{y}$ 的比特流连接，得到近无损图像压缩结果。

## IV. 网络架构和加速

### A. DLPR 编码的网络架构

我们提出了 DLPR 编码框架的网络架构，包括有损图像压缩器（LIC）、残差压缩器（RC）和可扩展量化残差压缩器（SQRC），如图所示。通过 LIC 和 RC，我们实现了用于无损图像压缩的 DLPR 编码。通过 LIC 和 SQRC，我们进一步实现了具有单一网络的可变 $\ell_ \infty$ 界限的可扩展近无损图像压缩。我们在以下小节中详细说明每个组件。

###### 1. 有损图像压缩器

在 LIC 中，我们采用复杂的图像编码器和解码器，同时使用高效的超先验模型，如图所示。图像编码器 $g_ e(\cdot)$ 和解码器 $g_ d(\cdot)$ 由分析、合成和 Swin-Attention 块组成，遵循残差和自注意学习的理念，如图所示。在 Swin-Attention 块中，我们采用基于窗口和移位窗口的多头自注意力（W-MSA/SW-MSA），自适应地在局部窗口内和跨窗口聚合信息，提高了 $g_ e(\cdot)$ 和 $g_ d(\cdot)$ 的表示能力，同时计算复杂度适中。通过 $g_ e(\cdot)$ 和 $g_ d(\cdot)$，我们将输入的原始图像 $x$ 转换为其潜在表示 $y = g_ e(x)$，将 $y$ 量化为 $\hat{y} = Q(y)$，并逆转换 $\hat{y}$ 为有损重建 $\tilde{x} = g_ d(\hat{y})$。

由于复杂的图像编码器和解码器可以大幅减少 $x$ 中的空间冗余，我们决定采用高效的超先验模型而无需任何上下文模型，以确保在 GPU 上的编码并行性。超先验模型提取边信息 $\hat{z} = Q(h_ e(y))$，以建模 $\hat{y}$ 的概率分布，其中 $h_ e(\cdot)$ 是超编码器。我们假设 $p_ \theta(\hat{y}| \hat{z})$ 的分解高斯分布模型 $N(\mu, \sigma) = h_ d(\hat{z})$，其中 $h_ d(\cdot)$ 是超解码器，并为 $p_ \theta(\hat{z})$ 假设一个非参数化分解密度模型。因此， $R_ {\hat{y}, \hat{z}}$ 被扩展为

$$
R_ {\hat{y}, \hat{z}} = E_ {p(x)} E_ {q_ \phi(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(\hat{y}| \hat{z}) - \log p_ \theta(\hat{z}) ],
$$

其中 $R_ {\hat{y},\hat{z}}$ 是编码 $\hat{y}$ 和 $\hat{z}$ 的成本。

![](https://img-blog.csdnimg.cn/direct/71965724e10a4575bd27b81a28e9533c.png)



###### 2. 残差压缩器

给定原始图像 $x$ 和由 LIC 生成的有损重建 $\tilde{x}$，我们得到残差 $r = x - \tilde{x}$。接下来我们介绍 RC，以估计 $r$ 的概率质量函数（PMF）并相应地使用算术编码对 $r$ 进行压缩。

表示为 $u = g_ u(\hat{y})$，其中特征 $u$ 由 $g_ u(\cdot)$ 从 $\hat{y}$ 生成。 $g_ u(\cdot)$ 和图像解码器 $g_ d(\cdot)$ 共享网络，除了最后一层卷积层，如图所示。我们将 $u$ 解释为给定 $\tilde{x}$ 和 $\hat{y}$ 的残差 $r$ 的特征。特征 $u$ 与 $r$ 具有相同的高度和宽度，并有 256 个通道。与通过图像编码器大幅减少空间冗余的潜在表示 $\hat{y}$ 不同，像素域中的残差 $r$ 具有无法通过特征 $u$ 完全利用的空间冗余。因此，我们进一步引入自回归模型到 $r$ 的统计建模中，得到

$$
p_ \theta(r| \tilde{x}, \hat{y}) = p_ \theta(r| u) = \prod_ {i,c} p_ \theta(r_ {i,c}| u, r_ {<(i,c)}),
$$

其中 $r_ {<(i,c)}$ 表示预定义扫描顺序中在 $r_ {i,c}$ 之前编码或解码的 $r$ 元素。实际上，我们使用具有特定感受野的掩码卷积层实现空间自回归模型，而不是依赖于 $r_ {<(i,c)}$ 的所有元素。我们将掩码卷积层的感受野视为上下文 $C_ r$。基于上述公式和 $C_ r$，我们将 $R_ r$ 重新公式化为

$$
R_ r = E_ {p(x)} E_ {q_ \phi(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(r| u, C_ r) ].
$$

具体来说，我们利用一个 7×7 掩码卷积层来从 $r_ {<(i,c)}$ 中提取上下文 $C_ {r_ i} \in C_ r$。 $C_ {r_ i}$ 被所有通道的 $r_ {i,c}$ 共享。对于具有三个通道的 RGB 图像，我们有

$$
p_ \theta(r| u, C_ r) = \prod_ i p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i}).
$$

我们进一步采用通道自回归方案对 $r_ {i,1}, r_ {i,2}, r_ {i,3}$ 进行处理，并将 $p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i})$ 重新公式化为

$$
p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i}) = p_ \theta(r_ {i,1}| u_ i, C_ {r_ i}) \cdot p_ \theta(r_ {i,2}| r_ {i,1}, u_ i, C_ {r_ i}) \cdot p_ \theta(r_ {i,3}| r_ {i,1}, r_ {i,2}, u_ i, C_ {r_ i}).
$$

我们使用离散逻辑混合似然来建模 $r_ {i,c}$ 的 PMF，并提出了一个子网络来估计相应的熵参数，包括混合权重 $\pi_ k^i$、均值 $\mu_ k^{i,c}$、方差 $\sigma_ k^{i,c}$ 和混合系数 $\beta_ i^t$。 $k$ 表示第 $k$ 个逻辑分布的索引。 $t$ 表示 $\beta$ 的通道索引。熵模型的网络架构如图所示。我们使用五个逻辑分布的混合。通道自回归方案通过更新均值实现

$$
\tilde{\mu}_ k^{i,1} = \mu_ k^{i,1}, \tilde{\mu}_ k^{i,2} = \mu_ k^{i,2} + \beta_ i^1 \cdot r_ {i,1}, \tilde{\mu}_ k^{i,3} = \mu_ k^{i,3} + \beta_ i^2 \cdot r_ {i,1} + \beta_ i^3 \cdot r_ {i,2}.
$$

通过 $\pi_ k^i, \tilde{\mu}_ k^{i,c}$ 和 $\sigma_ k^{i,c}$，
对于离散 $r_ {i,c}$，我们评估
$$
\sum_{k=1}^K \pi_k^i \left[ S\left( \frac{r_{i,c}^+ - \tilde{\mu}_ k^{i,c}}{\sigma_k^{i,c}} \right) - S\left( \frac{r_{i,c}^- - \tilde{\mu}_k^{i,c}}{\sigma_k^{i,c}} \right) \right],
$$

其中 $S(\cdot)$ 表示 sigmoid 函数。 $r_ {i,c}^+ = r_ {i,c} + 0.5$ 和 $r_ {i,c}^- = r_ {i,c} - 0.5$。残差的概率推理方案如图所示。

###### 3. 可扩展量化残差压缩器

我们最终引入 SQRC，以实现具有可变 $\ell_ \infty$ 界限 $\tau \in \{1, 2, \ldots\}$ 的可扩展近无损图像压缩。尽管给定特定 $\tau$ 的近无损图像压缩可以通过优化公式实现，但这种特定 $\tau$ 方案导致两个问题：

- 残差量化的松弛问题：与舍入量化不同，残差量化的箱大小要大得多。此外，原始残差在每个箱中的分布并不均匀，因此无法通过添加均匀噪声来松弛。
- 多网络的存储问题：为了部署近无损编解码器，我们必须传输和存储针对不同 $\tau$ 的多个网络，这在存储方面效率低下。

相反，我们提出了一种可扩展的近无损图像压缩方案，该方案可以避免残差量化的松弛，并使用单一网络满足可变 $\ell_ \infty$ 误差界限 $\tau \in \{1, 2, \ldots\}$。具体来说，这种可扩展压缩方案基于 DLPR 编码框架的学习无损压缩。我们保持有损重建 $\tilde{x}$ 不变，并通过量化公式对原始残差 $r$ 进行量化以获得可变 $\tau$ 的 $\hat{r}$。为了编码量化后的 $\hat{r}$，我们可以从学习的原始 $r$ 的 PMF 推导出 $\hat{r}$ 的 PMF。给定 $\tau$ 和学习的原始 $r_ {i,c}$ 的 PMF 
我们在图中展示了一个说明性示例。结合前面的公式，我们可以推导出量化残差 $\hat{r}$ 的概率模型 $\hat{p}_ \theta(\hat{r}| u, C_ r)$，该模型在给定学习的原始 $r$ 的 $p_ \theta(r| u, C_ r)$ 的情况下是最优的。随着 $\tau$ 的增加，编码量化残差 $\hat{r}$ 的成本显著降低，记为 $R_ \tau^{\hat{r}}$。

然而，用 $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 编码 $\hat{r}$ 导致比特流无法解码，因为解码器不知道原始残差 $r$。没有 $r_ {i,<c}$ 和因果上下文 $C_ {r_ i}$ 就无法评估 $\hat{p}_ \theta(\hat{r}_ {i,c}| r_ {i,<c}, u_ i, C_ {r_ i})$。相反，我们可以使用量化后的残差 $\hat{r}$ 进行 PMF 评估，即评估 $p_ \theta(r_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$ 并通过量化公式推导出 $\hat{p}_ \theta(\hat{r}_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$，从而得到用于编码 $\hat{r}$ 的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$。由于训练阶段（使用 $r$）和推理阶段（使用 $\hat{r}$）之间的不匹配，导致 PMF $p_ \theta(r_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$、 $\hat{p}_ \theta(\hat{r}_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$ 和 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 有偏。上述概率推理方案如图所示。

![](https://img-blog.csdnimg.cn/direct/043bba34ef8d470f93a0ae44a5967e98.png)


#### SQRC 偏差校正

由于 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 和偏置的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 之间的差异，用 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 编码 $\hat{r}$ 降低了压缩性能。

为了解决这个问题，我们提出了 SQRC 偏差校正，以缩小 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 和偏置 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 之间的差距，同时生成的比特流仍然可解码。SQRC 的组件如图所示。SQRC 中的掩码卷积层与 RC 中的共享。条件熵模型的网络架构与图示的熵模型相同，但用图示的条件卷积层替换卷积层。

带有 SQRC 的概率推理方案如图所示。对于 $\tau = 0$，我们仍然选择 RC 中的熵模型来估计 $p_ \theta(r| u, C_ r)$ 以编码 $r$。对于 $\tau \in \{1, 2, \ldots, N\}$，我们选择 SQRC 中的条件熵模型来估计条件 $\tau$ 下的 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$。然后我们通过量化公式推导出 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 以编码 $\hat{r}$，其中 $\theta$ 表示 SQRC 的参数。由于 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 比偏置的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 更接近 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$，压缩性能可以提高。由于评估 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 与 $r$ 无关，生成的比特流是可解码的。在实验中，我们证明了带有 SQRC 的可扩展近无损压缩方案可以超过 $\tau$ 特定的近无损方案和没有 SQRC 的可扩展近无损压缩方案。


![](https://img-blog.csdnimg.cn/direct/f80ccd1f4b44410b9c34057281ddc527.png)

![](https://img-blog.csdnimg.cn/direct/93365bf0859c4cd5a60975423ccf39f0.png)

![](https://img-blog.csdnimg.cn/direct/70d7760238bd4b2c9171f389209e6c59.png)


### B. DLPR 编码的训练策略

###### 1. 训练 LIC 和 RC

联合优化 LIC 和 RC 的完整损失函数，即用于无损图像压缩的 DLPR 编码，是

$$
L(\theta, \phi) = R_ {\hat{y}, \hat{z}} + R_ r + \lambda \cdot D_ {ls},
$$

其中 $\theta$ 和 $\phi$ 是 LIC 和 RC 的学习参数。除了码率项 $R_ {\hat{y}, \hat{z}}$ 和 $R_ r$，我们还引入失真项 $D_ {ls}(x, \tilde{x})$ 以最小化原始图像 $x$ 和其有损重建 $\tilde{x}$ 之间的均方误差（MSE）

$$
D_ {ls}(x, \tilde{x}) = E_ {p(x)} E_ {i,c} (x_ {i,c} - \tilde{x}_ {i,c})^2.
$$

如前期工作所述，最小化 MSE 损失等同于学习一个将残差 $r$ 拟合到分解高斯分布的 LIC。然而， $r$ 的真实分布与分解高斯分布之间的差异通常很大。因此，我们在 DLPR 编码框架中使用复杂的离散逻辑混合似然模型来编码 $r$。

公式中的 $\lambda$ 是无损压缩率和 MSE 失真之间的“率失真”权衡参数。当 $\lambda = 0$ 时，损失函数与理论 DLPR 编码公式一致， $\tilde{x}$ 变为没有任何约束的潜变量。在实验中，我们研究了 $\lambda$ 对无损和近无损图像压缩性能的影响。我们将 $\lambda$ 设置为 0 以实现最佳无损图像压缩，而设置 $\lambda = 0.03$ 以实现具有可变 $\tau$ 的鲁棒近无损图像压缩。

###### 2. 训练 SQRC

为了训练 SQRC，我们生成随机 $\tau \in \{1, 2, \ldots, N\}$ 并通过量化公式对 $r$ 进行量化以得到 $\hat{r}$。给定 $u$ 和从量化 $\hat{r}$ 中提取的上下文 $C_ {\hat{r}}$，我们使用条件熵模型估计在不同 $\tau$ 下的 $- \log p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 并最小化

$$
L(\theta) = E_ {p(x)} E_ {q_ \theta(\hat{y}, \hat{z}|x)} E_ \tau \left[ \log \frac{p_ \theta(r| u, C_ r)}{p_ \theta(r| u, C_ {\hat{r}}, \tau)} \right],
$$

其中 $\theta$ 表示条件熵模型的学习参数。 $- \log p_ \theta(r| u, C_ r)$ 由 RC 中的熵模型估计。 $L(\theta)$ 可以看作 $p_ \theta(r| u, C_ r)$ 和 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 之间的近似 KL 散度或相对熵。

SQRC 与 LIC 和 RC 一起训练，但最小化上述公式仅更新条件熵模型的参数，如图所示。掩码卷积层与 RC 中的共享，因此可以通过最小化前述公式进行更新。这带来了三个优点：

- 我们可以实现目标条件熵模型，缩小训练使用 $r$ 和推理使用 $\hat{r}$ 之间的差距。
- 我们可以避免残差量化的松弛问题。
- 我们可以避免由于使用随机生成的 $\tau$ 进行训练而导致 RC 中 $p_ \theta(r| u, C_ r)$ 估计的退化。

由于 RC 中的熵模型接收从原始残差 $r$ 中提取的上下文 $C_ r$， $p_ \theta(r| u, C_ r)$ 比 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 更接近真实分布 $p(r| \tilde{x}, \hat{y})$。因此， $- \log p_ \theta(r| u, C_ r)$ 是 $- \log p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 的下界。

### C. DLPR 编码的加速

为了实现实际的 DLPR 编码，瓶颈在于 RC 和 SQRC 中的序列化自回归模型，这严重限制了 GPU 上的编码速度。因此，我们提出了一种新颖的上下文编码设计，以增加算法并行度，并通过自适应残差区间进一步加速熵编码。

###### 1. 上下文设计和并行化

通常，自回归模型在解码时存在序列化问题，无法在 GPU 上高效实现。对于 $H \times W$ 的图像，我们需要进行 $HW$ 次上下文模型计算，以顺序解码所有像素。在有损图像压缩中，引入了棋盘上下文模型和通道上下文模型，以加速潜变量的概率推理。然而，这两种上下文模型对我们的残差编码来说太弱，无法在没有变换编码帮助的情况下实现显著性能提升。

为了提高残差编码的并行性，我们首先采用一种常见的操作，将 $H \times W$ 图像拆分为多个不重叠的 $P \times P$ 补丁，并行编码所有 $P \times P$ 补丁，将 $HW$ 次顺序上下文计算减少到 $P^2$ 次。接下来，我们提出了一种新颖的上下文编码设计，以提高 $P \times P$ 补丁和 $k \times k$ 掩码卷积的算法并行度，如图所示。假设 $P = 9$ 和 $k = 7$，对于通常使用的上下文模型，如图所示，我们需要 $P^2 = 81$ 次顺序解码步骤。每个像素中的数字表示像素在时间步长 $t$ 处被解码。当 $P > \left\lceil \frac{k}{2} \right\rceil$ 时，当前解码的像素仅依赖于一些先前解码的像素。例如，红色像素是当前解码的，黄色像素是其上下文。蓝色像素是先前解码的像素，但不包括在红色像素的上下文中。因此，通过调整扫描顺序，可以并行解码某些像素。通过使用 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k+1} \right)$ 度的并行扫描，具有相同数字 $t$ 的像素可以同时解码，如图所示。解码步骤的数量从 $P^2$ 减少到 $\frac{k+3}{2} \cdot P - \frac{k+1}{2}$。在这种情况下，我们使用 $14.04^\circ$ 的并行扫描，导致 $5P - 4 = 41$ 次顺序解码步骤。类似的扫描顺序也在前期工作中使用。此外，我们可以去掉当前解码像素右上方的一个上下文像素。新设计的上下文模型导致 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-1} \right)$ 度的并行扫描，并将解码步骤减少到 $\frac{k+1}{2} \cdot P - \frac{k-1}{2}$。如图所示，我们使用 $18.43^\circ$ 并行扫描和 $4P - 3 = 33$ 次解码步骤。当更多右上方的上下文像素被去掉时，编码并行性可以进一步提高，而压缩性能会逐渐受到影响。如图所示，上下文模型导致 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-3} \right)$ 度的并行扫描和 $\frac{k-1}{2} \cdot P - \frac{k-3}{2}$ 解码步骤，即在我们的例子中使用 $26.57^\circ$ 并行扫描和 $3P - 2 = 25$ 解码步骤。当达到 $45^\circ$ 并行扫描时，这种特殊情况是锯齿形扫描，我们需要 $2P - 1 = 17$ 解码步骤，如图所示。最后，最快的情况如图所示。我们可以使用 $90^\circ$ 并行扫描，仅需 $P = 9$ 解码步骤。

总之，所提出的上下文编码设计表明：给定 $P \times P$ 图像补丁和 $k \times k$ 掩码卷积，且 $P > \left\lceil \frac{k}{2} \right\rceil$，我们可以设计一系列上下文模型 $\{M^{(k+3)/2}_ k, M^{(k+1)/2}_ k, \ldots, M^1_ k\}$，导致 $\left\{ \frac{k+3}{2} \cdot P - \frac{k+1}{2}, \frac{k+1}{2} \cdot P - \frac{k-1}{2}, \ldots, P \right\}$ 并行解码步骤，通过逐渐调整上下文像素。相应的扫描角度为 $\left\{ \frac{180}{\pi} \cdot \arctan\left( \frac{2}{k+1} \right), \frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-1} \right), \ldots, 90^\circ \right\}$。在实验中，我们设置 $P = 64$， $k = 7$ 并选择上下文模型 $M^3_ 7$。 $M^3_ 7$ 拥有几乎与 $M^5_ 7$ 相同的压缩性能，但需要更少的编码步骤。

![](https://img-blog.csdnimg.cn/direct/88050c87d9854b6a94ed03c0591f806b.png)


###### 2. 自适应残差区间

由于原始图像 $x$ 和其有损重建 $\tilde{x}$ 的像素都在区间 $[0, 255]$ 内，相应的残差 $r$ 的元素在区间 $[-255, 255]$ 内。为了对每个 $r_ {i,c}$ 进行熵编码，我们需要计算并使用 511 个元素的 PMF，这效率低下。由于原始残差通常接近零，使用 511 个元素是没有必要的，我们可以使用更小的区间，即 $[- m, m]$ 以提高编码效率，其中 $m \leq 255$ 根据残差的分布自适应确定。具体来说，我们通过满足以下条件确定 $m$ 的值

$$
m = \left\lceil 1.05 \cdot \sqrt{\frac{2}{n_ c} \sum_ {i,c} (r_ {i,c} - \mu_ r)^2} \right\rceil,
$$

其中 $n_ c = 3H \cdot W$ 是 RGB 图像中的像素数量。 $\mu_ r = \frac{1}{n_ c} \sum_ {i,c} r_ {i,c}$ 是残差的平均值。区间 $[- m, m]$ 满足三西格玛经验法则， $m$ 的值应接近 $\frac{2}{n_ c} \sum_ {i,c} (r_ {i,c} - \mu_ r)^2$。我们采用 1.05 的因子来放松区间。

给定 $m$，我们将残差 $r$ 截断为 $\hat{r} = \min(\max(r, -m), m)$ 并使用 $2m + 1$ 元素的 PMF 对 $\hat{r}$ 进行编码。残差编码的成本由

$$
R_ r = E_ {p(x)} E_ {q_ \theta(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(\hat{r}| u, C_ r) ] + \| r - \hat{r} \|_ 0,
$$

其中 $\| r - \hat{r} \|_ 0$ 是零范数正则化，用于计算 $r$ 中截断残差的数量。残差编码成本是速率正则化熵，导致压缩性能和编码效率之间的平衡。在训练过程中，我们使用第一个 mini-batch 初始化 $m$ 的值，并自适应地更新每个批次的 $m$。这种简单的正则化仅适用于 RC，并且可以轻松集成到 DLPR 编码框架中。

## V. 实验

### A. 实验设置

我们在 DIV2K 高分辨率训练数据集 [62] 上训练 DLPR 编码系统，该数据集由 800 个 2K 分辨率的 RGB 图像组成。尽管 DIV2K 最初是为图像超分辨率任务构建的，但它包含大量高质量图像，适合训练我们的编解码器。在训练过程中，这些 2K 图像首先被裁剪成 121,379 个大小为 128×128 的不重叠补丁。然后，我们以 0.5 的随机因子水平和垂直翻转这些补丁，并进一步随机裁剪翻转后的补丁至 64×64 大小。我们使用 Adam [63] 优化所提出的网络，共训练 600 个周期，每个小批量的大小为 64。初始学习率设为 $1 \times 10^{-4}$，并在第 350, 390, 430, 470, 510, 550, 590 个周期时衰减至原来的 0.9 倍。

我们在六个图像数据集上评估训练好的 DLPR 编码系统：

- **ImageNet64**：ImageNet64 验证数据集 [64] 是 ImageNet 验证数据集 [65] 的降采样版本，由 50,000 个 64×64 大小的图像组成。
- **DIV2K**：DIV2K 高分辨率验证数据集 [62] 由 100 个 2K 彩色图像组成，与 DIV2K 高分辨率训练数据集共享相同的域。
- **CLIC.p**：CLIC 专业验证数据集由 41 个专业摄影师拍摄的彩色图像组成。CLIC.p 中的大多数图像为 2K 分辨率，但其中一些图像较小。
- **CLIC.m**：CLIC 移动验证数据集包含 61 个由手机拍摄的 2K 分辨率彩色图像。CLIC.m 中的大多数图像为 2K 分辨率，但其中一些图像较小。
- **Kodak**：Kodak 真彩色图像套件 [66] 包含 24 张分辨率为 768×512 或 512×768 的彩色图像。
- **Histo24**：Histo24 数据集 [67] 由 24 张高分辨率病理图像组成。

为了评估，我们使用了图像压缩中广泛采用的两个指标：BPP 和 PSNR。BPP 衡量比特率（每像素的比特数），PSNR 衡量重建图像的质量。

![](https://img-blog.csdnimg.cn/direct/8bce5e35adcd44b8bd577e5e38d0743c.png)



### B. 无损图像压缩

我们评估 DLPR 编码在上述六个数据集上的无损图像压缩性能，并与传统无损图像编解码器（JPEG-LS [2]，BPG [51]，FLIF [4]，JPEG-XL [5]）和一个实际的学习无损图像压缩方法（L3C [10]）进行比较。如表 I 所示，除了 Kodak 数据集略微落后于 FLIF 外，我们的 DLPR 编码系统在所有数据集上都实现了最佳无损压缩性能。特别是，我们的 DLPR 编码系统大幅优于 L3C，证明了将有损图像压缩与残差压缩相结合的有效性。


![](https://img-blog.csdnimg.cn/direct/56333f15e57c4666af72c576849f9933.png)

![](https://img-blog.csdnimg.cn/direct/962775becfd643698c8972e7605b5bcc.png)


### C. 近无损图像压缩

对于近无损图像压缩，我们考虑可变 $\tau \in \{0, 1, ..., 5\}$ 并在公式 (20) 中设置 $\lambda = 0.03$ 以实现稳健的性能。我们将可扩展近无损压缩方案与 $\tau$ 特定的近无损压缩方案以及传统近无损编解码器（JPEG-LS 和 CALIC [53]）进行比较。如图 9 和表 II 所示，对于大多数 $\tau$ 值，我们的可扩展方案（带 SQRC）比 $\tau$ 特定方案具有更好的压缩性能，并显著优于传统编解码器。

### D. DLPR 编码的运行时间

我们评估了 DLPR 编码在三种不同大小图像上的运行时间，并与四个代表性的传统无损图像编解码器（JPEG-LS，BPG，FLIF，JPEG-XL）和实际学习方法（L3C 和 Minnen[MSE] [40]）进行比较。如表 III 所示，在编码速度方面，我们的无损 DLPR 编码几乎与 FLIF 一样快，且比 BPG，JPEG-XL，L3C 和有损 Minnen[MSE] 快得多。尽管在解码速度方面我们的无损 DLPR 编码比传统编解码器慢，但对于 2K 分辨率的图像仍然实用，并且比 L3C 和有损 Minnen[MSE] 快得多。当 $\tau > 0$ 时，由于自适应残差区间方案，近无损 DLPR 编码可以更快。

![](https://img-blog.csdnimg.cn/direct/9c2b62e260794f8aa83873a07ce52c78.png)


### E. 消融研究

我们进行消融研究，以分析 LIC 和 RC 不同网络架构对无损压缩性能的影响。表 IV 显示了所提出的分析/合成块和 Swin 注意力块相比传统卷积层和注意力块提高了压缩性能。表 V 展示了所提出的 RC 架构的有效性，表 VI 比较了不同的熵模型，显示了逻辑混合模型在复杂残差分布中的最佳表现。

![](https://img-blog.csdnimg.cn/direct/9c2c2701a4034e08bdd745ac175d989d.png)


我们在 Kodak 数据集上提供了近无损重建的视觉示例，如图 10 所示。我们的 DLPR 编码系统即使在较小的 $\tau$ 值下也能实现高视觉质量，与原始图像的感知差异最小。


![](https://img-blog.csdnimg.cn/direct/64af4abf26854505b260882abd3b7231.png)

![](https://img-blog.csdnimg.cn/direct/15f03070cca64cc4aa9a38538b673179.png)

![](https://img-blog.csdnimg.cn/direct/11d372bc86bc4ebfbc5d785f5254e60d.png)

![](https://img-blog.csdnimg.cn/direct/f4bb690629934a03b7a4b2de1a019541.png)

![](https://img-blog.csdnimg.cn/direct/13d8d4927fc94468a6b8f2bc676bff1a.png)

![](https://img-blog.csdnimg.cn/direct/0b00befaac274ad7ba2e16559e3d18d6.png)

## VI. 结论

在本文中，我们提出了一个统一的 DLPR 编码框架，用于无损和近无损图像压缩。该框架包括一个有损图像压缩器，一个残差压缩器和一个可扩展量化残差压缩器，全部端到端训练。DLPR 编码系统支持具有可变 $\ell_ \infty$ 约束 $\tau$ 的可扩展近无损压缩，而不是为不同 $\tau$ 训练多个网络。我们还引入了一种新颖的上下文编码设计和自适应残差区间方案来加速编码过程。广泛的实验表明，DLPR 编码系统在实际图像压缩任务中实现了最先进的压缩性能和竞争力的编码速度。














# 题目：[Deep Lossy Plus Residual Coding for Lossless and Near-Lossless Image Compression](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10378746)  
## 深度有损加残差编码用于无损和近无损图像压缩
**作者：Yuanchao Bai; Xianming Liu; Kai Wang; Xiangyang Ji; Xiaolin Wu; Wen Gao** 

****
# 摘要
无损和近无损图像压缩对于许多技术领域的专业用户至关重要，如医学、遥感、精密工程和科学研究。然而，尽管基于学习的图像压缩研究兴趣迅速增长，但没有任何已发表的方法同时提供无损和近无损模式。在本文中，我们提出了一种统一且强大的深度有损加残差 (DLPR) 编码框架，用于无损和近无损图像压缩。在无损模式下，DLPR 编码系统首先执行有损压缩，然后对残差进行无损编码。我们采用 VAEs 方法解决联合有损和残差压缩问题，并添加残差的自回归上下文建模以增强无损压缩性能。在近无损模式下，我们量化原始残差以满足给定的 $\ell_ \infty$ 误差界限，并提出了一种可扩展的近无损压缩方案，适用于可变 $\ell_ \infty$ 界限，而不是训练多个网络。为了加速 DLPR 编码，我们通过一种新颖的编码上下文设计提高了算法并行度，并通过自适应残差区间加速了熵编码。实验结果表明，DLPR 编码系统在无损和近无损图像压缩方面均达到了最先进的性能，并具有竞争力的编码速度。

# 关键词
- 深度学习
- 图像压缩
- 无损压缩
- 近无损压缩
- 有损加残差编码




## I. 引言

在许多重要的技术领域，如医学、遥感、精密工程和科学研究，高空间、光谱和时间分辨率的成像对于发现和创新至关重要。随着现代成像技术可实现的分辨率稳步提高，用户被随之产生的海量图像和视频数据淹没。例如，病理成像扫描仪每个样本可以轻松生成1 GB或更多的数据。为了实现成本效益和系统可操作性（例如，通过云实时访问高保真视觉对象），必须对多维高分辨率获取的原始图像进行压缩。

与消费应用（例如，智能手机和社交媒体）不同，用户主要关注解压缩图像的外观，并且在信号级别上可以对压缩失真视而不见，高保真度的解压缩图像对于许多技术领域的专业用户至关重要。在后者的情况下，目前的金标准是数学上的无损图像压缩。香农的源编码定理确立了无损图像压缩的理论基础，证明了给定图像数据的实际概率分布下预期码长的下限，即信息熵。实际上，任何特定无损图像编解码器的压缩性能取决于它在多大程度上可以逼近未知的实际概率分布，以接近理论下限。尽管研究多年，传统无损图像编解码器的典型压缩比仍然在2:1到3:1之间。另一种在保持解压缩图像高保真的同时提高压缩性能的方法是近无损图像压缩。近无损图像压缩不是数学上的无损，而是对解压缩图像施加严格的 $\ell_ \infty$ 约束，要求每个像素的最大重建误差不大于给定的紧数值界限。通过引入 $\ell_ \infty$ 约束误差界限，近无损图像压缩可以保证每个像素的可靠性，同时打破无损图像压缩的理论压缩限制。当紧误差界限设置为零时，近无损图像压缩等同于无损图像压缩。传统的无损图像编解码器，如 JPEG-LS 和 CALIC，为用户提供无损和近无损图像压缩，以满足各种成像和视觉系统的带宽和成本效益要求。

随着深度神经网络（DNNs）的快速进步，基于学习的图像压缩在过去五年中取得了巨大进展。然而，大多数这些方法是为率失真优化的有损图像压缩设计的，即使在比特率充足的情况下也无法实现无损或近无损图像压缩。最近，许多研究团队开始开发端到端优化的无损图像压缩方法。这些方法利用复杂的深度生成模型，如自回归模型、流模型和变分自编码器（VAE）模型，学习给定图像数据的未知概率分布，并根据学习到的模型将图像数据熵编码为比特流。虽然实现了优于传统无损图像编解码器的出色压缩性能，但现有基于学习的无损图像方法通常编码速度过慢，难以应用于实际全分辨率图像压缩任务。此外，与传统的 JPEG-LS 和 CALIC 不同，除了我们最近的工作之外，没有研究进行基于学习的近无损图像压缩，尽管如上所述，这具有巨大的潜力。

在本文中，我们提出了一种统一且强大的深度有损加残差（DLPR）编码框架，用于无损和近无损图像压缩，较大程度上解决了基于学习的无损图像压缩的挑战。DLPR 编码系统的显著特点包括：最先进的无损和近无损图像压缩性能、单个网络实现的可扩展近无损图像压缩，具有可变的 $\ell_ \infty$ 界限，并在2K分辨率图像上具有竞争力的编码速度。具体而言，对于无损图像压缩，DLPR 编码系统首先执行有损压缩，然后对残差进行无损编码。有损图像压缩器和残差压缩器均设计了先进的神经网络架构。我们采用 VAEs 方法解决联合有损图像和残差压缩问题，并添加残差的自回归上下文建模以增强无损压缩性能。注意，我们的 VAE 模型不同于基于变换编码的 VAE 简单有损图像压缩或基于比特返回编码的 VAEs 无损图像压缩。对于近无损图像压缩，我们量化原始残差以满足给定的 $\ell_ \infty$ 误差界限，并压缩量化的残差，而不是原始残差。为了实现具有可变 $\ell_ \infty$ 误差界限的可扩展近无损压缩，我们通过量化用于无损压缩的学习概率模型，导出量化残差的概率模型，而不是训练多个网络。由于残差量化导致训练和推理之间的上下文不匹配，我们提出了一种具有偏差校正方案的可扩展量化残差压缩器，以校正导出的概率模型的偏差。为了加速 DLPR 编码，瓶颈在于残差和量化残差压缩中的串行自回归上下文模型。因此，我们提出了一种新颖的编码上下文设计，以提高算法的并行度，并通过自适应残差区间进一步加速熵编码。最后，无损或近无损压缩图像包括编码的有损图像、编码的原始残差或量化残差的比特流。

总之，本研究的主要贡献如下：

- 我们提出了一个统一的 DLPR 编码框架，实现无损和近无损图像压缩。该框架可以解释为 VAE 模型并进行端到端优化。尽管传统的无损图像编解码器（如 JPEG-LS 或 CALIC）支持无损和近无损模式，但我们是第一个在基于学习的图像压缩中支持这两种模式的。
- 我们实现了具有可变 $\ell_ \infty$ 误差界限的可扩展近无损图像压缩。给定 $\ell_ \infty$ 界限，我们量化原始残差并从无损图像压缩的学习概率模型导出量化残差的概率模型，而不是训练多个网络。偏差校正方案进一步提高了压缩性能。
- 为了加速 DLPR 编码系统，我们提出了一种新颖的编码上下文设计，以提高算法的并行度而不损害压缩性能。同时，我们进一步引入了自适应残差区间方案，以减少熵编码时间。

实验结果表明，DLPR 编码系统在无损和近无损图像压缩方面均达到了最先进的性能，并在高比特率下实现了竞争力的 PSNR，同时比有损图像编解码器具有更小的 $\ell_ \infty$ 误差。此外，DLPR 编码系统在运行时间方面是实用的，可以在几秒钟内压缩和解压缩2K分辨率图像。

注意，这篇论文是我们最近工作的非平凡扩展。首先，本文专注于无损和近无损图像压缩，而不仅仅是近无损图像压缩。其次，我们改进了有损图像压缩器、残差压缩器和可扩展量化残差压缩器的网络架构，超越了我们之前的工作，导致更强大而简洁的 DLPR 编码系统。第三，为了加速 DLPR 编码系统，我们引入了一种新颖的上下文编码设计，以提高算法并行度，并引入了自适应残差区间方案，以加速熵编码。最后，我们进行了全面的实验，表明最终的 DLPR 编码系统在无损和近无损图像压缩方面达到了最先进的性能，显著优于我们之前工作的原型，同时享有更快的编码速度。

本文的其余部分组织如下。我们在第二节简要回顾了相关工作。在第三节中，我们理论分析了无损和近无损图像压缩问题，并提出了 DLPR 编码框架。第四节介绍了 DLPR 编码框架的网络架构和加速。第五节和第六节分别是实验和结论。


## III. 深度有损加残差编码

在本节中，我们介绍了一个用于无损和近无损图像压缩的 DLPR 编码框架，通过将有损图像压缩与残差压缩相结合。我们在理论上分析了无损和近无损图像压缩问题，并以 VAEs 的形式构建了 DLPR 编码框架。

### A. 用于无损图像压缩的 DLPR 编码

无损图像压缩保证原始图像从压缩的比特流中完美重建。假设原始图像 $x$ 是从未知概率分布 $p(x)$ 中采样的，使用无损图像压缩的压缩图像的最短期望码长在理论上由信息熵下界

$$
H(p) = E_ {p(x)}[- \log p(x)].
$$

实际上，任何特定无损图像压缩方法的压缩性能取决于它如何用底层模型 $p_ \theta(x)$ 逼近 $p(x)$。相应的压缩性能由交叉熵给出

$$
H(p, p_ \theta) = E_ {p(x)}[- \log p_ \theta(x)] \geq H(p),
$$

其中 $H(p, p_ \theta)$ 仅在 $p_ \theta(x) = p(x)$ 时成立。





为了逼近 $p(x)$，广泛使用潜变量模型 $p_ \theta(x)$ 来实现这一目的，并通过边缘分布公式化

$$
p_ \theta(x) = \int p_ \theta(x,y) dy = \int p_ \theta(x|y) p_ \theta(y) dy,
$$

其中 $y$ 是未观察到的潜变量， $\theta$ 表示该模型的参数。由于直接学习 $p_ \theta(x)$ 的边缘分布通常是不可行的，另一种方法是通过 VAEs 优化证据下界（ELBO）。通过引入推理模型 $q_ \phi(y|x)$ 以逼近后验 $p_ \theta(y|x)$，边缘似然 $p_ \theta(x)$ 的对数可以重写为

$$
\log p_ \theta(x) = E_ {q_ \phi(y|x)} \log \frac{p_ \theta(x,y)}{q_ \phi(y|x)} + E_ {q_ \phi(y|x)} \log \frac{q_ \phi(y|x)}{p_ \theta(y|x)},
$$

其中 $D_ {KL}(\cdot \| \cdot)$ 是 Kullback-Leibler（KL）散度。 $\phi$ 表示推理模型 $q_ \phi(y|x)$ 的参数。由于 $D_ {KL}(q_ \phi(y|x) \| p_ \theta(y|x)) \geq 0$ 且 $\log p_ \theta(x) \leq 0$，ELBO 是 $\log p_ \theta(x)$ 的下界。因此，我们有

$$
E_ {p(x)}[- \log p_ \theta(x)] \leq E_ {p(x)} E_ {q_ \phi(y|x)} \left[ - \log \frac{p_ \theta(x,y)}{q_ \phi(y|x)} \right],
$$

并且可以最小化负 ELBO 的期望作为期望码长 $E_ {p(x)}[- \log p_ \theta(x)]$ 的代理。

为了最小化负 ELBO 的期望，我们提出了一个 DLPR 编码框架。我们首先采用基于变换编码的有损图像压缩来压缩原始图像 $x$ 并获得其有损重建 $\tilde{x}$。负 ELBO 的期望可以重新公式化为：

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(r|\tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中 $\hat{y}$ 是连续潜在表示 $y$ 的量化结果， $y$ 是由 $x$ 决定性变换得到的。像以前的工作一样，我们通过从 $U(- \frac{1}{2}, \frac{1}{2})$ 添加噪声来放松 $y$ 的量化，并假设 $q_ \phi(\hat{y}|x) = \prod_ i U(y_ i - \frac{1}{2}, y_ i + \frac{1}{2})$。因此， $\log q_ \phi(\hat{y}|x) = 0$ 从公式中删除。对于简单的有损图像压缩，公式的第二项可以视为 $x$ 和其有损重建 $\tilde{x}$ 之间的失真损失。第三项可以视为有损图像压缩的码率损失。只需将 $\hat{y}$ 编码为比特流并存储。

除了有损图像压缩外，我们还考虑了残差压缩。残差 $r$ 由 $r = x - \tilde{x}$ 计算得到。我们有以下命题 1。

**命题 1**： $p_ \theta(x| \hat{y}) = p_ \theta(\tilde{x}, r| \hat{y}) = p_ \theta(r| \tilde{x}, \hat{y})$。

**证明**：对于每个 $x$ 和所有 $(\tilde{x}, r)$ 对，满足 $\tilde{x} + r = x$，我们有 $p_ \theta(x| \hat{y}) = \sum_ {\tilde{x}+r=x} p_ \theta(\tilde{x}, r| \hat{y})$。根据贝叶斯规则，我们有 $p_ \theta(\tilde{x}, r| \hat{y}) = p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y})$。因此，我们有 $p_ \theta(x| \hat{y}) = \sum_ {\tilde{x}+r=x} p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y})$。由于有损重建 $\tilde{x}$ 是由 $\hat{y}$ 的决定性逆变换计算得到的，只有一个 $\tilde{x}$ 满足 $p_ \theta(\tilde{x}| \hat{y}) = 1$，其他 $\tilde{x}$ 的 $p_ \theta(\tilde{x}| \hat{y}) = 0$。因此，我们可以得到 $p_ \theta(x| \hat{y}) = p_ \theta(\tilde{x}| \hat{y}) \cdot p_ \theta(r| \tilde{x}, \hat{y}) + \sum 0 = p_ \theta(\tilde{x}, r| \hat{y}) = 1 \cdot p_ \theta(r| \tilde{x}, \hat{y}) = p_ \theta(r| \tilde{x}, \hat{y})$。

基于上述公式和命题 1，我们用 $p_ \theta(r| \tilde{x}, \hat{y})$ 替代 $p_ \theta(x| \hat{y})$ 并实现 DLPR 编码公式

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(r| \tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中第一项 $R_ r$ 和第二项 $R_ {\hat{y}}$ 是使用 $p_ \theta(r| \tilde{x}, \hat{y})$ 和 $p_ \theta(\hat{y})$ 熵编码 $r$ 和 $\hat{y}$ 的期望码长。在训练过程中，我们通过从 $U(- \frac{1}{2}, \frac{1}{2})$ 添加噪声来放松 $\tilde{x}$ 的量化，并有 $\log p_ \theta(\tilde{x}| \hat{y}) = 0$，与命题 1 的前提一致。由于上述公式等价于负 ELBO 的期望，所提出的 DLPR 编码框架是期望码长 $E_ {p(x)}[- \log p_ \theta(x)]$ 的上限，并且可以作为代理进行最小化。

注意，上述公式中没有指定有损图像压缩的失真损失。因此，我们可以嵌入任意有损图像压缩器，并最小化公式以实现无损图像压缩。一个特例是以前的无损图像压缩方法，其中 BPG 有损图像压缩器使用学习的量化参数分类器最小化 $- \log p_ \theta(\hat{y})$，基于 CNN 的残差压缩器最小化 $- \log p_ \theta(r| \tilde{x})$。

### B. 用于近无损图像压缩的 DLPR 编码

我们进一步扩展 DLPR 编码框架以实现近无损图像压缩。给定一个紧的 $\ell_ \infty$ 误差界限 $\tau \in \{1, 2, \ldots \}$，近无损方法压缩原始图像 $x$ 满足以下失真约束：

$$
D_ {nll}(x, \hat{x}) = \| x - \hat{x} \|_  \infty = \max_ {i,c} | x_ {i,c} - \hat{x}_ {i,c} | \leq \tau,
$$

其中 $\hat{x}$ 是原始图像 $x$ 的近无损重建。 $x_ {i,c}$ 和 $\hat{x}_ {i,c}$ 是 $x$ 和 $\hat{x}$ 的像素。 $i$ 表示预定义扫描顺序中的第 $i$ 个空间位置， $c$ 表示第 $c$ 个通道。如果 $\tau = 0$，近无损图像压缩等同于无损图像压缩。

为了满足 $\ell_ \infty$ 约束，我们通过量化残差来扩展 DLPR 编码框架。首先，我们仍然通过有损图像压缩获得原始图像 $x$ 的有损重建 $\tilde{x}$。尽管有损图像压缩方法在相对低的比特率下可以实现高 PSNR 结果，但这些方法难以确保 $\tilde{x}$ 中每个像素的紧误差界限 $\tau$。然后我们计算残差 $r = x - \tilde{x}$ 并假设 $r$ 被量化为 $\hat{r}$。令 $\hat{x} = \tilde{x} + \hat{r}$，重建误差 $x - \hat{x}$ 等同于 $r$ 的量化误差 $r - \hat{r}$。因此，我们采用均匀残差量化器，其箱大小为 $2\tau + 1$，量化值为

$$
\hat{r}_  {i,c} = \text{sgn}(r_ {i,c}) \cdot (2\tau + 1) \left\lfloor \frac{|r_ {i,c}| + \tau}{2\tau + 1} \right\rfloor,
$$

其中 $\text{sgn}(\cdot)$ 表示符号函数。 $r_ {i,c}$ 和 $\hat{r}_ {i,c}$ 是 $r$ 和 $\hat{r}$ 的元素。通过上述公式，对于 $\hat{r}$ 中的每个 $\hat{r}_ {i,c}$，我们现在有 $|r_ {i,c} - \hat{r}_ {i,c}| \leq \tau$，满足紧误差界限。由于残差量化是确定性的，用于近无损图像压缩的 DLPR 编码框架可以公式化为

$$
E_ {p(x)} E_ {q_ \phi(\hat{y}|x)} \left[ - \log p_ \theta(\hat{r}| \tilde{x}, \hat{y}) - \log p_ \theta(\hat{y}) \right],
$$

其中第一项 $R_ {\hat{r}}$ 是使用 $p_ \theta(\hat{r}| \tilde{x}, \hat{y})$ 而非原始残差 $r$ 熵编码 $\hat{r}$ 的期望码长。最后，我们将 $\hat{r}$ 的比特流与 $\hat{y}$ 的比特流连接，得到近无损图像压缩结果。

## IV. 网络架构和加速

### A. DLPR 编码的网络架构

我们提出了 DLPR 编码框架的网络架构，包括有损图像压缩器（LIC）、残差压缩器（RC）和可扩展量化残差压缩器（SQRC），如图所示。通过 LIC 和 RC，我们实现了用于无损图像压缩的 DLPR 编码。通过 LIC 和 SQRC，我们进一步实现了具有单一网络的可变 $\ell_ \infty$ 界限的可扩展近无损图像压缩。我们在以下小节中详细说明每个组件。

###### 1. 有损图像压缩器

在 LIC 中，我们采用复杂的图像编码器和解码器，同时使用高效的超先验模型，如图所示。图像编码器 $g_ e(\cdot)$ 和解码器 $g_ d(\cdot)$ 由分析、合成和 Swin-Attention 块组成，遵循残差和自注意学习的理念，如图所示。在 Swin-Attention 块中，我们采用基于窗口和移位窗口的多头自注意力（W-MSA/SW-MSA），自适应地在局部窗口内和跨窗口聚合信息，提高了 $g_ e(\cdot)$ 和 $g_ d(\cdot)$ 的表示能力，同时计算复杂度适中。通过 $g_ e(\cdot)$ 和 $g_ d(\cdot)$，我们将输入的原始图像 $x$ 转换为其潜在表示 $y = g_ e(x)$，将 $y$ 量化为 $\hat{y} = Q(y)$，并逆转换 $\hat{y}$ 为有损重建 $\tilde{x} = g_ d(\hat{y})$。

由于复杂的图像编码器和解码器可以大幅减少 $x$ 中的空间冗余，我们决定采用高效的超先验模型而无需任何上下文模型，以确保在 GPU 上的编码并行性。超先验模型提取边信息 $\hat{z} = Q(h_ e(y))$，以建模 $\hat{y}$ 的概率分布，其中 $h_ e(\cdot)$ 是超编码器。我们假设 $p_ \theta(\hat{y}| \hat{z})$ 的分解高斯分布模型 $N(\mu, \sigma) = h_ d(\hat{z})$，其中 $h_ d(\cdot)$ 是超解码器，并为 $p_ \theta(\hat{z})$ 假设一个非参数化分解密度模型。因此， $R_ {\hat{y}, \hat{z}}$ 被扩展为

$$
R_ {\hat{y}, \hat{z}} = E_ {p(x)} E_ {q_ \phi(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(\hat{y}| \hat{z}) - \log p_ \theta(\hat{z}) ],
$$

其中 $R_ {\hat{y},\hat{z}}$ 是编码 $\hat{y}$ 和 $\hat{z}$ 的成本。

![](https://img-blog.csdnimg.cn/direct/71965724e10a4575bd27b81a28e9533c.png)



###### 2. 残差压缩器

给定原始图像 $x$ 和由 LIC 生成的有损重建 $\tilde{x}$，我们得到残差 $r = x - \tilde{x}$。接下来我们介绍 RC，以估计 $r$ 的概率质量函数（PMF）并相应地使用算术编码对 $r$ 进行压缩。

表示为 $u = g_ u(\hat{y})$，其中特征 $u$ 由 $g_ u(\cdot)$ 从 $\hat{y}$ 生成。 $g_ u(\cdot)$ 和图像解码器 $g_ d(\cdot)$ 共享网络，除了最后一层卷积层，如图所示。我们将 $u$ 解释为给定 $\tilde{x}$ 和 $\hat{y}$ 的残差 $r$ 的特征。特征 $u$ 与 $r$ 具有相同的高度和宽度，并有 256 个通道。与通过图像编码器大幅减少空间冗余的潜在表示 $\hat{y}$ 不同，像素域中的残差 $r$ 具有无法通过特征 $u$ 完全利用的空间冗余。因此，我们进一步引入自回归模型到 $r$ 的统计建模中，得到

$$
p_ \theta(r| \tilde{x}, \hat{y}) = p_ \theta(r| u) = \prod_ {i,c} p_ \theta(r_ {i,c}| u, r_ {<(i,c)}),
$$

其中 $r_ {<(i,c)}$ 表示预定义扫描顺序中在 $r_ {i,c}$ 之前编码或解码的 $r$ 元素。实际上，我们使用具有特定感受野的掩码卷积层实现空间自回归模型，而不是依赖于 $r_ {<(i,c)}$ 的所有元素。我们将掩码卷积层的感受野视为上下文 $C_ r$。基于上述公式和 $C_ r$，我们将 $R_ r$ 重新公式化为

$$
R_ r = E_ {p(x)} E_ {q_ \phi(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(r| u, C_ r) ].
$$

具体来说，我们利用一个 7×7 掩码卷积层来从 $r_ {<(i,c)}$ 中提取上下文 $C_ {r_ i} \in C_ r$。 $C_ {r_ i}$ 被所有通道的 $r_ {i,c}$ 共享。对于具有三个通道的 RGB 图像，我们有

$$
p_ \theta(r| u, C_ r) = \prod_ i p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i}).
$$

我们进一步采用通道自回归方案对 $r_ {i,1}, r_ {i,2}, r_ {i,3}$ 进行处理，并将 $p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i})$ 重新公式化为

$$
p_ \theta(r_ {i,1}, r_ {i,2}, r_ {i,3}| u_ i, C_ {r_ i}) = p_ \theta(r_ {i,1}| u_ i, C_ {r_ i}) \cdot p_ \theta(r_ {i,2}| r_ {i,1}, u_ i, C_ {r_ i}) \cdot p_ \theta(r_ {i,3}| r_ {i,1}, r_ {i,2}, u_ i, C_ {r_ i}).
$$

我们使用离散逻辑混合似然来建模 $r_ {i,c}$ 的 PMF，并提出了一个子网络来估计相应的熵参数，包括混合权重 $\pi_ k^i$、均值 $\mu_ k^{i,c}$、方差 $\sigma_ k^{i,c}$ 和混合系数 $\beta_ i^t$。 $k$ 表示第 $k$ 个逻辑分布的索引。 $t$ 表示 $\beta$ 的通道索引。熵模型的网络架构如图所示。我们使用五个逻辑分布的混合。通道自回归方案通过更新均值实现

$$
\tilde{\mu}_ k^{i,1} = \mu_ k^{i,1}, \tilde{\mu}_ k^{i,2} = \mu_ k^{i,2} + \beta_ i^1 \cdot r_ {i,1}, \tilde{\mu}_ k^{i,3} = \mu_ k^{i,3} + \beta_ i^2 \cdot r_ {i,1} + \beta_ i^3 \cdot r_ {i,2}.
$$

通过 $\pi_ k^i, \tilde{\mu}_ k^{i,c}$ 和 $\sigma_ k^{i,c}$，
对于离散 $r_ {i,c}$，我们评估
$$
\sum_{k=1}^K \pi_k^i \left[ S\left( \frac{r_{i,c}^+ - \tilde{\mu}_ k^{i,c}}{\sigma_k^{i,c}} \right) - S\left( \frac{r_{i,c}^- - \tilde{\mu}_k^{i,c}}{\sigma_k^{i,c}} \right) \right],
$$

其中 $S(\cdot)$ 表示 sigmoid 函数。 $r_ {i,c}^+ = r_ {i,c} + 0.5$ 和 $r_ {i,c}^- = r_ {i,c} - 0.5$。残差的概率推理方案如图所示。

###### 3. 可扩展量化残差压缩器

我们最终引入 SQRC，以实现具有可变 $\ell_ \infty$ 界限 $\tau \in \{1, 2, \ldots\}$ 的可扩展近无损图像压缩。尽管给定特定 $\tau$ 的近无损图像压缩可以通过优化公式实现，但这种特定 $\tau$ 方案导致两个问题：

- 残差量化的松弛问题：与舍入量化不同，残差量化的箱大小要大得多。此外，原始残差在每个箱中的分布并不均匀，因此无法通过添加均匀噪声来松弛。
- 多网络的存储问题：为了部署近无损编解码器，我们必须传输和存储针对不同 $\tau$ 的多个网络，这在存储方面效率低下。

相反，我们提出了一种可扩展的近无损图像压缩方案，该方案可以避免残差量化的松弛，并使用单一网络满足可变 $\ell_ \infty$ 误差界限 $\tau \in \{1, 2, \ldots\}$。具体来说，这种可扩展压缩方案基于 DLPR 编码框架的学习无损压缩。我们保持有损重建 $\tilde{x}$ 不变，并通过量化公式对原始残差 $r$ 进行量化以获得可变 $\tau$ 的 $\hat{r}$。为了编码量化后的 $\hat{r}$，我们可以从学习的原始 $r$ 的 PMF 推导出 $\hat{r}$ 的 PMF。给定 $\tau$ 和学习的原始 $r_ {i,c}$ 的 PMF 
我们在图中展示了一个说明性示例。结合前面的公式，我们可以推导出量化残差 $\hat{r}$ 的概率模型 $\hat{p}_ \theta(\hat{r}| u, C_ r)$，该模型在给定学习的原始 $r$ 的 $p_ \theta(r| u, C_ r)$ 的情况下是最优的。随着 $\tau$ 的增加，编码量化残差 $\hat{r}$ 的成本显著降低，记为 $R_ \tau^{\hat{r}}$。

然而，用 $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 编码 $\hat{r}$ 导致比特流无法解码，因为解码器不知道原始残差 $r$。没有 $r_ {i,<c}$ 和因果上下文 $C_ {r_ i}$ 就无法评估 $\hat{p}_ \theta(\hat{r}_ {i,c}| r_ {i,<c}, u_ i, C_ {r_ i})$。相反，我们可以使用量化后的残差 $\hat{r}$ 进行 PMF 评估，即评估 $p_ \theta(r_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$ 并通过量化公式推导出 $\hat{p}_ \theta(\hat{r}_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$，从而得到用于编码 $\hat{r}$ 的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$。由于训练阶段（使用 $r$）和推理阶段（使用 $\hat{r}$）之间的不匹配，导致 PMF $p_ \theta(r_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$、 $\hat{p}_ \theta(\hat{r}_ {i,c}| \hat{r}_ {i,<c}, u_ i, C_ {\hat{r}_ i})$ 和 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 有偏。上述概率推理方案如图所示。

![](https://img-blog.csdnimg.cn/direct/043bba34ef8d470f93a0ae44a5967e98.png)


#### SQRC 偏差校正

由于 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 和偏置的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 之间的差异，用 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 编码 $\hat{r}$ 降低了压缩性能。

为了解决这个问题，我们提出了 SQRC 偏差校正，以缩小 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$ 和偏置 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 之间的差距，同时生成的比特流仍然可解码。SQRC 的组件如图所示。SQRC 中的掩码卷积层与 RC 中的共享。条件熵模型的网络架构与图示的熵模型相同，但用图示的条件卷积层替换卷积层。

带有 SQRC 的概率推理方案如图所示。对于 $\tau = 0$，我们仍然选择 RC 中的熵模型来估计 $p_ \theta(r| u, C_ r)$ 以编码 $r$。对于 $\tau \in \{1, 2, \ldots, N\}$，我们选择 SQRC 中的条件熵模型来估计条件 $\tau$ 下的 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$。然后我们通过量化公式推导出 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 以编码 $\hat{r}$，其中 $\theta$ 表示 SQRC 的参数。由于 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 比偏置的 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}})$ 更接近 oracle $\hat{p}_ \theta(\hat{r}| u, C_ r)$，压缩性能可以提高。由于评估 $\hat{p}_ \theta(\hat{r}| u, C_ {\hat{r}}, \tau)$ 与 $r$ 无关，生成的比特流是可解码的。在实验中，我们证明了带有 SQRC 的可扩展近无损压缩方案可以超过 $\tau$ 特定的近无损方案和没有 SQRC 的可扩展近无损压缩方案。


![](https://img-blog.csdnimg.cn/direct/f80ccd1f4b44410b9c34057281ddc527.png)

![](https://img-blog.csdnimg.cn/direct/93365bf0859c4cd5a60975423ccf39f0.png)

![](https://img-blog.csdnimg.cn/direct/70d7760238bd4b2c9171f389209e6c59.png)


### B. DLPR 编码的训练策略

###### 1. 训练 LIC 和 RC

联合优化 LIC 和 RC 的完整损失函数，即用于无损图像压缩的 DLPR 编码，是

$$
L(\theta, \phi) = R_ {\hat{y}, \hat{z}} + R_ r + \lambda \cdot D_ {ls},
$$

其中 $\theta$ 和 $\phi$ 是 LIC 和 RC 的学习参数。除了码率项 $R_ {\hat{y}, \hat{z}}$ 和 $R_ r$，我们还引入失真项 $D_ {ls}(x, \tilde{x})$ 以最小化原始图像 $x$ 和其有损重建 $\tilde{x}$ 之间的均方误差（MSE）

$$
D_ {ls}(x, \tilde{x}) = E_ {p(x)} E_ {i,c} (x_ {i,c} - \tilde{x}_ {i,c})^2.
$$

如前期工作所述，最小化 MSE 损失等同于学习一个将残差 $r$ 拟合到分解高斯分布的 LIC。然而， $r$ 的真实分布与分解高斯分布之间的差异通常很大。因此，我们在 DLPR 编码框架中使用复杂的离散逻辑混合似然模型来编码 $r$。

公式中的 $\lambda$ 是无损压缩率和 MSE 失真之间的“率失真”权衡参数。当 $\lambda = 0$ 时，损失函数与理论 DLPR 编码公式一致， $\tilde{x}$ 变为没有任何约束的潜变量。在实验中，我们研究了 $\lambda$ 对无损和近无损图像压缩性能的影响。我们将 $\lambda$ 设置为 0 以实现最佳无损图像压缩，而设置 $\lambda = 0.03$ 以实现具有可变 $\tau$ 的鲁棒近无损图像压缩。

###### 2. 训练 SQRC

为了训练 SQRC，我们生成随机 $\tau \in \{1, 2, \ldots, N\}$ 并通过量化公式对 $r$ 进行量化以得到 $\hat{r}$。给定 $u$ 和从量化 $\hat{r}$ 中提取的上下文 $C_ {\hat{r}}$，我们使用条件熵模型估计在不同 $\tau$ 下的 $- \log p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 并最小化

$$
L(\theta) = E_ {p(x)} E_ {q_ \theta(\hat{y}, \hat{z}|x)} E_ \tau \left[ \log \frac{p_ \theta(r| u, C_ r)}{p_ \theta(r| u, C_ {\hat{r}}, \tau)} \right],
$$

其中 $\theta$ 表示条件熵模型的学习参数。 $- \log p_ \theta(r| u, C_ r)$ 由 RC 中的熵模型估计。 $L(\theta)$ 可以看作 $p_ \theta(r| u, C_ r)$ 和 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 之间的近似 KL 散度或相对熵。

SQRC 与 LIC 和 RC 一起训练，但最小化上述公式仅更新条件熵模型的参数，如图所示。掩码卷积层与 RC 中的共享，因此可以通过最小化前述公式进行更新。这带来了三个优点：

- 我们可以实现目标条件熵模型，缩小训练使用 $r$ 和推理使用 $\hat{r}$ 之间的差距。
- 我们可以避免残差量化的松弛问题。
- 我们可以避免由于使用随机生成的 $\tau$ 进行训练而导致 RC 中 $p_ \theta(r| u, C_ r)$ 估计的退化。

由于 RC 中的熵模型接收从原始残差 $r$ 中提取的上下文 $C_ r$， $p_ \theta(r| u, C_ r)$ 比 $p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 更接近真实分布 $p(r| \tilde{x}, \hat{y})$。因此， $- \log p_ \theta(r| u, C_ r)$ 是 $- \log p_ \theta(r| u, C_ {\hat{r}}, \tau)$ 的下界。

### C. DLPR 编码的加速

为了实现实际的 DLPR 编码，瓶颈在于 RC 和 SQRC 中的序列化自回归模型，这严重限制了 GPU 上的编码速度。因此，我们提出了一种新颖的上下文编码设计，以增加算法并行度，并通过自适应残差区间进一步加速熵编码。

###### 1. 上下文设计和并行化

通常，自回归模型在解码时存在序列化问题，无法在 GPU 上高效实现。对于 $H \times W$ 的图像，我们需要进行 $HW$ 次上下文模型计算，以顺序解码所有像素。在有损图像压缩中，引入了棋盘上下文模型和通道上下文模型，以加速潜变量的概率推理。然而，这两种上下文模型对我们的残差编码来说太弱，无法在没有变换编码帮助的情况下实现显著性能提升。

为了提高残差编码的并行性，我们首先采用一种常见的操作，将 $H \times W$ 图像拆分为多个不重叠的 $P \times P$ 补丁，并行编码所有 $P \times P$ 补丁，将 $HW$ 次顺序上下文计算减少到 $P^2$ 次。接下来，我们提出了一种新颖的上下文编码设计，以提高 $P \times P$ 补丁和 $k \times k$ 掩码卷积的算法并行度，如图所示。假设 $P = 9$ 和 $k = 7$，对于通常使用的上下文模型，如图所示，我们需要 $P^2 = 81$ 次顺序解码步骤。每个像素中的数字表示像素在时间步长 $t$ 处被解码。当 $P > \left\lceil \frac{k}{2} \right\rceil$ 时，当前解码的像素仅依赖于一些先前解码的像素。例如，红色像素是当前解码的，黄色像素是其上下文。蓝色像素是先前解码的像素，但不包括在红色像素的上下文中。因此，通过调整扫描顺序，可以并行解码某些像素。通过使用 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k+1} \right)$ 度的并行扫描，具有相同数字 $t$ 的像素可以同时解码，如图所示。解码步骤的数量从 $P^2$ 减少到 $\frac{k+3}{2} \cdot P - \frac{k+1}{2}$。在这种情况下，我们使用 $14.04^\circ$ 的并行扫描，导致 $5P - 4 = 41$ 次顺序解码步骤。类似的扫描顺序也在前期工作中使用。此外，我们可以去掉当前解码像素右上方的一个上下文像素。新设计的上下文模型导致 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-1} \right)$ 度的并行扫描，并将解码步骤减少到 $\frac{k+1}{2} \cdot P - \frac{k-1}{2}$。如图所示，我们使用 $18.43^\circ$ 并行扫描和 $4P - 3 = 33$ 次解码步骤。当更多右上方的上下文像素被去掉时，编码并行性可以进一步提高，而压缩性能会逐渐受到影响。如图所示，上下文模型导致 $\frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-3} \right)$ 度的并行扫描和 $\frac{k-1}{2} \cdot P - \frac{k-3}{2}$ 解码步骤，即在我们的例子中使用 $26.57^\circ$ 并行扫描和 $3P - 2 = 25$ 解码步骤。当达到 $45^\circ$ 并行扫描时，这种特殊情况是锯齿形扫描，我们需要 $2P - 1 = 17$ 解码步骤，如图所示。最后，最快的情况如图所示。我们可以使用 $90^\circ$ 并行扫描，仅需 $P = 9$ 解码步骤。

总之，所提出的上下文编码设计表明：给定 $P \times P$ 图像补丁和 $k \times k$ 掩码卷积，且 $P > \left\lceil \frac{k}{2} \right\rceil$，我们可以设计一系列上下文模型 $\{M^{(k+3)/2}_ k, M^{(k+1)/2}_ k, \ldots, M^1_ k\}$，导致 $\left\{ \frac{k+3}{2} \cdot P - \frac{k+1}{2}, \frac{k+1}{2} \cdot P - \frac{k-1}{2}, \ldots, P \right\}$ 并行解码步骤，通过逐渐调整上下文像素。相应的扫描角度为 $\left\{ \frac{180}{\pi} \cdot \arctan\left( \frac{2}{k+1} \right), \frac{180}{\pi} \cdot \arctan\left( \frac{2}{k-1} \right), \ldots, 90^\circ \right\}$。在实验中，我们设置 $P = 64$， $k = 7$ 并选择上下文模型 $M^3_ 7$。 $M^3_ 7$ 拥有几乎与 $M^5_ 7$ 相同的压缩性能，但需要更少的编码步骤。

![](https://img-blog.csdnimg.cn/direct/88050c87d9854b6a94ed03c0591f806b.png)


###### 2. 自适应残差区间

由于原始图像 $x$ 和其有损重建 $\tilde{x}$ 的像素都在区间 $[0, 255]$ 内，相应的残差 $r$ 的元素在区间 $[-255, 255]$ 内。为了对每个 $r_ {i,c}$ 进行熵编码，我们需要计算并使用 511 个元素的 PMF，这效率低下。由于原始残差通常接近零，使用 511 个元素是没有必要的，我们可以使用更小的区间，即 $[- m, m]$ 以提高编码效率，其中 $m \leq 255$ 根据残差的分布自适应确定。具体来说，我们通过满足以下条件确定 $m$ 的值

$$
m = \left\lceil 1.05 \cdot \sqrt{\frac{2}{n_ c} \sum_ {i,c} (r_ {i,c} - \mu_ r)^2} \right\rceil,
$$

其中 $n_ c = 3H \cdot W$ 是 RGB 图像中的像素数量。 $\mu_ r = \frac{1}{n_ c} \sum_ {i,c} r_ {i,c}$ 是残差的平均值。区间 $[- m, m]$ 满足三西格玛经验法则， $m$ 的值应接近 $\frac{2}{n_ c} \sum_ {i,c} (r_ {i,c} - \mu_ r)^2$。我们采用 1.05 的因子来放松区间。

给定 $m$，我们将残差 $r$ 截断为 $\hat{r} = \min(\max(r, -m), m)$ 并使用 $2m + 1$ 元素的 PMF 对 $\hat{r}$ 进行编码。残差编码的成本由

$$
R_ r = E_ {p(x)} E_ {q_ \theta(\hat{y}, \hat{z}|x)} [ - \log p_ \theta(\hat{r}| u, C_ r) ] + \| r - \hat{r} \|_ 0,
$$

其中 $\| r - \hat{r} \|_ 0$ 是零范数正则化，用于计算 $r$ 中截断残差的数量。残差编码成本是速率正则化熵，导致压缩性能和编码效率之间的平衡。在训练过程中，我们使用第一个 mini-batch 初始化 $m$ 的值，并自适应地更新每个批次的 $m$。这种简单的正则化仅适用于 RC，并且可以轻松集成到 DLPR 编码框架中。

## V. 实验

### A. 实验设置

我们在 DIV2K 高分辨率训练数据集 [62] 上训练 DLPR 编码系统，该数据集由 800 个 2K 分辨率的 RGB 图像组成。尽管 DIV2K 最初是为图像超分辨率任务构建的，但它包含大量高质量图像，适合训练我们的编解码器。在训练过程中，这些 2K 图像首先被裁剪成 121,379 个大小为 128×128 的不重叠补丁。然后，我们以 0.5 的随机因子水平和垂直翻转这些补丁，并进一步随机裁剪翻转后的补丁至 64×64 大小。我们使用 Adam [63] 优化所提出的网络，共训练 600 个周期，每个小批量的大小为 64。初始学习率设为 $1 \times 10^{-4}$，并在第 350, 390, 430, 470, 510, 550, 590 个周期时衰减至原来的 0.9 倍。

我们在六个图像数据集上评估训练好的 DLPR 编码系统：

- **ImageNet64**：ImageNet64 验证数据集 [64] 是 ImageNet 验证数据集 [65] 的降采样版本，由 50,000 个 64×64 大小的图像组成。
- **DIV2K**：DIV2K 高分辨率验证数据集 [62] 由 100 个 2K 彩色图像组成，与 DIV2K 高分辨率训练数据集共享相同的域。
- **CLIC.p**：CLIC 专业验证数据集由 41 个专业摄影师拍摄的彩色图像组成。CLIC.p 中的大多数图像为 2K 分辨率，但其中一些图像较小。
- **CLIC.m**：CLIC 移动验证数据集包含 61 个由手机拍摄的 2K 分辨率彩色图像。CLIC.m 中的大多数图像为 2K 分辨率，但其中一些图像较小。
- **Kodak**：Kodak 真彩色图像套件 [66] 包含 24 张分辨率为 768×512 或 512×768 的彩色图像。
- **Histo24**：Histo24 数据集 [67] 由 24 张高分辨率病理图像组成。

为了评估，我们使用了图像压缩中广泛采用的两个指标：BPP 和 PSNR。BPP 衡量比特率（每像素的比特数），PSNR 衡量重建图像的质量。

![](https://img-blog.csdnimg.cn/direct/8bce5e35adcd44b8bd577e5e38d0743c.png)



### B. 无损图像压缩

我们评估 DLPR 编码在上述六个数据集上的无损图像压缩性能，并与传统无损图像编解码器（JPEG-LS [2]，BPG [51]，FLIF [4]，JPEG-XL [5]）和一个实际的学习无损图像压缩方法（L3C [10]）进行比较。如表 I 所示，除了 Kodak 数据集略微落后于 FLIF 外，我们的 DLPR 编码系统在所有数据集上都实现了最佳无损压缩性能。特别是，我们的 DLPR 编码系统大幅优于 L3C，证明了将有损图像压缩与残差压缩相结合的有效性。


![](https://img-blog.csdnimg.cn/direct/56333f15e57c4666af72c576849f9933.png)

![](https://img-blog.csdnimg.cn/direct/962775becfd643698c8972e7605b5bcc.png)


### C. 近无损图像压缩

对于近无损图像压缩，我们考虑可变 $\tau \in \{0, 1, ..., 5\}$ 并在公式 (20) 中设置 $\lambda = 0.03$ 以实现稳健的性能。我们将可扩展近无损压缩方案与 $\tau$ 特定的近无损压缩方案以及传统近无损编解码器（JPEG-LS 和 CALIC [53]）进行比较。如图 9 和表 II 所示，对于大多数 $\tau$ 值，我们的可扩展方案（带 SQRC）比 $\tau$ 特定方案具有更好的压缩性能，并显著优于传统编解码器。

### D. DLPR 编码的运行时间

我们评估了 DLPR 编码在三种不同大小图像上的运行时间，并与四个代表性的传统无损图像编解码器（JPEG-LS，BPG，FLIF，JPEG-XL）和实际学习方法（L3C 和 Minnen[MSE] [40]）进行比较。如表 III 所示，在编码速度方面，我们的无损 DLPR 编码几乎与 FLIF 一样快，且比 BPG，JPEG-XL，L3C 和有损 Minnen[MSE] 快得多。尽管在解码速度方面我们的无损 DLPR 编码比传统编解码器慢，但对于 2K 分辨率的图像仍然实用，并且比 L3C 和有损 Minnen[MSE] 快得多。当 $\tau > 0$ 时，由于自适应残差区间方案，近无损 DLPR 编码可以更快。

![](https://img-blog.csdnimg.cn/direct/9c2b62e260794f8aa83873a07ce52c78.png)


### E. 消融研究

我们进行消融研究，以分析 LIC 和 RC 不同网络架构对无损压缩性能的影响。表 IV 显示了所提出的分析/合成块和 Swin 注意力块相比传统卷积层和注意力块提高了压缩性能。表 V 展示了所提出的 RC 架构的有效性，表 VI 比较了不同的熵模型，显示了逻辑混合模型在复杂残差分布中的最佳表现。

![](https://img-blog.csdnimg.cn/direct/9c2c2701a4034e08bdd745ac175d989d.png)


我们在 Kodak 数据集上提供了近无损重建的视觉示例，如图 10 所示。我们的 DLPR 编码系统即使在较小的 $\tau$ 值下也能实现高视觉质量，与原始图像的感知差异最小。


![](https://img-blog.csdnimg.cn/direct/64af4abf26854505b260882abd3b7231.png)

![](https://img-blog.csdnimg.cn/direct/15f03070cca64cc4aa9a38538b673179.png)

![](https://img-blog.csdnimg.cn/direct/11d372bc86bc4ebfbc5d785f5254e60d.png)

![](https://img-blog.csdnimg.cn/direct/f4bb690629934a03b7a4b2de1a019541.png)

![](https://img-blog.csdnimg.cn/direct/13d8d4927fc94468a6b8f2bc676bff1a.png)

![](https://img-blog.csdnimg.cn/direct/0b00befaac274ad7ba2e16559e3d18d6.png)

## VI. 结论

在本文中，我们提出了一个统一的 DLPR 编码框架，用于无损和近无损图像压缩。该框架包括一个有损图像压缩器，一个残差压缩器和一个可扩展量化残差压缩器，全部端到端训练。DLPR 编码系统支持具有可变 $\ell_ \infty$ 约束 $\tau$ 的可扩展近无损压缩，而不是为不同 $\tau$ 训练多个网络。我们还引入了一种新颖的上下文编码设计和自适应残差区间方案来加速编码过程。广泛的实验表明，DLPR 编码系统在实际图像压缩任务中实现了最先进的压缩性能和竞争力的编码速度。

声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。












