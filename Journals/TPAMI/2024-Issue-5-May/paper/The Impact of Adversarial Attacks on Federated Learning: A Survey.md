# 题目：[The Impact of Adversarial Attacks on Federated Learning: A Survey](https://ieeexplore.ieee.org/document/10274102/)  
## 对联合学习中对抗性攻击的影响：一项调查
**作者：Kummari Naveen Kumar, Chalavadi Krishna Mohan, 和 Linga Reddy Cenkeramaddi** 

**源码链接：** https://github.com/lab-sun/PotCrackSeg

## 摘要
联合学习（FL）已经出现作为一种强大的机器学习技术，它允许从分散的数据源开发模型。然而，FL的分散性质使其容易受到对抗性攻击的影响。在这项调查中，我们通过涵盖攻击预算、可见性、泛化能力等多个方面，全面概述了恶意攻击对FL的影响。以往的调查主要集中在多种类型的攻击和防御上，但没有考虑这些攻击在预算、可见性和泛化能力方面的冲击。本调查旨在通过识别具有低预算、低可见性和高影响的FL攻击来填补这一空白。此外，我们讨论了FL领域对抗性防御的最新进展，并强调了保护FL的挑战。本调查的贡献是三方面的：首先，它提供了一个全面和最新的FL攻击和防御的概述。其次，它强调了考虑FL攻击的影响、预算和可见性的重要性。最后，我们提供了十个案例研究和改进FL系统安全性和隐私的潜在未来方向。

## 关键词
对抗性攻击, 安全挑战, 攻击状态, 攻击与防御, 预算, 联合学习, 泛化能力, 影响, 在线与离线攻击, 真实世界应用领域, 可见性。
## I. 引言
联邦学习（FL）[1] 是一种去中心化的机器学习（ML）范式[2]、[3]，它允许使用多个参与方的数据开发模型，同时保留他们各自的数据所有权。这种方法对于敏感数据特别有价值，因为它确保了用户隐私[4]。联邦学习最初由谷歌研究人员在2016年提出[5]，提出了一个框架，用于在不损害隐私的情况下，在移动设备等分散的数据源上训练ML模型。随着时间的推移，FL作为一种保护隐私的ML技术获得了 popularity，见证了大量的研究和现实世界的应用[6]、[7]。
### 联邦学习中的威胁
FL的去中心化特性使其容易受到敌意攻击[8]、[9]的威胁，这些攻击被归类为以效用为中心和以隐私为中心的威胁[10]。以效用为中心的威胁涉及数据投毒或模型篡改，从而损害准确性[11]、[12]、[13]。隐私中心的威胁[14]、[15]、[16]与参与者数据暴露有关，冒着敏感信息泄露的风险，侵蚀对FL系统的信任。此外，攻击根据攻击来源被分为两类：因果性（训练时）或规避性（测试时），如图1所示。在因果性攻击中，恶意参与者在训练期间提交有毒数据或篡改模型更新，使模型的预测产生偏差[13]、[17]、[18]。相反，规避攻击[19]、[20]通过在推理期间修改输入测试数据来操纵模型的预测。因果性和规避性攻击都对FL模型的准确性和隐私构成重大威胁。此外，当对手拦截客户端和服务器之间的敏感数据或操纵通信时，通信通道攻击是另一种威胁。通信通道攻击的一个例子是中间人（MitM）[21]攻击，攻击者截取通信通道并操纵数据。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5123d3c458464e25b6ea7f047b94c3b9.jpeg" width="70%" />

</div>

### 现有调查的局限性
表I突出了现有调查的差距，并概述了我们调查的广泛范围。虽然一些先前的调查考虑了攻击可见性的主题，但它们没有全面地解决攻击影响、攻击预算和攻击可见性作为对FL系统综合影响的问题。现有的调查主要关注单独的方面或提到的因素的子集，而没有提供它们相互作用的统一整体分析。因此，我们的调查旨在通过综合考虑攻击影响、预算和可见性，提供对敌意攻击对FL潜在影响的更全面理解，来弥补这一差距。此外，许多现有的调查没有解决攻击的状态，如在线或离线，以及它们对FL系统安全的影响。因此，我们将涵盖各种方面，如攻击影响、预算、可见性、泛化性、攻击状态、攻击指标以及性能值。我们还将讨论不同现实世界应用领域的攻击案例研究，以及敌意攻击对FL类型（如水平、垂直FL和联邦迁移学习）的影响。
此外，这篇调查论文专注于识别预算低、可见性低、影响大的FL攻击，这些攻击可能难以检测和预防，从而导致FL系统严重后果。此外，我们强调了FL领域对抗性防御的最新进展，并解决了保护FL的挑战。我们的调查是理解恶意攻击对FL影响的全面资源。它为理解当前挑战和未来研究方向提供了见解，以实现去中心化数据源的可信FL系统。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/8ecc21d4458e4f978aad35895b55804f.jpeg" width="70%" />

</div>

### 我们的贡献
这篇调查的贡献如下：
- **全面概述**：调查提供了关于FL攻击和防御的当前状态的全面和最新概述，涵盖了攻击影响、预算、可见性、泛化性、攻击状态和攻击指标以及性能值等多个方面。
- **识别FL攻击**：我们专注于理解和识别具有低预算、低可见性和高影响的FL攻击，因为这些攻击可能更难以检测，并且可能对FL系统产生严重后果。
- **FL的类别**：我们讨论了对水平FL、垂直FL和联邦迁移学习等FL类别的敌意攻击，以理解影响。
- **通信通道攻击**：调查简要讨论了针对FL客户端和服务器之间通信通道的攻击。
- **对抗性防御**：调查讨论了FL领域对抗性防御的最新进展、其类别和指标。
- **现实世界的案例研究**：本研究提出了十个全面的案例研究，评估了当前FL攻击的适用性及其局限性。此外，我们提出了潜在的解决方案，以有效解决这些局限性。
- **突出研究差距和潜在的未来方向**：最后，我们突出并确定了十个研究差距和潜在的未来方向，以保护和为FL系统提供隐私。

### 论文大纲
本文的其余部分组织如下：
- 第II节提供了FL的背景，基于数据分布的FL类型，以及威胁模型。
- 第III节涵盖了可以针对FL系统发起的不同类型敌意攻击。它包括对这些攻击的影响进行分析，包括预算、可见性和泛化性。
- 第IV节讨论了保护FL系统免受敌意攻击的不同防御策略。
- 第V节涵盖了用于评估FL系统中恶意攻击有效性的不同评估指标。
- 第VI节讨论了FL攻击领域的可能研究差距和探索领域。
- 最后，第VII节提供了论文的总结和结论性评论。

## II. 背景
1) **联邦学习**：它由一个服务器和n个客户端组成，每个客户端都有自己的本地私有数据。目标是学习一个全局模型 $W$，该模型在全局测试数据上表现出良好的性能。在每个 epoch $t$ 期间，服务器将模型 $W_t$ 发送给所有客户端。随后，每个客户端在自己的数据上训练它并计算更新。然后，服务器接收各个更新，并使用同步联邦加权平均（FedAvg）[5]进行聚合，以获得 $W_{t+1}$。这个过程迭代地持续，直到全局模型收敛。

2) **不同类型 FL**：根据参与者数据的特征和分布，FL可以分为三种类型，如图2所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/49169463cd2a4ef6a142d52782f88b1e.jpeg" width="70%" />

</div>

   - **水平联邦学习（HFL）**：是一种FL形式，参与者拥有不同的数据样本，但数据特征重叠，如图2(a)所示。它也被称为同质联邦学习。例如，不同地点的两家医院可能拥有不同患者数据，但底层特征相似，导致数据特征重叠。图2(a)中的红色垂直条表示参与者拥有相同的特征。HFL中的主要挑战是确保聚合模型在同时维护隐私和安全问题的同时，准确地代表客户端的数据。

   - **垂直联邦学习（VFL）**：包括参与者拥有重叠数据样本但不同特征的场景，如图2(b)所示。图2(b)中的红色水平条表示具有相同重叠样本的参与者。例如，在金融行业中，银行和电子商务公司可能拥有共同的用户，但每个实体收集的数据可能不同。VFL中的主要挑战在于有效地对齐来自不同来源的数据，同时维护隐私和安全考虑。

   - **联邦迁移学习（FTL）**：结合了FL和迁移学习的概念[47]。它的特点是跨不同样本的数据特征重叠有限，参与者之间的数据样本重叠最小，如图2(c)所示。图2(c)中的红色表格突出了不同的数据和特定于FTL的潜在投毒威胁，这些威胁在后续部分中讨论。迁移学习是一种机器学习技术，利用从一个领域或任务中获得的知识来提高另一个领域或任务的性能。FTL通过在大型公共数据集上训练模型，然后使用每个参与者的本地数据进行微调，解决了非重叠样本和特征的挑战。FTL在涉及不同数据类型（如文本、图像和语音数据）的场景中特别有价值，这些数据不容易组合。FTL中的主要挑战在于确保共享模型对公共数据集和客户端本地数据之间的领域变化具有韧性，同时保留隐私和安全。

3) **FL中的威胁模型**：威胁建模[48]是通过分析系统的组件[49]来识别潜在威胁和漏洞的过程。它涉及识别潜在攻击者、他们的动机、能力和战术，并评估成功攻击对机密性、完整性和可用性的影响。这个过程有助于确定关键威胁并加强系统的安全性。

   在FL中，威胁建模是必要的，因为它有助于识别潜在的漏洞，如投毒或模型反转攻击。Shejwalkar等人[11]强调了FL中威胁模型的关键维度，如下所述。

   - **攻击者的目标**：FL中的对手旨在实现三个目标，这些目标根据三个属性进行分类：安全违规（完整性或可用性）、攻击特异性（歧视性或非歧视性）和错误特异性（特定或通用）[11]。测试输入的误分类可能会损害系统性能。了解这些目标和属性对于保护FL系统至关重要。

   - **攻击者的了解**：在FL中，攻击者的了解可以被分类为白盒、灰盒或黑盒，如图3所示。在白盒设置[17]、[50]中，攻击者可以完全访问模型参数和预测，使其容易受到复杂的模型投毒攻击。在灰盒设置[51]中，攻击者对系统有部分了解，能够开发针对性的投毒攻击。在黑盒设置[52]中，攻击者无法访问模型参数，必须推断预测，使数据投毒攻击成为问题。此外，攻击者可以完全或部分了解来自良性客户端的数据[13]，其中完全了解允许访问FL中的所有良性和被破坏的客户端，而部分了解仅提供对被破坏客户端数据的访问。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/874e2473cc60428cb460ea0c6d8ad5cd.jpeg" width="70%" />

</div>

   - **攻击者的能力**：FL中的攻击者具有各种能力，可以广泛地分类为被动和主动：被动攻击[53]是指攻击者仅仅观察客户端和服务器之间的通信而不进行干预的攻击。在FL中，被动攻击可能涉及窃听通信渠道，并且由于它们不会破坏系统的正常功能，因此可能难以检测。另一方面，主动攻击涉及积极地操纵客户端和服务器的数据和模型。FL中的主动攻击可以采取不同的形式，如数据投毒、模型投毒和推理攻击[54]。

### III. 对FL的敌意攻击
图3展示了各种FL攻击的全面树状图，分类为主动和被动，以及效用中心和隐私中心攻击的子类别。攻击源自通信渠道、模型和数据等漏洞源头。攻击空间进一步划分为攻击类型、模式、状态和设置，为理解攻击变化提供了全面的理解。例如，攻击类型包括针对性的、非针对性的和后门攻击，而模式涉及周期性洗牌或无洗牌。攻击状态可以是在线的或离线的，而设置可以是白盒、灰盒或黑盒。叶节点表示实际攻击，提供了攻击执行的具体示例。这棵树状图是理解FL攻击多样性的有价值工具，并有助于开发有效的防御措施以增强FL系统安全性。在后续部分中，将详细说明进一步的解释和相应的攻击，并在表II中详细说明。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/f95d2213e0de476a8f398ea0ba4e2d54.jpeg" width="70%" />

</div>

1) **FL中的攻击来源**：在FL中，攻击可以来自客户端、中央服务器或通信渠道。作为参与训练阶段的内部人员，客户端可以发起影响模型准确性的因果性攻击。参与测试阶段的中央服务器容易受到试图绕过模型防御的规避性攻击。此外，拦截客户端和中央服务器之间模型更新的外部人员可以将通信渠道作为中间人攻击的目标。表II的第五列显示了FL中各种最新攻击的来源。

2) **HFL、VFL和FTL中的潜在攻击源**：图2提供了FL类型（HFL、VFL和FTL）及其相关漏洞的概述。在HFL中，客户端拥有不同的样本但共同的特征，容易受到特征推断攻击[78]。这些攻击利用基于梯度的生成对抗网络（GANs）[78]重建良性客户端的私有数据。图2(a)中的箭头象征着对手从良性客户端的训练数据中获取特征表示，并随后重建整个私有数据集。相反，在VFL中，客户端的数据样本具有重叠的特征和不同的特征（图2(b)），使它们容易受到标签推断攻击[73]。本地训练的底层模型和梯度引入了潜在的隐私问题，允许恶意参与者通过分析接收到的梯度的符号来推断受害者数据的标签[73]。图2(b)中的箭头表示对手能够推断出受害者数据的标签，最终导致隐私泄露。此外，在FTL中，参与者拥有不同的样本和特征，面临效用威胁。对手利用这一点发起数据投毒攻击[11]、[12]或操纵模型层，导致破坏性的更新，损害了良性客户端的效用（图2(c)）。这些攻击破坏了共享模型的预期目的，并阻碍了从预训练模型的无缝知识转移。图2(c)中的红色表格代表了注入的有毒数据，破坏了良性客户端的效用。表II的第二列列出了针对HFL、VFL和FTL在FL中的各种攻击。然而，值得注意的是，专门针对FTL系统的攻击数量有限，表明在这一研究和开发领域存在差距。

3) **FL中的攻击影响（AIm）**：FL中的攻击影响指的是攻击导致全局模型准确性降低的程度。对于以效用为中心的攻击，它是在攻击后全局模型的测试准确性降低的量度。为了量化影响，$A_{\theta}$ 表示在所有FL训练轮次中全局模型达到的最大准确性，而 $A^{*}_{\theta}$ 表示在给定攻击下模型的最大准确性。然后攻击影响（$I_{\theta}$）计算为 $|A_{\theta} - A^{*}_{\theta}|$ [11]。隐私中心的攻击，旨在执行成员资格推断或模型反转，有不同的影响指标，如均方误差（MSE）、峰值信噪比（PSNR）、结构相似性指数（SSIM）和学习感知图像补丁相似性（LPIPS）。为了评估各种攻击的影响，我们根据它们的性能分配了三个标签，即低（L）、中（M）和高（H），更多细节在评估第V节中。评估攻击影响对于理解攻击严重性和制定有效的缓解策略至关重要。表II的第六列显示了FL中不同以效用为中心和以隐私为中心攻击的攻击影响标签。

4) **FL中的攻击预算（AB）**：FL中的攻击预算在确定攻击者为破坏系统而使用的资源方面至关重要。它包括影响全局模型准确性的效用预算和损害客户端数据隐私的隐私预算。一般来说，效用预算可以考虑诸如恶意客户端的数量、有毒数据的数量、模型投毒攻击中损坏的模型层数、使用替代模型以及额外的开销模型如GANs等因素。另一方面，隐私预算参数 $\epsilon$ 在添加差分隐私[79]、[80]作为FL系统的保护时被考虑。然而，在本文中，我们从攻击者的角度引用隐私预算，它是攻击者用来破坏个别客户端数据隐私的资源数量。我们采用了一种全面的方法，考虑了多个参数，如总客户端、每轮选择用于聚合的客户端、恶意客户端、本地和全局轮次，来分配标签，即低（L）、中（M）和高（H），代表攻击资源强度和复杂性。基于这些参数分配标签使我们能够衡量攻击的资源强度和复杂性。例如，涉及更多客户端、每轮选择更多客户端、并且有更多的恶意客户端的攻击表明了多客户端攻击策略，具有显著的资源投资。这类攻击被赋予了“H”标签。此外，本地和全局轮次的数量作为平局破坏者，当两个攻击具有相似的前述参数值时。具有更高数量的本地和全局轮次的方法被认为需要更多的迭代和计算才能收敛，表明了更多的资源承诺。这种将本地和全局轮次作为平局破坏者考虑的方法进一步提高了我们标签方法的准确性和粒度。表II的第七列显示了各种最新效用和隐私中心FL攻击的攻击预算标签。我们研究中的评估第V节中使用了用于标记的更详细的全面细节和量化。

5) **FL中的攻击可见性（AV）**：在FL安全性中，攻击可见性至关重要，影响攻击的检测和预防。对于以效用为中心的攻击，可见性在于检测恶意模型更新，如果攻击者引入隐蔽的模型投毒攻击或以难以通过服务器的准确性和权重更新分析检测的方式对数据进行投毒，这可能很具有挑战性。在这种情况下，攻击可见性在于恶意客户端的模型更新是否远离良性更新。我们根据攻击者避免检测的努力，为以效用为中心的攻击评估攻击可见性，并使用标签，即低（L）、中（M）和高（H）。隐私中心的攻击侧重于数据重建或成员资格推断，而不在模型上产生明显的扰动，使攻击可见性不太相关。评估攻击可见性有助于开发针对潜在攻击的对策。对于可见性低的攻击，可能需要加强检测措施。表II的第八列显示了FL中最新以效用为中心攻击的攻击可见性标签，这不适用于FL中的隐私中心攻击。

6) **FL中的攻击泛化性**：FL中的攻击泛化性指的是攻击者破坏FL系统的隐私或效用的能力，无论其具体配置如何。FL系统可以在设备类型、客户端选择、聚合方法等方面有所不同，因此泛化性对于攻击者发动大规模攻击至关重要。在以效用为中心的攻击中，泛化性意味着攻击可以降低具有类似特征的FL模型的性能。例如，能够成功破坏一个FL模型的数据投毒或模型窃取攻击，也可能能够破坏具有类似架构的另一个FL模型。同样，在隐私中心的攻击中，它指的是在不同FL配置或模型中破坏参与者的数据。数据验证、模型验证和差分隐私等技术在设计强大的FL系统以抵抗具有高泛化性的攻击中至关重要。通过研究FL中的泛化性，我们保护FL模型的隐私和效用免受大规模威胁。表II的第九列显示了FL中各种最新效用和隐私中心攻击的攻击泛化性。

7) **FL中的攻击状态**：FL中的攻击状态指的是攻击是在每个通信轮次（在线）持续进行还是在FL过程开始时（离线）发生。在线攻击涉及对手重复对被破坏的客户端投毒，导致对攻击预算和可见性的持续影响。例如，FL中的模型投毒攻击在每轮中持续对更新的全局模型投毒，导致持久影响。另一方面，离线攻击只在FL过程开始时投毒，如静态标签翻转数据投毒攻击，预算和可见性低。理解攻击状态对于估计攻击者的意图进行高影响、低预算和低可见性在线攻击至关重要。通过理解攻击者的行为，可以实施适当的防御机制，保护FL系统免受在线和离线攻击的侵害。表II的第十列显示了最新FL攻击的状态。

8) **FL中的攻击设置**：攻击者的知识影响FL中的攻击设置，可以分为三类：白盒、灰盒和黑盒：在FL中，攻击者的知识可以被分类为白盒、灰盒或黑盒，如第II节所讨论的。根据[11]，黑盒离线数据投毒攻击设置和白盒在线模型投毒设置最接近生产部署FL。理解攻击者的知识设置对于估计攻击者的预算、影响和可见性至关重要。表II的第十一列为各种最新的FL攻击呈现了知识设置。我们的观察表明，灰盒FL攻击的研究存在显著的研究空白，很少有研究关注这一领域。

9) **攻击类型**：在FL中，以效用为中心的攻击可以根据攻击者的目标被分类为目标性、非目标性和后门攻击。在目标性攻击中，目标是操纵模型对特定目标类别的预测。相比之下，非目标性攻击旨在通过导致任何类别的不正确预测来降低模型的整体性能。后门攻击涉及在训练数据中添加触发器或模式，导致模型在输入数据中存在触发器时做出不正确的预测。表II的第十二列显示了各种最新的以效用为中心的FL攻击的攻击类型。了解这些攻击类型对于设计强大的FL系统和开发有效的防御机制至关重要。通过研究它们的性质和影响，我们可以识别弱点，评估安全性和性能之间的权衡，并实施预防措施以增强FL系统的安全性。

10) **攻击模式**：FL攻击的领域可以从攻击模式的角度进行可视化，具体包括带和不带周期性洗牌的视角，如图3所示。周期性洗牌是指攻击者动态地在恶意客户端ID之间切换，这使得检测机制难以识别恶意客户端。这个参数由频率（对手在相同ID下保持的全局轮次数量）和数量（任何给定时间内的恶意客户端数量）等因素特征化。考虑这个参数至关重要，因为周期性洗牌允许攻击者通过切换ID来混淆服务器的检测机制，显著影响FL的整体性能。通过理解这一方面，可以开发有效的防御机制来对抗此类攻击并提高FL系统的安全性。

### 常见任务在FL下受到攻击
表II的第十三列显示了各种最新的FL攻击所针对的任务。虽然大多数攻击论文集中在图像分类任务上，但也有一些考虑了回归、文本、情感分类和异常检测等其他任务。然而，FL领域内对更高级别的计算机视觉任务（如检测、跟踪和分割）的攻击仍存在研究空白。解决这一空白将有助于更全面地理解与FL相关的潜在漏洞和风险，并设计出更健壮、更安全的FL系统，以保护敏感数据并提供可靠和准确的结果。

## IV. 防御策略
FL中的防御策略有不同类别。表III系统地按类别、来源、它们所防御的攻击以及所使用的指标全面概述了现有的效用中心和隐私中心攻击的防御。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c06ce3fd626e4ecc9754055f4e4e898c.jpeg" width="70%" />

</div>

1) **针对FL中以效用为中心的攻击的防御**：
   - **对抗性训练**：这种防御策略主要在客户端实施，旨在防御数据投毒攻击。客户端上的本地模型在对抗性示例上进行训练，这些示例是为欺骗模型并导致错误预测而恶意设计输入数据。通过在这些示例上训练模型，它可以学会对此类攻击更加健壮。此策略的示例包括FAT [81]、FedDynAT [82]和GALP [83]。
   - **模型剪枝**：模型剪枝是针对FL中模型投毒攻击的防御策略，可以在服务器端和客户端实施，具体取决于特定方法。在服务器端，剪枝算法可以在聚合过程中应用，以从全局模型中移除不必要的参数或连接。同样，客户端可以在将更新发送到服务器之前执行本地模型剪枝，减少大小并专注于其数据的相关特征。总体而言，它减少了模型复杂性并降低了计算需求，增强了通信、鲁棒性、泛化能力和推理效率。示例包括PruneFL [84]和Network Pruning [85]。
   - **拜占庭鲁棒聚合技术**：这些通常在服务器端实施，并用于保护免受模型和数据投毒攻击，其中一些客户端向服务器发送恶意更新。这些技术用作服务器上的聚合算法，而不是FedAvg [5]，以过滤掉恶意更新，并确保仅使用有效更新来构建模型。其中一些包括Krum [86]、Multi-krum [86]、Trimmed Mean [87]、Median [87]、Bulyan [88]、RLR [89]、ZeKoC [90]、ShieldFL [91]、自适应模型平均 [92]和FLTrust [93]。
   - **正则化**：正则化是一种适用于FL中服务器和客户端两侧的防御策略，可保护免受数据投毒和模型投毒攻击。在服务器端，正则化技术在模型更新聚合期间应用，以防止过拟合并增强模型泛化能力。常见的方法包括L1或L2正则化，在模型训练期间的损失函数中引入惩罚项。它控制共享模型的复杂性，并促进从本地数据中学习鲁棒模式。在客户端，参与者在他们的模型训练中采用正则化技术，如dropout、批量归一化或权重衰减。这对抗了本地数据的过拟合，有助于整体FL的鲁棒性。示例包括LSR [94]、ConTre [95]和Su等人[96]。
   - **检测和移除**：此方法通常在服务器端实施。它涉及检测和移除模型中的恶意更新。这是通过监视更新并标记任何可疑或不符合预期模式的更新来完成的。示例包括LoMar [97]、Federated Reverse [98]、DDaBA [99]、SecFedNIDS [100]、PA-SM [101]、基于密度的异常检测[102]、BaFFLe [103]和基于Mahalanobis距离的检测[105]。
   - **鲁棒客户端选择技术**：这些用于选择最值得信赖和可靠的客户端，并在服务器端实施。这有助于确保只有有效的更新用于聚合，并降低了使用恶意更新的风险。示例包括Ensemble FL [106]、DivFL [107]和FedClean [108]。
   - **数据和更新分析**：这种防御策略可以在FL的服务器和客户端两侧实施。在服务器端，它涉及仔细检查聚合的客户端更新，以检测可疑模式或不一致性。应用统计和机器学习技术，如异常检测，以识别潜在的恶意活动或数据操纵。在客户端，数据和更新分析包括预处理、数据质量检查、验证和清理，以确保在训练前的数据完整性。客户端还在与服务器共享之前验证其本地更新。示例包括SIREN [109]、DeepSight [110]、Biscotti [111]和FL-Defender [112]。

2) **针对FL中以隐私为中心的攻击的防御**：
   - **同态加密**：这是FL中的强大防御，通过允许在加密数据上执行计算来确保隐私保护。同态加密使数据在仍然有用计算的同时保持加密状态，使攻击者难以访问敏感信息。示例包括DCAE [46]和PEFL [122]。
   - **知识蒸馏**：它涉及将知识从较大的复杂模型转移到较小的简单模型。通过这样做，较小的模型可以在不处理大量数据的情况下进行准确预测，减少了客户端和服务器之间共享数据的需求。示例包括FEDGEN [126]、FedKD [127]、FedFTG [128]和PATE [129]。
   - **安全多方计算**：该技术通过使多个参与方能够在不泄露各自数据的情况下联合计算函数，保护隐私。它确保了一个安全的过程，不泄露任何敏感信息。示例包括AMPC [130]、SMPAI [131]和Byrd等人[132]。
   - **可信执行环境（TEE）**：通过为运行敏感应用程序提供安全环境，TEE保护免受篡改或逆向工程攻击。这保护了试图窃取或分析数据的隐私攻击。示例包括Flatee [133]、Chen等人[134]和PPFL [135]。
   - **分割学习**：它将模型在客户端和服务器之间进行分割，允许敏感数据保留在客户端，同时使模型能够以分布式方式更新。这种方法保护了免受试图窃取或分析数据的攻击。示例包括SplitLearn [136]、FSL [137]和Splitfed [138]。
   - **扰动梯度**：该技术通过向模型训练中使用的梯度添加随机噪声来保护易受攻击的数据，从而阻碍攻击者使用基于梯度的攻击来逆向工程模型或窃取敏感数据。示例包括OtA-FL [139]、Yang等人[140]、局部随机扰动[141]、Soteria [142]、DgstNN [143]、Haung等人[144]和DtC [145]。
   - **差分隐私**：这种技术在高度敏感的FL场景中使用，以保护数据免受未经授权的访问。通过在将模型更新发送到服务器之前引入噪声，差分隐私保护了用于模型训练的数据的隐私，防止攻击者了解有关个别数据点的敏感信息。它作为防御旨在窃或分析数据的隐私攻击的手段。示例包括NbAFL [146]、Hu等人[147]、Triastcyn等人[79]、PixelDP [148]和2DP-FL [149]。

## V. 评估
在本节中，我们根据攻击影响、可见性和预算的权衡维度评估最新的攻击。此外，我们介绍了常用的数据集、FL和攻击参数，以及后续部分中的指标及其相应的值。

1) **数据集**：在FL中用于以效用为中心的攻击的常用数据集包括CIFAR10、MNIST、FashionMNIST、Purchase、FMNIST、EMNIST和Reddit。同时，MNIST、CIFAR10、CIFAR100、ImageNet和LFW是用于FL中隐私中心攻击的常用数据集，如表II所示。

2) **指标**：如第V节所述，用于评估FL中以效用为中心的攻击影响的是全局测试准确率（GTA）攻击前后的差异。此外，还使用了错误率、RFA距离、FoolsGold权重、L2距离和模型权重值等其他指标。相比之下，FL中隐私中心攻击的评估是使用准确度、精确度、召回率、F1分数、MSE、PSNR、SSIM和LPIPS等指标进行的。表IV和表V显示了所有前述指标。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/d495a77d23384f75bf9b8623d92fe2e4.jpeg" width="70%" />

</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c1abb0e0b4bb458b96ba49a4b7dce9d6.jpeg" width="70%" />

</div>


3) **以效用为中心的攻击在FL中的权衡评估**：图4显示了考虑攻击预算、可见性和影响之间的权衡的FL中以效用为中心的攻击的比较分析。理想情况下，攻击者的目标是低预算、低可见性和高影响。然而，这些维度之间存在权衡，其中更高的预算即使在较低可见性下也可能导致更大的影响。另一方面，高可见性可能导致更高的检测率，从而导致较低的影响。平衡这些维度对于攻击者有效实现其目标至关重要。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/7158ef4abe9648b3ab098539f9c9c429.jpeg" width="70%" />

</div>

### 攻击者视角下的标签分配和量化
在表II（第III节）中为以效用为中心的攻击分配和量化攻击预算、可见性和影响的标签是一项复杂任务，因为每种攻击在不同和动态的参数设置下运行，如表IV所示。我们的方法旨在提供从攻击者视角出发的攻击的一般化评估，提供关于它们在影响、预算和可见性方面的相对立场的全面视图。

图4中的攻击预算、可见性和影响的量化是基于[0, 1]刻度，代表低、中和高水平。被标记为低的攻击被分配了每个参数（预算、可见性和影响）0.1的值，而中和高标签分别被分配了0.5和0.9的值。对于在表IV中评估相似的攻击，进行了±0.05的微小调整。值得注意的是，Edge-case攻击[67]和ADA[59]在图4中接近理想的攻击状态，表现出潜在的风险和评估FL防御的必要性。

### 攻击影响
表IV展示了FL中以效用为中心的攻击的影响，范围从数据投毒攻击的3%到76.14%，以及模型投毒攻击的3.4%到89.97%，这些攻击跨越了各种数据集和威胁模型。它根据数据集、数据与模型投毒、威胁模型参数以及不同数量的恶意客户端的最佳与最差攻击影响提供了结构化分类。该表为读者提供了一个全面的概述，展示了在不同设置下由最新攻击实现的攻击影响值。我们强调，我们比较的焦点在于权衡分析，而不是仅基于攻击影响就宣布最佳攻击，因为攻击预算、可见性和其他因素在评估攻击的效率时也起着重要作用。

4) **以隐私为中心的攻击在FL中的权衡评估**：图5展示了FL中以隐私为中心的攻击的二维比较分析，重点关注攻击预算和影响维度，因为攻击可见性不是特别相关。以隐私为中心的攻击的标签分配和量化在[0, 1]范围内的方法与以效用为中心的攻击类似，如前所述。此外，对于标签相似的攻击，根据对表V的评估进行了±0.05的微小调整。经过广泛的文献综述，我们确定AGIC[58]和特征推断攻击[76]接近理想的攻击状态，展示了在破坏隐私方面的显著效果和效率。AGIC利用近似梯度反转，在多个周期中从模型或梯度更新有效地重建图像，而特征推断攻击提出了一种基于逻辑回归和决策树模型的方法，并扩展到复杂模型，如神经网络和随机森林模型。这些观察结果强调了考虑各种攻击特性以评估鲁棒性和严重性的重要性。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5843091390764534ade148693afe1f98.jpeg" width="70%" />

</div>

### 攻击影响
表V展示了FL中以隐私为中心的攻击的影响，使用了常用指标，如准确度、PSNR、SSIM、MSE和F1分数等。影响值因数据集和攻击而异，取决于威胁模型、攻击者能力和目标等因素。该表根据不同的数据集、攻击点、隐私攻击指标、威胁模型参数和影响提供了攻击影响数据的结构化分类。我们提供此表的目的是为读者提供一个全面的概述，展示不同数据集和参数值在文献中使用的攻击及其相应的攻击影响值，而不是宣布最佳攻击。

5) **其他FL参数**：表IV和表V分别展示了以效用为中心和以隐私为中心的攻击的不同的FL参数值。

- **客户端数量**：FL攻击中使用的客户端数量范围很广，从10到83293不等，而每轮被服务器选中用于聚合的客户端更新数量从10到100不等。恶意客户端的数量从1到8320不等，取决于它们的能力及目标。对于以隐私为中心的攻击，总客户端数量通常从4到100不等，并且每轮都使用所有客户端。由于服务器是隐私中心场景中的主要攻击源，没有恶意客户端。然而，我们观察到一些论文缺乏关于总客户端数量和每轮选中的客户端数量的详细信息。客户端的数量直接影响攻击预算、可见性，因此也影响攻击的影响。

- **非独立同分布（Non-IID）对FL攻击的影响（Dirichlet分布[158]）**：Dirichlet分布在FL中常用于模拟客户端之间的数据分布。通过调整参数α，可以控制独立同分布（IID）数据在客户端之间的分割的密度，影响数据分布的非IID性质。较高的α值会在客户端之间产生更均匀的数据分布，减少它们数据分布的变化。相反，较低的α值会导致更集中或偏斜的数据分布，引入客户端之间的异质性和非IID性。正确调整α使FL系统能够考虑客户端数据的固有异质性，这在现实世界的FL场景中至关重要。

  Dirichlet分布在评估FL效用攻击的影响中起着关键作用。当与攻击策略结合使用时，高度非IID的客户端数据集可以在攻击之前和期间降低全局模型的准确性，加剧了整体影响。然而，攻击的影响并不仅仅由非IID性决定。其他因素和参数，如总客户端数量、每轮选中的客户端数量、恶意客户端的存在以及本地和全局训练周期，共同影响攻击影响的大小。

  FL中的非IID数据对隐私既有积极影响也有消极影响。从积极的方面来看，客户端之间的不同数据特性使得攻击者更难进行准确的推断攻击或重建敏感信息。然而，高度不同的非IID数据分布也可能潜在地揭示数据集中的特定个人或群体。攻击者可能会利用这些差异来识别具有独特特征或敏感属性的客户端。非IID数据的隐私影响取决于特定攻击场景、隐私保护机制的使用（例如，差分隐私技术）以及攻击者的知识和能力。非IID数据本身并不能保证隐私保护，但在某些情况下可以为攻击者增加复杂性。

  表IV和表V展示了在最新的攻击中使用的各种α值及其影响。大多数FL效用攻击使用α值为0.5、0.9和1，而以隐私为中心的攻击通常使用α为1，表明IID数据分布。然而，评估在不同非IID程度下的攻击对现实世界设置中攻击影响的研究存在显著空白。

- **聚合技术**：在FL中广泛使用的聚合客户端更新的联合平均（FedAvg）[5]被几个在第IV节讨论的鲁棒聚合技术补充，这些技术在表IV和表V中进行了概述。聚合技术的选取对于理解攻击的鲁棒性至关重要，因为非鲁棒的聚合方法可能导致高影响、低预算和对可见攻击的检测效果差。

- **本地和全局周期**：我们的文献分析揭示了效用中心攻击中本地和全局周期的广泛值范围，即本地周期为1到20，全局周期为40到2000，如表IV所示。同样，对于隐私中心攻击，本地周期的范围从1到10，全局周期的范围从100到20000，如表V所示。这一分析提供了对攻击者在设计FL攻击时所需努力和预算的洞察。因此，本地和全局周期的数量是设计FL攻击时的关键考虑因素。

- **模型架构**：在第III节-10中，我们讨论了图像分类是FL攻击论文中流行的任务，其中常用的模型架构包括VGG-9、ResNet-18、ResNet-50、ResNet20-4、Alexnet、定制的CNN和全连接网络（MLP）。对于其他任务，观察到LSTM架构的使用（如表IV和表V所示）。模型架构的选择至关重要，因为它影响攻击预算、可见性和影响。攻击较简单的架构可能预算低、影响高、可见性低，但未受攻击时的基础性能对现实世界使用不太实用。另一方面，攻击更深层次的标准神经网络需要更高的预算，并且由于投毒难度，导致影响较低，使攻击不太明显。因此，攻击者必须仔细选择一个提供更好基础准确性的模型，并以低预算和低可见性攻击它，以实现更高的影响。

6) **案例研究**：探索FL在不同领域应用的可能性威胁：图6和表VI提供了FL应用的概述，FL如何促进其运营，对安全性和隐私的威胁，以及需要解决的研究空白。研究空白包括隐私保护FL、增强在线学习安全性和调查攻击影响。尽管FL具有潜力，但通过意识和监管框架解决风险对于减轻FL在不同领域中的漏洞至关重要。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/af67b56d55954b3f84e130bb1deecc2d.jpeg" width="70%" />

</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/34d7cd515ee6481ab731e0b56b91c79e.jpeg" width="70%" />

</div>

## VI. 研究空白和潜在的未来研究方向
本研究广泛回顾了从攻击者视角出发的各种FL系统中的攻击文献。我们确定了开放性挑战，并在表VII中提出了未来研究的潜在方向。这些研究空白为解决FL当前的安全和隐私限制提供了有希望的机会。重点领域包括考虑不同的FL参数、攻击预算、可见性、影响和泛化性的新型攻击和防御。此外，需要探索不同FL组件（如通信协议、学习算法、超参数、压缩和公平性）中的漏洞。此外，开发实际且成本效益高的防御措施对于确保FL在现实世界应用中的安全性和隐私至关重要。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/a343b8c333074415a8caafb28480bcbc.jpeg" width="70%" />

</div>

## VII. 结论
本调查提供了对恶意攻击对FL影响的全面概述，涵盖了攻击影响、预算、可见性、泛化性、现实世界应用、攻击和防御以及攻击状态等多个方面。我们还强调了在设计和部署FL系统时考虑FL攻击的影响、预算、可见性和泛化性的重要性。我们确定了研究空白和潜在的未来方向，以改进FL系统的安全性和隐私性。这些空白包括开发新型攻击和防御，以平衡低攻击预算、低可见性、高影响和高泛化性，研究攻击在各种现实世界应用领域之外的性能，开发可以在接近FL生产部署的在线实际攻击环境中运行的防御措施，探索使用Dirichlet分布在隐私中心FL攻击中低与高集中数据的影响，以及研究攻击和防御对不同类型的FL的影响。我们还讨论了FL领域对抗性防御的最新进展，并强调了保护FL的挑战。总的来说，这篇调查论文是FL安全领域的研究人员、从业者和学生的宝贵资源，并为该领域的当前挑战和未来研究方向提供了见解I


# 声名
本文内容为论文学习收获分享，受限于知识能力，本文对原文的理解可能存在偏差，最终内容以原论文为准备。  
本文信息旨在传播和交流学术，其内容由作者负责，不代表本号观点。文中内容如涉及作品文字。图片等内容、版权和其他问题，请及时与我们联系，我们将在第一时间删文处理。
