# [A Little Truth Injection But a Big Reward: Label Aggregation With Graph Neural Networks](https://ieeexplore.ieee.org/document/10337741/)
## 题目：少量真实信息的注入，却能带来巨大的回报：使用图神经网络进行标签聚合
**作者：Zijian Ying; Jing Zhang; Qianmu Li; Ming Wu; Victor S. Sheng**  
**源码：https://github.com/fadewind/CrowdGNN**  
****

# 摘要

在众包注释任务中隐藏的各种相关性为进一步提高标签聚合的准确性带来了机会。然而，这些关系通常极难建模。大多数现有方法只能利用一种或两种相关性。在本文中，我们提出了一种新颖的图神经网络模型，即LAGNN，它通过利用具有卷积操作的深度图神经网络建模众包注释任务中的五种不同相关性，并导出了高标签聚合性能。利用标签相似性，LAGNN可以高效地修正工人之间的偏好。此外，通过在其训练阶段注入少量真实标签，LAGNN的标签聚合性能可以进一步显著提高。我们在大量通过变化六个自由度生成的模拟数据集上以及在八个人群众包数据集上以监督和无监督（不可知）模式评估LAGNN。还包括了数据泄露的实验。实验结果一致表明，所提出的LAGNN在标签聚合准确性方面显著优于六个最先进的模型。

# 关键词

- 众包
- 真实性推断
- 图神经网络
- 可解释学习

# I. 引言

众包在过去十年中展示了其节省成本、高效和实用性的特点。精心设计的聚合算法可以准确推断众包注释中的隐藏真相，从而允许应用监督学习算法以获得预测模型。因此，标签聚合（或真实性推断）在过去关于众包学习的研究中扮演了最关键的角色之一[46]。标签聚合的主要目标是让数据集中推断（或集成）的标签的值尽可能多地与其潜在的真实值相匹配。

最直接的方法是多数投票（MV）。它选择最多的选择作为真实情况，将所有工人和注释同等对待。当考虑到注释都是由工人提供时，MV就变得不太合适了。因为专家比普通工人更可信，注释本身的可信度并不一样。为了解决这个问题，Weight-MV[23]引入了工人之间的相关性到标签聚合中，根据工人的标签质量（标签准确性）向注释添加了与工人数量相同大小的线性权重。[21]声称工人之间的相关性可以帮助找到专家。ELICE[17]将这种工人-工人相关性建模转变为监督方法。除了工人之间的相关性，cBCC[34]和EBCC[22]通过扩展实例之间的相关性来扩展经典的贝叶斯推理方法BCC[18]。[25]还考虑了实例-实例相关性，并采用了主动真实性注入策略。SpeeLFC[4]，扩展了CrowdLayer[29]，引入了工人-类别相关性，具有可解释的参数。这些可解释的参数包含了每个工人的转移矩阵映射。GCN-Clean[15]通过利用图卷积网络[19]和N×N的亲和矩阵（其中N是示例的数量）来模拟类别之间的相关性。[40]通过应用异构图来建模工人-实例相关性。这个异构图包含工人节点和任务节点，为每个组件生成表示。尽管这些模型考虑了各种关系，但仍然没有一种方法能够尽可能多地利用标签任务中包含的相关性。

在这项工作中，我们首先得出了关于工人标签相似性与工人质量之间关系的两个结论。我们得出的结果是，具有更大标签相似性的两个工人也可能具有更相似的质量。我们发现，高质量工人更有可能具有更大的标签相似性。这为寻找高质量工人奠定了理论基础。

然而，在实际应用我们得出的结论时存在两个问题。一个问题是由稀疏注释引起的不确定性。考虑到标注任务的人力成本，实例通常只被标注几次。因此，工人的注释矩阵呈现出稀疏性，其中只有少数实例被任何特定的工人对共同标注。因此，注释的稀缺性意味着抽样结果与实际潜在数据分布之间存在显著差异的可能性增加。这个问题会导致工人之间的相似性不准确。另一个问题是，在二分类任务中，很难区分高质量工人和低质量工人。这个问题是由特殊的概率分布引起的，可能会使标签聚合方法将低质量工人视为高质量工人。为了解决这两个问题，我们提出了一种新颖的可解释的标签聚合图神经网络（LAGNN）模型，用于模拟众包注释任务中复杂的各种相关性。图卷积操作能够聚合节点的邻居信息，例如在每次卷积中将邻居节点上的特定值与权重聚合到节点本身。在图上应用一次图卷积操作后，图上的所有节点都能够获得其邻居节点的信息。这些信息被称为一阶邻居信息。通过多次应用图卷积操作，图上的节点可以获得远距离节点的信息。这些信息被称为多阶邻居信息。多阶邻居信息能够表征更深层次的节点相关性。因此，图卷积操作被用来连接和聚合稀疏注释。通过多阶邻居信息，注释可以获得所有注释之间更深层次的相关性，这允许注释从其他注释中获取有用的聚合信息。为了解决第二个问题，我们通过一些相关性改进了标签相似性，例如实例-实例和工人-实例的相关性。仅使用标签信息确保了无论我们是否拥有工人特征（例如年龄、性别和经验），都能够区分出高质量工人。

图卷积网络本身非常强大，但仍存在一些问题。一旦邻接矩阵形成，图的结构就在所有阶段中固定了，例如训练阶段和验证阶段。这阻碍了工人之间关系连接（偏好）的动态调整以适应数据。我们通过考虑工人对不同任务和类别的态度进一步改进了模型。这通过考虑工人-实例和工人-类别的相关性具体呈现。该模型结合了类别-类别的相关性，以解决由于随机抽样中数据有限可能导致的类别不平衡问题。为了适应没有真实标签的注释任务，我们引入了一个简化的无监督（不可知）版本的LAGNN，称为lazy-LAGNN。LAGNN提供了卓越的灵活性，无论有限的真实数据和工人特征的可用性如何。

为了全面评估我们的模型，我们全面评估了LAGNN在监督和无监督（不可知）模式下的性能，这些评估在大量不同数据分布的模拟数据集上进行，这些数据分布由六个自由度控制，同时也在八个真实世界的数据集上进行。模拟数据集可以全面分析模型的适用性。通过涵盖大部分众包任务，它可以评估LAGNN以及lazy-LAGNN在哪些情况下表现良好。真实世界数据集的实验展示了LAGNN在真实众包任务上的客观结果，并支持了合成实验的结果。还包括了数据泄露的实验，以验证LAGNN的有效性。我们还展示了LAGNN的可视化，以确保它能找到高质量的工人，并正确纠正工人的偏好。

本文的其余部分安排如下。第二节介绍了与标签聚合相关的研究工作。第三节描述了标签聚合问题、图卷积网络及其动机的声明。第四节详细介绍了LAGNN的实现，并定义了所声称的相关性。在第五节中，我们提出了关于标签相似性与工人质量之间关系的一般性结论，并展示了LAGNN的可解释性。第六节展示了实验以及分析。第七节包含了一些评论和未来的展望。


# III. 预备知识

首先，我们介绍问题设置。然后，我们介绍图卷积操作，并解释为什么它可以用于标签聚合。最后，我们讨论了在使用图卷积进行相关性建模时的问题（弱点以及我们需要做的事情）。

## A. 问题设置
在众包注释中，数据集可以表示为  $D = \{X, Y, U, L\}$ ，其中  $X = \{x_i\}_ {i \in I}$  是一组  $I$  个实例， $Y = \{y_i\}$  是对应的未知真实标签集， $U = \{u_j\}_ {j \in J}$  是一组  $J$  名工人， $L = \{l_{i,j}\}$  是众包标签矩阵。这里， $l_{i,j}$  表示工人  $u_j$  提供给实例  $x_i$  的标签。每个未知真实标签  $y_i$  属于一个类别集合  $C = \{c_k\}_ {k \in K}$ 。为简单起见，我们可以使用索引来引用对象，比如说工人  $j$  将实例  $i$  标记为类别  $k$ 。此外，每个众包标签  $l_{i,j}$  属于集合  $C \cup \{0\}$ ，其中  $0$  表示工人  $j$  没有给实例  $i$  标记。在本研究中，我们考虑了工人特征（特征，例如年龄和经验，或特定任务的标签）和实例的难度，但没有考虑实例特征（因为我们专注于标签聚合，实例特征很少被考虑）。因此， $u_{j,p}$ ，其中  $p \in P$ ，表示工人  $j$  的第  $p$  个特征。 $D_{i,\text{fi}}$ ，其中  $i \in I$ ，表示实例  $i$  的难度。为实例  $i$  提供标签的工人数量表示为  $|l_i|$ 。

目标是学习一个模型，该模型不仅为训练集中的每个实例分配一个综合标签  $\hat{y}$ ，而且还能为带有众包标签的新实例提供综合标签，并同时最大化  $\text{Pr}(\hat{y} = y)$ 。为了最大限度地利用数据集中的关联，我们的方法求助于图神经网络，其中图卷积是核心操作。此外，这里解释了一些术语。工人的质量指的是他的标注准确性。偏好意味着一个工人对另一个工人的标签采用的比例。

## B. 图卷积用于标签聚合
Kipf 和 Welling [19] 提出了一个模型，计算图滤波的一阶近似，即图卷积网络（GCN）。GCN 将傅里叶变换应用于图结构，以更好地利用图的拓扑空间中的结构属性。这使得 GCN 可以使用节点的特征和边上的权重，在图上为未标记节点提供分类。GCN 的核心操作是图卷积，它可以聚合一阶邻居信息。GCN 中的每个卷积层执行以下计算：

$$
Z = \hat{D}^{-1/2} \hat{A} \hat{D}^{-1/2} M \Theta, (1)
$$

$$
\hat{A} = A + I_J, (2)
$$

$$
\hat{D}_ {n,n} = \sum_{m} \hat{A}_{m,n}. (3)
$$

这里，A 是图的邻接矩阵，I 是单位矩阵， $I_J$  表示这个单位矩阵的秩为 J。由于 A 没有自环，通过添加单位矩阵，节点应该将自己纳入卷积中。这种添加的结果是  $\hat{A}$ 。 $\hat{D}$  是  $\hat{A}$  的度矩阵，M 是输入信号， $\Theta$  是一个滤波器， $m, n \in J$ 。为了与原始文本 [19] 保持一致，(1) 中的图卷积操作可以简单地表示为：

$$
\hat{A} = \hat{D}^{-1/2} \hat{A} \hat{D}^{-1/2} (4)
$$

类似于拉普拉斯矩阵， $\hat{A}$  能够为图上的每个节点聚合一阶邻居信息。这种聚合与线性加权聚合相同。通过滤波器  $\Theta$ ，输入信号 M 可以被转换到一个训练有素的特征空间中，例如分类空间。因此，直观上，GCN 模型可以直接应用于标签聚合，尽管迄今为止还没有这样的研究。这个想法是直接的：图上的每个节点都是一个工人，其特征是他/她提供标签。两个节点之间的边的权重是相应工人之间的相似性。节点和边上的权重形成了邻接矩阵 A。输入信号（ $M \in \mathbb{R}^{J \times K}$ ）属于众包标签 L，并且是独热编码的。GCN 不仅能直接完成每个节点上的缺失众包标签，而且还可以使用滤波器  $\Theta$  将 M 的每一行映射到潜在特征空间。通过在最后一层添加一个简单的线性层，GCN 可以将输入信号 M 映射到分类空间。也就是说，GCN 对每个实例进行分类，给它分配一个综合标签。

## C. 相关性建模的问题
GCN 有能力通过图生成来建模工人之间的相关性，通过卷积操作建模工人和实例之间的相关性，并通过滤波器建模实例之间的相关性。然而，从 (3) 和 (4) 我们可以推导出：

$$
\hat{A}_ {m,n} = \frac{\hat{A}_ {m,n}}{\sqrt{\sum_{m} \hat{A}_ {m,n} \cdot \sum_{n} \hat{A}_{m,n}}}
$$

(5)

第一项的平方根下可以被视为工人 n 对工人 m 的偏好比例。第二项类似。这两项与平方根的乘积，即  $\hat{A}_ {m,n}$ ，可以解释为“采纳彼此观点（注释）的偏好”。 $\hat{A}_{m,n}$  也可以被称为两个工人之间的相对偏好。

这种简单的 GCN 方案在实践中面临三个问题。(1) 一旦在图卷积之前生成了  $\hat{A}$ ，它在训练期间就固定不变了。也就是说，两个工人之间的偏好总是一样的，不会随着环境的变化而变化。(2) 因为  $\hat{A}$  是对称的，它表明两个工人之间的相互偏好是相同的。这与常识不符，因为工人对不同类别有不同的偏见。工人 m 同意工人 n，并不意味着后者同意前者，例如，普通工人信任专家，但专家可能不信任普通工人。(3) 类之间的相关性在这个方案中仍未被覆盖。滤波器  $\Theta$  不能模拟噪声标签张量中类别的分布。

为了解决上述问题，本研究将通过向  $\hat{A}$  添加一个偏好校正矩阵来动态地找到工人和标签之间的最佳关系，并通过将不同隧道中分离的噪声标签与类别数量连接起来，获得类别之间的相关性。

# IV. 提出的方法

我们首先概述我们的模型。然后，我们将详细展示其技术关键点。此外，我们将明确声明如何模拟五种不同的相关性。

## A. LAGNN 的架构

LAGNN 是一个构建在图结构上的深度学习网络，如图 1 所示。输入数据是众包标签 L，输出是预测结果，即相应实例的综合标签。为了形成综合标签，L 首先应该被转换成 one-hot 编码，形成一个张量 $L_{I \times J \times K}$。然后，Lin 的每个切片（即一个 $I \times J$ 矩阵）关于某个类别将被送入卷积层的一个相应通道。在卷积层上总共有 K 个通道，每个通道只接受一个特定类别的 Lin 切片。在每个卷积层上，预先计算的邻接矩阵 A、偏好校正矩阵 W，以及 Lin 切片聚合每个节点（工人）的邻域信息。可以有多个卷积层来动态校正工人之间的相关性。每个通道的输出将通过线性连接层连接起来，以学习类别的分布，并使用 Softmax 函数。Softmax 函数的输出表示一个综合标签。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/d111f6830fa046ba97b4df269809ed31.png" width="70%" /> </div>

## B. 技术细节

如上所述，架构中有四个关键点，即 L 的 one-hot 编码、邻接矩阵 A 的生成、卷积层操作和连接层操作。这里，我们讨论它们的细节。

1) L 的 One-Hot 编码：众包标签 $L_{I \times J}$ 必须被编码为图神经网络的 one-hot 码。对于 L 中的每个元素 l 值 k，它被替换为一个 K 维向量。这个 K 维向量在位置 k 上只有一个 1（其他为 0）。当元素 l 为空（值为 0）时，该向量为 0。因此， $L_{I \times J}$ 将被转换为一个张量 $L_{I \times J \times K}$。

2) 邻接矩阵 A 的生成：为了有效地模拟工人之间的关系，我们使用工人特征、成对工人相似性和实例难度构建一个图。这个图由邻接矩阵 A 表示。由于注释任务中的工人数量不是太大，因此用工人相似性填充邻接矩阵的计算成本是可以接受的。A 的定义如下：

$$
A = \{A_{m,n}|A_{m,n} = s_{m,n}\},
$$

其中 $s_{m,n}$ 是工人 $u_m$ 和 $u_n$ 之间的相似性。注意，该图不允许自环。也就是说，当 m = n 时，我们定义 $A_{m,n} = 0$。

考虑到工人特征由不同类型的数据组成，例如年龄通常是整数，而国籍由序列号表示，这些特征的具体值的范围在一定程度上是不同的。因此，依赖 Lp 距离来量化相似性可能并不公平，由于上述差异。因此，我们使用余弦相似性来度量相似性，如下所示：

$$
s_{\text{cos}}^{m,n} = \frac{u_m \cdot u_n}{|u_m| |u_n|} = \frac{\sum_{p=1}^{P} u_p^m \times u_p^n}{\sqrt{\sum_{p=1}^{P} (u_p^m)^2} \times \sqrt{\sum_{p=1}^{P} (u_p^n)^2}},
$$

然而，在某些情况下（如许多传统的标签聚合研究），工人特征并不可用。可以使用标签相似性代替，如下所示：

$$
s_{\text{lab}}^{m,n} = \frac{\sum_{i=1}^{I} D_{\text{ifi}} \cdot 1(\ell_{i,m} = \ell_{i,n})}{\sum_{i=1}^{I} D_{\text{ifi}} \cdot \phi(\ell_{i,m}, \ell_{i,n})},
$$

其中

$$
D_{\text{ifi}} = \text{STD}(\text{Ent}(L)),
$$

 $\text{STD}(\cdot)$ 是所有实例的难度的 min-max 归一化函数。归一化应用于避免过大的值。[Ent(L)] 是信息熵。它可以估计没有真实标签的实例的相对难度。[|\ell_{k}^i|] 是为实例 i 提供 k 类标签的工人数量。特别是，当分母 (8)（即 $\sum_{i=1}^{I} D_{\text{ifi}} \cdot \phi(\ell_{i,m}, \ell_{i,n})$）为 0 时，我们设置 $s_{\text{lab}}^{m,n}$ 为 0.5。此设置防止了数据非常稀疏时模型失败。0.5 是边缘权重的中间值，不会对图产生偏见。

3) 卷积层操作：卷积层是 LAGNN 的核心。我们在传统的图卷积操作中添加了一个偏好校正权重矩阵 W，使用哈达玛乘积。在第 d 个卷积层上，操作如下：

$$
Z_d^{\text{conv},t} = W_d^{\text{conv},t} \odot \hat{A} \odot H_{d-1}^{\text{conv},t},
$$

$$
H_d^{\text{conv},t} = \sigma_{\text{conv}}(Z_d^{\text{conv},t}),
$$

其中 $\sigma_{\text{conv}}(\cdot)$ 是 Relu 激活函数， $W_{\text{conv}}$ 是偏好校正权重矩阵， $\hat{A}$ 是在 (4) 中定义的图卷积操作， $\odot$ 是哈达玛积，t 是通道的索引。对于每个通道， $W_{\text{conv},l,t}$ 将使用特定类别纠正 $\hat{A}$ 中的偏好。由于 $W_{\text{conv},t} \odot \hat{A}$ 不是神经网络中的经典内积，因此在反向传播中 $W_{\text{conv}}$ 的梯度必须重新定义，如下所示：

$$
\text{Grad}(W_d^{\text{conv},t}) = \delta_d^t \cdot \hat{A} \cdot \text{Diag}(H_{d-1}^{\text{conv},t}),
$$

其中

$$
\delta_d = \frac{\partial \text{Loss}}{\partial Z_d^{\text{conv},t}}.
$$

这里，Loss 是损失函数。在本研究中，我们使用交叉熵损失函数。 $\delta_d^t$ 是 $W_d^{\text{conv},t}$ 的误差。 $H_{d-1}^{\text{conv},t}$ 是一个 J 维向量。 $\text{Diag}(\cdot)$ 是一个对角化函数，它将向量转换为对角矩阵。

4) 连接层操作：连接层连接所有通道以形成最终结果。在卷积部分，输出 $H_{\text{conv}}$ 是带有偏好卷积的 one-hot 码。我们在 $H_{\text{conv}}$ 上添加权重 $W_{\text{cnct}}$ 以聚合在不同通道中分离的数据，并挖掘不同类别之间的联系。连接层的操作如下：

$$
Z_{\text{cnct},t} = H_{\text{Depth}, \text{conv},t} \cdot W_{\text{cnct},t},
$$

$$
O = \sigma_{\text{cnct}}(Z_{\text{cnct}}),
$$

其中 t 是通道的索引，O 是输出， $\sigma_{\text{cnct}}(\cdot)$  是 Softmax 函数， $Z_{\text{cnct}} = [Z_{\text{cnct},1}, . . . , Z_{\text{cnct},t}, . . . , Z_{\text{cnct},K}]$ 。


## C. LAGNN 算法
训练 LAGNN 的步骤伪代码总结在算法 1 中。LAGNN 可以在弱监督和无监督（不可知）模式下运行。在弱监督模式中，只有一小部分真实数据被注入到 D 中。在计算图的原始邻接矩阵 A 时，如果提供了工人的特征（如他们的个人资料），则可以使用公式 (7)，否则，使用公式 (8) 至 (12)。当训练过程停止时，训练集中的每个实例都将被分配一个综合标签。构建 LAGNN 模型后，它可以接受一个新的众包标记实例并直接预测其综合标签。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/f8d36b3d4b274535b593b0e72b58b0e7.png" width="70%" /> </div>


## D. LAGNN 的复杂度
LAGNN 前向传播的复杂度包括两个方面：卷积层和连接层。考虑到对于给定的数据集， $\hat{A}$  是固定的，并且  $\hat{A}$  的计算不涉及 LAGNN 前向传播过程中的时间，因此不将  $\hat{A}$  的预处理包括在复杂度推导中。然后，对于每个卷积层， $\hat{A}$  和  $W_{\text{conv},t}$  都是  $J \times J$  矩阵， $H_{\text{conv},t}$  是  $J \times 1$  并且总共有 K 个通道。然后每个卷积层的时间复杂度是  $T(Z_{\text{conv}}) = O(J \cdot J \cdot K) = O(K \cdot J^2)$ 。每个卷积层的空间复杂度  $S(Z_{\text{conv}}) = O(K \cdot (J \cdot J + J \cdot J + J)) = O(K \cdot J^2)$ 。对于连接层， $H_{\text{conv},t}$  是  $J \times 1$ ， $W_{\text{cnct},t}$  是  $J \times 1$  并且总共有 K 个通道。然后连接层的时间复杂度是  $T(Z_{\text{cnct}}) = O(J \cdot J \cdot K) = O(K \cdot J^2)$ 。连接层的空间复杂度是  $S(Z_{\text{cnct}}) = O(K \cdot (J + J)) = O(K \cdot J)$ 。假设一个 LAGNN 有 D 个卷积层，整个时间复杂度（不包括激活函数）是  $T(\text{LAGNN}) = O(D \cdot K \cdot J^2 + K \cdot J^2) = O((D + 1) \cdot K \cdot J^2)$ 。相应的空间复杂度是  $S(\text{LAGNN}) = O(D \cdot K \cdot J^2 + K \cdot J) = O(D \cdot K \cdot J^2)$ 。

## E. 关于相关性建模的声明

LAGNN 能够很好地建模五种相关性。以下是这五种相关性的详细信息，以及 LAGNN 如何建模它们：

- 实例-实例：这种相关性是通过估计所有实例的难度分布来建模的，该分布是利用信息熵计算得到的。通过 min-max 归一化（见公式 (9) 和 (10)），得到表示所有实例相对分布的分布。

- 工人-工人：这种相关性表示工人的分布。它通过每对工人之间的相似性以及邻接矩阵 A 的生成来固定建模（参见公式 (6)、(7) 和 (8)）。

- 类别-类别：这种相关性代表类别特征（由于实例特征是众包的类别标签）与最终预测的类别之间的映射关系。连接层将每个  $H_{\text{Depth}, \text{conv},t}$  视为第 t 个类别的特征，并像普通分类器一样将信息流从特征空间映射到类别空间。训练完成后， $W_{\text{cnct}}$  包含数据集中类别内部的映射关系。它也可以被理解为类别的相对分布。

- 工人-实例：这种相关性由两部分组成。首先，它涉及工人对不同难度任务的态度。这一方面是通过公式 (8) 中的  $1(\cdot)$  和  $\phi(\cdot)$  隐式建模的。第二部分是工人可能分配给实例的潜在标签。在 LAGNN 中，图表示使用节点信息进行标签，使用边缘信息进行工人相似性。通过图卷积操作，直接建模了工人-实例相关性，并使用  $\hat{A}$  和  $W_{\text{conv}}$  形成了实例的潜在注释。特定  $W_{\text{conv}}$  的训练进一步细化了这种相关性。

- 工人-类别：这种相关性表示工人对某个类别的偏好。通过在不同通道中添加偏好校正权重矩阵  $W_{\text{conv},t}$ ，具有自己偏好的工人将在训练过程中自动建模。

# V. LAGNN的可解释性

## A. 标签相似性与高质量工人
提高标签聚合方法的一个有效途径是发现高质量工人（专家），并更多地采纳他们的意见[21]。为了明确起见，我们直接将一个工人的准确性与他的质量联系起来。这意味着具有高准确性的人是高质量工人。在众包任务中，与来自低质量工人的标签相比，来自高质量工人的标签更有可能是正确的。当涉及到发现高质量工人时，[21]声称专家比非专家更相似。这个结论有助于从工人中区分专家和非专家。在这里，我们扩展了这个结论，并提供了一个推导。

假设：对于任意两个工人m和n，他们的注释正确的概率分别为 $P_m$ 和 $P_n$ 。工人m和n之间的相似性是标签相似性 $s_{\text{lab}, m,n}$ 。为了简化问题，不失一般性，假设实例的难度都设置为1，并且工人倾向于随机选择错误的标签。（这个假设与[21]中的设置相同。）

断言：(1) 不论 $K$ 的值如何， $P_m$ 和 $P_n$ 越接近， $s_{\text{lab}, m,n}$ 就越大。(2) 不论 $K$ 的值如何，当 $P_m$ 和 $P_n$ 同时趋近于1时， $s_{\text{lab}, m,n}$ 收敛于1。(3)  $K$ 的值越大， $P_m$ 和 $P_n$ 的值越小， $s_{\text{lab}, m,n}$ 就越小。

推导：因为实例的难度都设置为1， $s_{\text{lab}, m,n} \cdot \sum_{i=1}^{I} \phi(l_{i,m}, l_{i,n})$ 是一个二项分布。

$$
s_{\text{lab}, m,n} \cdot \sum_{i=1}^{I} \phi(l_{i,m}, l_{i,n}) \sim B(I, P(l_{i,m} = l_{i,n}))
$$

对于任意两个工人m和n，如果两者标记的实例数量 $\sum_{i=1}^{I} \phi(l_{i,m}, l_{i,n})$ 都不为零，则可以替换为 $N_{\text{labeled}}$ 。然后，(19)可以写成：

$$
(s_{\text{lab}, m,n} \cdot N_{\text{labeled}}) \sim B(N_{\text{labeled}}, P(l_{i,m} = l_{i,n}))
$$

根据二项分布，我们可以得到期望值：

$$
E(s_{\text{lab}, m,n} \cdot N_{\text{labeled}}) = N_{\text{labeled}} \cdot P(l_{i,m} = l_{i,n})
$$

然后， $s_{\text{lab}, m,n}$ 的期望值是：

$$
E(s_{\text{lab}, m,n}) = P(l_{i,m} = l_{i,n})
$$

对于一个K类分类问题， $P(l_{i,m} = l_{i,n})$ 可以表示为：

$$
P(l_{i,m} = l_{i,n}) = P(l_{i,m} = l_{i,n} = T) + P(l_{i,m} = l_{i,n} \neq T)
$$

$$
= P_m \cdot P_n + (1 - P_m) \cdot (1 - P_n) / (K - 1)
$$

其中 $P_m \in [0, 1], P_n \in [0, 1], K \geq 2$ ，T代表正确标签。如果且仅当 $P_m = P_n = 1$ 时， $P(l_{i,m} = l_{i,n})$ 在不改变K的情况下取得最大值。 $P(l_{i,m} = l_{i,n})$ 是一个关于 $P_m$ 和 $P_n$ 的鞍函数。K主要影响当 $P_m$ 和 $P_n$ 都趋于零时的部分。这个函数的三维图在图2中绘制。从这个图中，我们可以很容易地得到，固定K时，相似质量的工人可以很容易地用标签相似性聚类。而且，当K变大时，高质量工人比低质量工人更相似。一个更一般的推导，不假设实例难度都是1，显示在附录B中，可在线获取。推导的结果与这里的断言在某种程度上仍然相似。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/5bee174d7d2a4fb0b81d1457aeb687f8.png" width="70%" /> </div>


## B. LAGNN如何有效找到高质量工人
然而，在真实的众包任务中，每对工人很难有共同注释的实例。特别是当标签稀疏时，大多数工人之间的相似性将是不确定的，许多偶然的错误相似性将会建立。例如，两个低质量工人只有一个共同注释的实例，并且他们都用相同的错误标签注释。在这种情况下，标签相似性等于1。对于另一个例子，一群高质量工人没有共同注释的实例。这导致他们之间的标签相似性都是0.5。这是通过相似性提高发现高质量工人难度的一个问题。

还有另一个严重的问题。当K=2时，低质量工人将与高质量工人具有相同的聚类效果。当有一组工人通常错误地注释实例时，他们也可能被视为一组高质量的工人。这使得标签聚合的结果不稳定。

为了解决第一个问题，我们利用图卷积操作来聚合多阶邻居信息。图卷积可以关注整个图而不仅仅是两个节点。通过设置不确定性为某个非零值（零表示节点之间没有边），例如0.5，图卷积可以从其他节点聚合信息以纠正偶然的错误。然后，通过将工人-工人的相关性内置于图中，没有共同注释实例的工人可以通过图中的中间节点连接。

为了解决第二个问题，我们将实例-实例和工人-实例的相关性嵌入到标签相似性生成中。这可以指示工人完成不同难度级别任务的条件。当正确标签多于错误标签时，这两个相关性可以自动区分高质量工人和工人群体。可以理解为，高质量工人有更高的概率正确注释困难的实例。极端情况是错误标签多于正确标签，这种情况没有讨论的价值。这是众包任务的失败。几乎所有现有的方法在这种情况下都会失败。

# VI. 实验

在本节中，我们在模拟数据集和真实世界数据集上对LAGNN进行了评估，并与六种现有方法进行了比较。模拟数据集的实验强调了六个自由度的总体影响。真实世界数据集的实验强调了真实注入比例的影响。此外，还对三个数据集进行了清洗，以验证LAGNN是否受益于数据泄露。LAGNN的源代码和演示可在以下链接获取：https://github.com/fadewind/CrowdGNN。

## A. 比较中的算法
我们与六种精心挑选的最新方法进行了比较：(1) MV：标签聚合的基线。(2) DS [5]：使用混淆矩阵对工人的可靠性进行建模的经典概率模型。(3) GTIC [44]：它使用聚类来捕捉众包标签的分布特征，隐式地建模标签相关性。(4) CrowdLayer [29]：端到端学习模型，它生成概率模型以帮助深度神经网络实现更好的性能。(5) weighted-MV [23]：基于MV的改进监督模型。(6) 多层感知器 (MLP)：可以直接用于聚合标签的基本深度学习模型。所有这六种标签聚合算法以及LAGNN都可以处理多类标签。我们考虑了无监督（不可知）方法，MV是标签聚合的基线。DS是概率模型（如BCC，iBCC，EBCC）中最有代表性的。GTIC通过聚类捕捉众包标签的分布。因此，我们也将其纳入了比较。CrowdLayer是最新的端到端学习模型。将其预模型设置为MLP可以使它直接解决标签聚合问题。因此，我们在CrowdLayer前端添加了一个双层MLP以进行比较。Lazy-LAGNN，LAGNN的无监督版本，以及这四种模型将在每个数据集的测试集上运行以获得综合标签。


由于LAGNN可以是弱监督方法，MLP，作为最经典的深度神经网络，被考虑用于与LAGNN的比较。通过将标签视为实例的特征，MLP可以直接用于聚合标签。Weighted-MV是基于MV的经典监督方法。它应该被包含在比较中。在这里，我们解释了为什么表I中列出的一些方法没有被考虑作为基线。我们没有选择ELICE [17]，因为它只能处理二元分类任务。[25]提出的方法包括一个主动步骤，从专家那里获取特定实例的真实标签。该方法在选择最具价值的实例后，从前面的无监督模型获得综合标签，然后再次请专家进行标记。这个策略与我们实验中采用的隐藏测试[46]非常不同。隐藏测试将已知真相的实例，也称为黄金任务，混合到所有待标记的实例中。工人在不知道黄金任务被混合的情况下对所有实例进行标记。然后，黄金任务可以在一定程度上反映工人的质量。因此，我们没有包括[25]中的模型，因为我们的方法不需要实例选择机制。尽管一些研究[32]认为DS模型也可以在弱监督模式下运行，但它与LAGNN的弱监督模式也不同。在弱监督DS中，所有实例（包括那些带有真实标签的实例）都被计入准确性的计算中，因为它没有训练阶段。本质上，它仍然是无监督模式。LAGNN有一个训练阶段，在这个阶段中，使用少量带有真实标签的实例。然而，最终的准确性是在测试集上针对训练模型进行评估的。因此，在我们的实验中，我们只运行DS的传统无监督模式。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/82360396490f4534b0fa9110e957e89b.png" width="70%" /> </div>
LAGNN设置：为了进行公平的比较，LAGNN的卷积层的深度与MLP中的层数相同（设置为2）。由于工人的特征通常难以获得，我们用标记相似度实现了LAGNN。学习速率设置为1.0，最大历元设置为1000。为了避免从SOTA训练策略中获益，LAGNN模型通过纯SGD算法进行优化，不防止过拟合方法（过拟合方法，如辍学，可以很容易地作为常见的学习模型添加到LAGNN中）。由于MV、DS、GTIC和CrowdLayer都是无监督的方法，所以我们还运行了一个无监督（不可知的）LAGNN版本，名为laly-LAGNN，其权重都设置为1。

## B. 模拟评估
1) 模拟方法：在模拟中，我们假设每个工人j都有一个质量 $Q_j$ ，这等于工人的标注准确性（本节中的Q与第五章中的P具有相同的含义）。Q从高斯分布中提取，如下所示：

$$
Q \sim N(\mu, \sigma^2)
$$

其中 $\mu$ 是工人的平均准确性， $\sigma$ 可以被视为平均准确性的离散程度。在多类场景中，我们假设工人的错误均匀地分布在所有错误的标签上。也就是说，对于工人j和错误的选择类别 $k'$ ，我们有：

$$ 
p_{j,\text{correct}} = Q_j, p_{j,\text{wrong},k'} = \frac{(1 - Q_j)}{K - 1}
$$

因此，对于一个未标记的实例，工人j有 $p_{j,\text{correct}}$ 的概率提供正确的标签。对于错误的标签 $k'$ ，这个工人有 $p_{j,\text{wrong},k}$ 的概率选择它。一旦所有Q值都从高斯分布中提取出来，J个工人的质量分布就形成了。需要注意的是，特定的工人特征，例如年龄、性别和经验，在众包中本质上被用来推断工人质量的分布。然后，遵循高斯分布的Q值可以代表所有工人的标准化质量 $\bar{Q}$ （即， $\bar{Q}_j = \text{Norm}(Q)$ ，其中Norm(·)是归一化函数）。由于重复标注[14]是众包标注任务中常用的方案，每个实例上的重复标签数量由冗余参数ρ控制。总而言之，我们有六个自由度来生成模拟数据集。它们是平均工人质量( $\mu$ )、工人质量方差( $\sigma$ )、类别数量(K)、冗余(ρ)、实例数量(I)和工人数量(J)。为了使刺激更可信和全面，这六个参数应该一个接一个地改变，并在广泛的范围内。

为了全面评估模型，我们创建了大量模拟数据集，这些数据集的不同数据分布由这六个自由度控制。首先，我们为每个自由度选择一个标准值。然后，我们通过单变量变化扩展数据集，即我们一次只改变一个自由度的值。所有六个自由度的选定值显示在表II中。最后，我们总共模拟了60种不同的数据分布。我们让测试实例的数量是训练实例数量的10倍。这个设置与weighted-MV和MLP中的设置相同。值得注意的是，所有方法的准确率都是从测试实例中得出的。训练实例仅被视为监督方法的真实注入。它们不参与准确性度量。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/f5e1725dbf3040b9a915bb90d9a1ad0a.png" width="70%" /> </div>


由于模拟数据集是不确定地创建的，为了抑制随机性的影响，对于每个数据分布，我们创建了10个数据集，并报告了这些10个数据集上方法的平均性能。因此，我们总共有600个模拟数据集。

2) 模拟数据集上的结果：图3显示了模拟数据集上的实验结果。右半部分指示每个数据集上表现最佳（在准确性方面）的模型。尽管每个模型都有机会在某些数据集上展示最佳性能，我们的LAGNN和lazy-LAGNN占据了大部分区域。让我们感到惊讶的是，lazy-LAGNN也像LAGNN一样占据了大部分区域，这意味着LAGNN可以有效地以无监督（不可知）模式运行。当我们深入观察每个子图时，我们发现weighted-MV占据了子图σ（工人质量分布更均匀）的顶部区域的大部分，DS占据了子图ρ（获得更多冗余标签）的顶部区域的大部分。直观地说，这很容易理解。weighted-MV对工人质量的分布很敏感。更均匀的分布将减少weighted-MV工作时的训练错误。然而，DS更容易在更多冗余的情况下寻找最优解，特别是在工人质量高的情况下。LAGNN在多类分类上特别表现出色。lazy-LAGNN和LAGNN占据了子图K（更多类别）的顶部区域的所有区域，并且在ρ的低冗余条件下也表现出色，以及在其他子图上表现出稳定的性能。

图3的左半部分显示了模型在数据集上的平均性能，随着自由度值的变化。毫无疑问，LAGNN和lazy-LAGNN在水平轴上的大多数值下都优于其他模型。值得注意的是，尽管weighted-MV和DS有如上所述的一些最佳性能，这两种方法的大多数曲线都是曲折的，这两种模型甚至可能在某些数据集上失败。这反过来证明了我们模型的鲁棒性，因为LAGNN和lazy-LAGNN的曲线都是平滑和平坦的。这些稳定的曲线，特别是在K、μ和ρ上，归功于相关性建模。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/233317e7d8704b888306fb27532f92d4.png" width="70%" /> </div>


# VI. 实验

在本节中，我们在模拟数据集和真实世界数据集上对LAGNN进行了评估，并与六种现有方法进行了比较。模拟数据集的实验强调了六个自由度的总体影响。真实世界数据集的实验强调了真实注入比例的影响。此外，还对三个数据集进行了清洗，以验证LAGNN是否受益于数据泄露。LAGNN的源代码和演示可在以下链接获取：https://github.com/fadewind/CrowdGNN。

## A. 比较中的算法
我们与六种精心挑选的最新方法进行了比较：(1) MV：标签聚合的基线。(2) DS [5]：使用混淆矩阵对工人的可靠性进行建模的经典概率模型。(3) GTIC [44]：它使用聚类来捕捉众包标签的分布特征，隐式地建模标签相关性。(4) CrowdLayer [29]：端到端学习模型，它生成概率模型以帮助深度神经网络实现更好的性能。(5) weighted-MV [23]：基于MV的改进监督模型。(6) 多层感知器 (MLP)：可以直接用于聚合标签的基本深度学习模型。所有这六种标签聚合算法以及LAGNN都可以处理多类标签。我们考虑了无监督（不可知）方法，MV是标签聚合的基线。DS是概率模型（如BCC，iBCC，EBCC）中最有代表性的。GTIC通过聚类捕捉众包标签的分布。因此，我们也将其纳入了比较。CrowdLayer是最新的端到端学习模型。将其预模型设置为MLP可以使它直接解决标签聚合问题。因此，我们在CrowdLayer前端添加了一个双层MLP以进行比较。Lazy-LAGNN，LAGNN的无监督版本，以及这四种模型将在每个数据集的测试集上运行以获得综合标签。

由于LAGNN可以是弱监督方法，MLP，作为最经典的深度神经网络，被考虑用于与LAGNN的比较。通过将标签视为实例的特征，MLP可以直接用于聚合标签。Weighted-MV是基于MV的经典监督方法。它应该被包含在比较中。在这里，我们解释了为什么表I中列出的一些方法没有被考虑作为基线。我们没有选择ELICE [17]，因为它只能处理二元分类任务。[25]提出的方法包括一个主动步骤，从专家那里获取特定实例的真实标签。该方法在选择最具价值的实例后，从前面的无监督模型获得综合标签，然后再次请专家进行标记。这个策略与我们实验中采用的隐藏测试[46]非常不同。隐藏测试将已知真相的实例，也称为黄金任务，混合到所有待标记的实例中。工人在不知道黄金任务被混合的情况下对所有实例进行标记。然后，黄金任务可以在一定程度上反映工人的质量。因此，我们没有包括[25]中的模型，因为我们的方法不需要实例选择机制。尽管一些研究[32]认为DS模型也可以在弱监督模式下运行，但它与LAGNN的弱监督模式也不同。在弱监督DS中，所有实例（包括那些带有真实标签的实例）都被计入准确性的计算中，因为它没有训练阶段。本质上，它仍然是无监督模式。LAGNN有一个训练阶段，在这个阶段中，使用少量带有真实标签的实例。然而，最终的准确性是在测试集上针对训练模型进行评估的。因此，在我们的实验中，我们只运行DS的传统无监督模式。

## B. 模拟评估
1) 模拟方法：在模拟中，我们假设每个工人j都有一个质量 $Q_j$ ，这等于工人的标注准确性（本节中的Q与第五章中的P具有相同的含义）。Q从高斯分布中提取，如下所示：

$$
Q \sim N(\mu, \sigma^2)
$$

其中 $\mu$ 是工人的平均准确性， $\sigma$ 可以被视为平均准确性的离散程度。在多类场景中，我们假设工人的错误均匀地分布在所有错误的标签上。也就是说，对于工人j和错误的选择类别 $k'$ ，我们有：

$$
p_{j,\text{correct}} = Q_j, p_{j,\text{wrong},k'} = \frac{(1 - Q_j)}{K - 1} 
$$

因此，对于一个未标记的实例，工人j有 $p_{j,\text{correct}}$ 的概率提供正确的标签。对于错误的标签 $k'$ ，这个工人有 $p_{j,\text{wrong},k}$ 的概率选择它。一旦所有Q值都从高斯分布中提取出来，J个工人的质量分布就形成了。需要注意的是，特定的工人特征，例如年龄、性别和经验，在众包中本质上被用来推断工人质量的分布。然后，遵循高斯分布的Q值可以代表所有工人的标准化质量 $\bar{Q}$ （即， $\bar{Q}_j = \text{Norm}(Q)$ ，其中Norm(·)是归一化函数）。由于重复标注[14]是众包标注任务中常用的方案，每个实例上的重复标签数量由冗余参数ρ控制。总而言之，我们有六个自由度来生成模拟数据集。它们是平均工人质量( $\mu$ )、工人质量方差( $\sigma$ )、类别数量(K)、冗余(ρ)、实例数量(I)和工人数量(J)。为了使刺激更可信和全面，这六个参数应该一个接一个地改变，并在广泛的范围内。

为了全面评估模型，我们创建了大量模拟数据集，这些数据集的不同数据分布由这六个自由度控制。首先，我们为每个自由度选择一个标准值。然后，我们通过单变量变化扩展数据集，即我们一次只改变一个自由度的值。所有六个自由度的选定值显示在表II中。最后，我们总共模拟了60种不同的数据分布。我们让测试实例的数量是训练实例数量的10倍。这个设置与weighted-MV和MLP中的设置相同。值得注意的是，所有方法的准确率都是从测试实例中得出的。训练实例仅被视为监督方法的真实注入。它们不参与准确性度量。

由于模拟数据集是不确定地创建的，为了抑制随机性的影响，对于每个数据分布，我们创建了10个数据集，并报告了这些10个数据集上方法的平均性能。因此，我们总共有600个模拟数据集。

2) 模拟数据集上的结果：图3显示了模拟数据集上的实验结果。右半部分指示每个数据集上表现最佳（在准确性方面）的模型。尽管每个模型都有机会在某些数据集上展示最佳性能，我们的LAGNN和lazy-LAGNN占据了大部分区域。让我们感到惊讶的是，lazy-LAGNN也像LAGNN一样占据了大部分区域，这意味着LAGNN可以有效地以无监督（不可知）模式运行。当我们深入观察每个子图时，我们发现weighted-MV占据了子图σ（工人质量分布更均匀）的顶部区域的大部分，DS占据了子图ρ（获得更多冗余标签）的顶部区域的大部分。直观地说，这很容易理解。weighted-MV对工人质量的分布很敏感。更均匀的分布将减少weighted-MV工作时的训练错误。然而，DS更容易在更多冗余的情况下寻找最优解，特别是在工人质量高的情况下。LAGNN在多类分类上特别表现出色。lazy-LAGNN和LAGNN占据了子图K（更多类别）的顶部区域的所有区域，并且在ρ的低冗余条件下也表现出色，以及在其他子图上表现出稳定的性能。

图3的左半部分显示了模型在数据集上的平均性能，随着自由度值的变化。毫无疑问，LAGNN和lazy-LAGNN在水平轴上的大多数值下都优于其他模型。值得注意的是，尽管weighted-MV和DS有如上所述的一些最佳性能，这两种方法的大多数曲线都是曲折的，这两种模型甚至可能在某些数据集上失败。这反过来证明了我们模型的鲁棒性，因为LAGNN和lazy-LAGNN的曲线都是平滑和平坦的。这些稳定的曲线，特别是在K、μ和ρ上，归功于相关性建模。

## C. 在真实世界数据集上的评估

我们使用了八个真实世界众包数据集，这些数据集来自文献[35]中描述的数据收集。这些数据集涵盖了广泛的众包注释任务。CF[16]由Crowd-Flower提供，用于2013年众包规模共享任务挑战。CF包含五个类别，对关于天气的推文进行情感分析。它拥有所有八个数据集中最多的工人。CF是一个典型的标签稀疏数据集，包含大量的工人。SP[28]是一个两类别电影评论情感分析。SP是一个大型稀疏数据集，有27747个注释用于5000个实例。CFamt和SPamt分别是CF和SP在AMT平台上重新收集的版本。[35]重新收集CF和SP，并在AMT平台上进行标注。CFamt和SPamt中的每个实例都接收到近20个判断。这两个数据集是典型的标签密集数据集。MS[30]是基于30秒音乐样本的音乐流派分类任务数据集。参与MS的工人必须在AMT平台上有超过95%的任务接受率。由于此任务的难度较高，所有八个数据集中的平均标注准确率最低。ZCin是关于判断所提供的统一资源标识符（URI）是否与从新文章中提取的实体名称相关数据集。ZCin中的工人都来自印度。ZCus与ZCin类似。ZCus中的工人都来自美国。ZCall没有对工人的上述限制。这三个数据集具有非常高的标注重复率（从相同工人那里获得相同的响应）。ZCall、ZCin和ZCus的标注重复率分别为7.21%、20%和56%。总的来说，这八个真实世界数据集可以从全面的角度评估模型。这里，我们在表III中列出了这八个数据集的具体特征。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/9db58f67465f4ec2b64bfd3edaeb5a39.png" width="70%" /> </div>


为了评估真实注入比例的影响，我们将原始数据集划分为训练集和测试集，比例从2%变化到50%。确切的范围是[0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.3, 0.4, 0.5]。对于每个比例，我们随机抽取5个数据集，并报告这些5个数据集上方法的平均性能。因此，我们总共有360个数据集。通过寻找最优的参数设置，我们报告了比较模型的最佳性能。我们对LAGNN和lazy-LAGNN采用与模拟相同的设置。在真实世界数据集上的比较结果如图4所示。每个模型的具体平均准确率以数值形式在附录A中的表格A1到A8中报告，可在线获取。值得注意的是，所有准确率都是仅从测试实例中得出的，这与模拟数据集的实验一致。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/39ab6ed2b8d2408b826b75bb66d6866b.png" width="70%" /> </div>


当同时检查图3的右半部分和左半部分时，可以明显看出，LAGNN与所有其他模型相比展现出最高的整体性能。CF、CFamt和MS是多类数据集，并且LAGNN以及lazy-LAGNN在这些数据集上占据主导地位。这与模拟结果高度一致。LAGNN在一些二元类别数据集上，如ZCall和ZCus，也有出色的表现。尽管DS在SP和ZCin数据集上具有最高的准确率，LAGNN仍然是第二好的。LAGNN次优的可能原因在附录C中在线获取。此外，大多数模型在所有数据集的综合性能上都不稳定。然而，LAGNN的曲线几乎保持平滑并逐渐上升。这直接证明了我们的LAGNN比其他模型更加稳健，尤其是在稍微的真实注入下。

从在线获取的表格A1到A8中可以进一步观察到一些细节。当我们仅查看MV、GTIC、DS、CrowdLayer和lazy-LAGNN等无监督方法的结果时，可以明显发现lazy-LAGNN在大多数情况下表现最佳。DS在SP和ZCin数据集上的准确率远高于其他方法，包括监督方法。然而，DS在CF和MS数据集上也有极差的表现。回顾lazy-LAGNN，它始终保持着出色的表现。即使lazy-LAGNN不是最好的，它仍然可以是第二好的。面对不同的数据条件，lazy-LAGNN表现出强大的鲁棒性。

LAGNN继承了lazy-LAGNN的优势。它还利用训练集来获得进一步的改进。无论与无监督还是监督方法相比，它在真实世界数据集上展现出高性能，表明LAGNN在大多数数据集上都是最好的。与lazy-LAGNN相比，LAGNN可以通过稍微的真实注入（甚至2%）直接提高准确率。除了准确率，LAGNN还提高了鲁棒性。特别是在在线获取的表格A7中，LAGNN有大约4个百分点的稳定改进。考虑到数据分布，LAGNN和lazy-LAGNN都显示出强大的能力来处理低工人质量条件，正如在线获取的表格A3所证明的。比较在线获取的表格A1–A3与A4–A8，揭示了LAGNN更适合多类任务。这一发现表明，LAGNN从其建模标签相似性和类-类相关性的能力中受益。

与模拟数据集的评估相比，真实世界数据集的实验结果显示LAGNN可以获得更好的性能。LAGNN很少在真实世界数据集上过拟合，而lazy-LAGNN可能在模拟数据集上表现更好。这种现象可能是由不同的数据分布引起的。在模拟数据集中，数据点在特征空间中更均匀地分布。通过弱监督模式，有可能从每个类别的中心采样一些数据点。这将使决策边界变得模糊，甚至可能导致函数退化。然而，真实世界数据集通常正好相反。因此，决策边界可以很容易地通过弱监督策略进行优化，而不会过拟合。

总的来说，来自真实世界数据集的结果表明，LAGNN以及lazy-LAGNN在无监督和弱监督模式下都优于其他六种最先进的模型。同时，极低比例的真实注入可以直接提高LAGNN的综合标签的准确性和鲁棒性。

## D. 数据泄露
为了验证LAGNN是否受益于数据泄露，我们清理了数据集中的重复注释，并使用与真实世界数据集相同的设置重复实验。模拟数据集的平均注释重复率低于0.2%。CF、CFamt和SPamt都是干净的。因此，这些数据集太干净了，无法使用。ZCin和ZCus的注释重复率分别为20%和56%。这两个值太高了，这意味着在清理后这些数据集几乎是新的。因此，我们选择MS、SP和ZCall来完成这个验证。这三个数据集的注释重复率分别为9.43%、9.64%和7.21%。实验结果显示在表IV中。符号+表示LAGNN在数据清理后的准确率更高。符号-则相反。符号+和-后面的具体值是差异值。特别是，0表示LAGNN在数据清理后的准确率相同。

从总体上看，准确率增加和减少的数量本质上是相似的。这可以直接验证LAGNN的优良性能并非由于数据泄露。在细节上，准确率下降主要发生在低采样率区间，例如比例为0.02和0.05。下降大约为1%，这远远低于这三个数据集的注释重复率。因此，准确率的下降不应与数据泄露有关。这些准确率的下降可以解释为低采样率的结果。高采样率区间中准确率的增加可以很好地证实这一解释。更高的采样率意味着更稳定的训练结果。此外，LAGNN在高采样率区间取得了更高的准确率，这意味着良好的性能确实来自于训练而不是数据泄露。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/2dc565e7dc204a2091b225df90e63846.png" width="70%" /> </div>


## E. 不确定性的超参数
在这一部分，我们尝试了三种不同的不确定性值，以比较上面构建图时使用的“0.5”。我们还比较了一个没有相似性的图。我们在所有八个真实世界数据集上进行了这个实验，使用了第VI-C节中相同的样本数据集。应用了监督模式和无监督模式。实验结果显示在表V中。

从上面的结果中，指的是Lazy-LAGNN，可以观察到，与所有八个真实世界数据集上使用0.5不确定性的图相比，没有相似性的图确实有更低的性能。当涉及到其他不确定性值时，不同的不确定性总体上与0.5相比有更低的性能。然而，在某些情况下，其他不确定性值似乎在某些数据集上有更好的性能，例如，1.00在MS上表现最佳，0.25在ZCus上表现最佳。监督模式的结果，也就是虚线下面的结果，也反映了与无监督模式相同的情况。这种现象可能是由数据集的特定分布引起的，这意味着一个数据集可能有最佳的不确定性值来聚合标签。而且，不同的数据集可能与不同的最佳不确定性值相关。然而，总的来说，由于表V中的大多数结果都低于0，选择0.5作为不确定性似乎是一个不错的选择。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/073e950da42f4bd9a2ed51c6a9cb542e.png" width="70%" /> </div>


## F. LAGNN的可视化分析

从第V节我们知道，高质量工人之间的相似性远高于低质量工人。然而，这两组之间清晰的界限在哪里？当高质量工人的数量是所有工人的一半时，这是否是最好的选择？很难设定基调。因此，我们赋予模型的唯一原则是尽可能多地采纳高质量工人的意见。在弱监督模式下，LAGNN将根据输入的信息重新调整工人之间的偏好。

我们在图5中可视化了原始偏好矩阵（ $\hat{A}$ ）、第一层的校正偏好矩阵（ $W^0_{\text{conv}} \circ \hat{A}$ ）和第二层的校正偏好矩阵（ $W^1_{\text{conv}} \circ \hat{A}$ ）。为了使可视化更具代表性，我们选择了二分类任务，并选择了没有共同注释任务的高质量工人（前三名准确的工人）。在图5中，我们分别从数据集ZCin中选择了三个表现最差、中等和最好的工人。工人0到8的准确率分别为{0.20, 0.57, 0.58, 0.71, 0.72, 0.73, 0.87, 0.91, 0.93}。在校正第一层的偏好矩阵后，所有工人表现出对高质量工人更强的偏好。值得注意的是，校正显著增强了高质量工人之间的偏好。在第二层的校正偏好矩阵中，倾向于偏爱高质量工人的倾向变得更加明显。总的来说，LAGNN确实可以纠正偏好，以适应性地采纳更有可能正确注释的信息。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/b3c3976f1d734e8e805a9b56c332e519.png" width="70%" /> </div>



# VII. 结论

在本文中，我们提出了一个新颖的图神经网络模型，即LAGNN，用于学习可以整合众包标签的模型。LAGNN在图卷积操作中重新加权了工人之间的偏好组合以及标签之间的关系，以便它可以模拟众包注释任务中的五种不同关系，并在标签聚合中实现更好的性能。在大量模拟数据集和八个真实世界的众包数据集上的实验结果一致地表明，我们提出的LAGNN及其无监督（不可知）版本lazy-LAGNN通常显著优于其他六种最先进的方法，无论是在弱监督还是无监督模式下。数据泄露的实验也验证了LAGNN的效率。

尽管标签聚合是众包学习中最基本和关键的任务之一，但使用众包标记数据学习预测模型以预测未标记实例也是非


# 声明

本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
