# 题目：[Fast Graph Generation via Spectral Diffusion](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10366850)  
## 通过谱扩散快速图生成
**作者：Tianze Luo; Zhanfeng Mo; Sinno Jialin Pan** 

**代码：** https://github.com/ltz0120/Fast_Graph_Generation_via_Spectral_Diffusion
****
# 摘要
生成图结构数据是一个具有挑战性的问题，需要学习图的潜在分布。已经提出了各种模型，如图VAE、图GAN和图扩散模型，以生成有意义和可靠的图，其中扩散模型已达到最先进的性能。本文认为，在整个图邻接矩阵空间上运行全秩扩散SDE会阻碍扩散模型学习图拓扑生成，因此显著降低生成图数据的质量。为了解决这一限制，我们提出了一种高效且有效的图谱扩散模型（GSDM），它由图谱空间上的低秩扩散SDE驱动。进一步证明我们的谱扩散模型比标准扩散模型具有实质上更强的理论保证。在各种数据集上的广泛实验表明，我们提出的GSDM成为了最先进的模型，表现出显著更高的生成质量和比基线更少的计算消耗。


# 关键词
- 图扩散
- 图生成模型
- 随机微分方程。




## I. 引言


学习生成图结构数据不仅需要了解节点的特征分布，还需要深入理解底层图拓扑，这对于建模各种图实例（如社交网络、分子结构、神经架构、推荐系统等）至关重要。传统的基于似然的图生成模型，例如 GraphGAN、GraphVAE 和 GraphRNN，在图生成任务中表现出强大的能力。一般来说，基于似然的模型旨在学习底层图数据分布的似然函数，借此可以从感兴趣的分布中绘制出具有保留图属性的新样本。然而，大多数基于似然的生成模型在建模图结构的质量或计算负担方面存在局限性。

最近，提出了一系列基于扩散的生成模型，以克服基于似然的模型的局限性。尽管最初是为图像生成建立的，但扩散模型在具有复杂图结构属性的图生成任务中表现出巨大成功。大致而言，扩散是一种数学技术，涉及使用随机微分方程（SDE）通过添加更多噪声将真实数据平滑地转化为纯噪声。扩散模型是一类使用该技术反向生成代表性数据样本的概率生成模型。这些模型通过模拟数据点由于添加噪声逐渐变模糊的过程来学习数据集的底层结构。因此，一个训练良好的扩散模型允许我们通过反向扩散过程恢复原始数据，并逐步从模糊样本中去除噪声。第一个通过 SDE 系统进行的图扩散模型，称为通过 SDE 系统进行图扩散（GDSS），旨在通过反向扩散同时生成节点特征和邻接矩阵。与图像扩散模型类似，在每个扩散步骤中，GDSS 直接向节点特征和邻接矩阵中插入标准高斯噪声。同时，训练了两个独立的神经网络，分别学习节点特征和邻接矩阵的评分函数。


![](https://img-blog.csdnimg.cn/direct/3a2632ca3efe4e3a882eb2819385b4dd.png)



然而，与密集分布的图像数据不同，图邻接矩阵可能高度稀疏，这使得各向同性高斯噪声插入与图结构数据不兼容。在这些情况下，图像上的扩散过程与图邻接矩阵上的扩散过程有显著区别。被全秩高斯噪声破坏的图像在前向扩散的早期和中期阶段表现出可识别的数值模式。然而，被破坏的稀疏图邻接矩阵在几次扩散步骤中退化为具有均匀分布条目的密集矩阵。直观上，标准的全秩各向同性噪声插入的扩散 SDEs 对学习图拓扑和特征表示具有破坏性。

即使是对于密集连接的图，标准的扩散模型在拓扑生成方面也存在问题。与仅局部相关的图像像素不同，邻接矩阵控制着整个图的消息传递模式。因此，各向同性的高斯噪声插入严重扭曲了消息传递模式，盲目地鼓励在稀疏连接的部分进行消息传递，这妨碍了稀疏区域的表示学习。


![](https://img-blog.csdnimg.cn/direct/21caa31b42614bceb5c91a9919d67ae7.png)



为了建立一个对图友好的扩散模型，应该设计一个与图拓扑结构相兼容的适当扩散方案。为此，我们提出了一种图谱扩散模型（Graph Spectral Diffusion Model，GSDM），它在节点特征空间和图谱空间上都由扩散随机微分方程（SDEs）驱动。在每个扩散步骤中，我们的方法不是对整个邻接矩阵进行高斯噪声插入，而是将噪声插入限制在图谱空间，即邻接矩阵的特征值矩阵。这种新颖的扩散方案使我们能够在训练和采样阶段对图数据进行平滑转换。如图2所示，我们提出的GSDM在图生成质量和合理性方面显著优于标准图扩散模型（GDSS [10]）。对于图顶部的Grid数据集，GDSS样本看起来只是混乱的簇，而GSDM样本显示出平滑的类似表面模式，视觉类似于真实数据。对于图底部的Community-small数据集，GDSS在某些样本中未能捕捉到两个社区之间的联系，而GSDM能够捕捉到哑铃状模式（两个簇通过一条边连接）以及蝴蝶状模式（两个簇通过两条边连接）。这意味着GDSS的生成不仅未能模仿观察到的拓扑分布，而且在捕捉数据的挑战性细节（如社区之间的联系）方面也存在困难。相比之下，GSDM能够生成在拓扑上与真实数据相似的高质量图，同时保留关键细节。

- 我们在通用图生成任务上实证评估了我们提出的GSDM的能力，通过评估合成和现实世界图数据集上的生成质量。如第四部分所示，GSDM在各种数据集上优于现有的一次性生成模型，同时与自回归模型相比也具有竞争力。进一步的分子生成实验表明，我们的GSDM优于最先进的基线，证明我们提出的谱扩散模型能够捕捉节点和边之间的复杂依赖关系。我们的主要贡献有三个方面：

- 我们提出了一种新颖的图谱扩散模型（GSDM），用于快速且高质量的图生成。我们的方法通过利用节点特征和图谱空间上的扩散SDEs，克服了现有图扩散模型的限制。通过随机分析的视角，我们证明了GSDM比标准图扩散模型具有更强的性能保证。我们提出的谱扩散将重建误差界限从 $O(n^2 exp(n^2))$减少到 $O(n exp(n))$，其中 $n$是节点数。

我们在合成和现实世界的图生成任务上评估了GSDM。GSDM优于所有现有的图生成模型，并且与现有的图扩散模型相比，也明显提高了计算效率。




## III. 预备知识

在本文中，我们将感兴趣的概率空间表示为 $(Ω, F, P)$， $(F_t)_ {t∈R}$ 是一个过滤，即 $F$ 的递增子 $\sigma$-代数序列。在没有特别说明的情况下，我们将 $(B_t)_ {t∈R}$ 表示为过滤概率空间 $(Ω, F, P, (F_t)_ {t∈R})$ 上的 $d$ 维标准布朗运动。随机变量 $z$ 的分布、支持集和期望分别定义为 law $(z)$、supp $(z)$ 和 $E[z]$。 $y|z$ 表示 $y$ 在条件 $z$ 下的分布。 $Unif(A)$ 表示集合 $A$ 上的均匀分布。 $\| \cdot \|$ 表示标准欧几里得范数。 $\| \cdot \|_ \infty$ 和 $\| \cdot \|_ {\text{lip}}$ 分别表示函数的上确界范数和 Lipschitz 范数。 $[·]$ 表示取整函数。

### A. 基于评分的生成扩散模型

生成模型是指映射 $g_θ: R^d \rightarrow R^d$，将一个简单的已知先验 $π$ 映射到一个复杂的数据分布 $D$。一旦模型 $g_θ$ 在 $D$ 的 $N$ 个独立同分布样本上充分训练，表示为 $S$，它使我们能够通过从 $g_θ(ε), ε ∼ π$ 采样直接生成合理的实例。与将 $D$ 视为 $π$ 的单边变换的传统生成模型（例如 VAE 和 GAN）不同，扩散模型从 SDE 的角度考虑 $D$ 和 $π$ 之间的双边关系。给定一个从 $D$ 到 $π$ 的 SDE，相应的反向时间 SDE 使我们能够从噪声先验追溯到感兴趣的分布。

**引理 III.1（前向扩散和反向时间 SDE [22]）**：

前向扩散是指以下 SDE

$$
z_0 ∼ D, \, dz_t = f(z_t, t)dt + σ_t dB_t, \, t ∈ [0, 1],
$$

其中 $f(·, t): R^d \rightarrow R^d$ 是漂移函数， $σ_t: [0, 1] → R$ 是标量扩散函数。设 $p_t(·)$ 为 $z_t$ 的概率密度函数，则反向时间 SDE 表示为

$$
dz̄_t = (f(z̄_t, t) - σ_t^2 \nabla \log p_t(z̄_t)) dt̄ + σ_t dB̄_t,
$$

其中 $z̄_1 ∼ z_1, \, t ∈ [0, 1], \, dt̄ = -dt$ 是负无穷小时间步长， $(B̄_t)_ {t∈R}$ 是相对于 $(Ω, F, P, (\overline{F_t})_ {t∈R})$ 的反向时间布朗运动， $(\overline{F_t})_{t∈R}$ 是相应的递减过滤， $\nabla \log p_t(·)$ 是评分函数。

在前向扩散过程中，通过精心设计的 $f(·, t)$，原始数据被增加噪声逐渐扰动，假设逐渐被破坏为真正的噪声信号（先验），即 law $(z_1) = π$。为了通过反向时间 SDE 从 $D$ 中提取新数据，需要通过神经网络 $s_θ(·): R^d \rightarrow R^d$ 学习未知的评分函数 $\nabla \log p_t(·)$，通过最小化以下显式评分匹配误差：

$$
E(θ) \, \dot{=} \, E_{z ∼ D} E_{z_t|z} \| s_θ(z_t) - \nabla \log p_t(z_t) \|^2.
$$

在实践中，我们采用高斯先验 $π$。对于每个样本 $z_i ∈ S$，首先通过离散化（1）生成一系列损坏的数据 $\{z_{t_j}^i\}_{j=1}^T$。为了学习评分网络 $s_θ(·)$，可以最小化更易处理的去噪评分匹配目标 $Ê(θ)$

$$
Ê(θ) \, \dot{=} \, E_{z ∼ Unif(S)} E_{z_t|z} \| s_θ(z_t) - \nabla \log p(z_t|z) \|^2,
$$

这已被证明与 $E(θ)$ 在 [23] 中等价。给定一个训练良好的评分网络 $s_θ^*(·)$，可以通过解决学习的反向时间 SDE 从 $π$ 生成合理的数据

$$
dẑ_t = (f(ẑ_t, t) - σ_t^2 s_θ^*(ẑ_t)) dt̄ + σ_t dB̄_t,
$$

其中 $ẑ_1 ∼ π, \, t ∈ [0, 1]$。理想情况下，学习的反向时间 SDE 应该引导我们走向 $D$，即 law $(ẑ_0) = D$。

## IV. 方法

在本节中，我们建立了图谱扩散模型（GSDM），用于快速有效的图数据生成。在第 IV-A 节中，我们简要回顾了标准的基于评分的图扩散模型 [10]。在第 IV-B 节中，我们正式介绍了我们的 GSDM 算法及其 $\alpha$-分位数变体。在第 IV-C 节中，我们提供了理论分析，以证明 GSDM 在图数据生成中的有效性。

#### A. 标准图扩散模型

一个具有 $n$ 个节点的图定义为 $G = (X, A) ∈ R^{n×d} × R^{n×n}$，其中 $X ∈ R^{n×d}$ 是维度为 $d$ 的节点特征矩阵，而 $A ∈ R^{n×n}$ 表示邻接矩阵。图生成模型旨在学习底层数据分布，即 $G ∼ G$，这是 $X$ 和 $A$ 的联合分布。注意，如果将 $(X, A)$ 视为一个整体而忽略内在的图结构，那么上述基于评分的生成框架可以平行地扩展到图生成环境中，从而产生标准图扩散模型，即 GDSS [10]。大致而言，对于每个图样本 $(X, A)$，我们首先通过前向扩散生成一系列扰动图 $\{(X_{t_i}, A_{t_i})\}_{i=1}^T$。然后，我们训练两个评分网络 $s_θ(·)$ 和 $s_φ(·)$ 来学习 $X_t$ 和 $A_t$ 的评分函数，利用这些评分函数，我们可以通过运行反向时间 SDE 从 $π$ 生成新数据。

**定义 1（图扩散 SDEs）**：
前向图扩散指以下 SDE 系统

$$
\begin{cases}
dX_t = f_X(X_t, t)dt + σ_{X,t} dB_{X_t}, \\
dA_t = f_A(A_t, t)dt + σ_{A,t} dB_{A_t},
\end{cases}
$$

其中 $(X_0, A_0) ∼ G, \, t ∈ [0, 1], \, f_X(·, t): R^{n×d} → R^{n×d}$ 和 $f_A(·, t): R^{n×n} → R^{n×n}$ 是节点特征和邻接矩阵的漂移函数； $σ_{X,t}, \, σ_{A,t}$ 是标量扩散项（即噪声调度函数）， $(B_{X_t})_ {t∈R}$ 和 $(B_{A_t})_{t∈R}$ 分别是 $R^{n×d}$ 和 $R^{n×n}$ 上的标准布朗运动。为了减轻计算高维 $G$ 漂移项的负担，前向图扩散的漂移项被解耦为 $f_X(·, t)$ 和 $f_A(·, t)$。同样，引理 III.1 保证了图扩散的反向时间 SDE 的存在。

**推论 1（图扩散的反向时间 SDEs）**：系统（6）的反向时间 SDE 系统为

$$
\begin{cases}
dX̄_t = \left( f_X(X̄_t, t) - σ_{X,t}^2 \nabla_X \log p_t(X̄_t, Ā_t) \right) dt̄ + σ_{X,t} dB̄_{X_t}, \\
dĀ_t = \left( f_A(Ā_t, t) - σ_{A,t}^2 \nabla_A \log p_t(X̄_t, Ā_t) \right) dt̄ + σ_{A,t} dB̄_{A_t},
\end{cases}
$$

其中 $(X̄_1, Ā_1) ∼ π, \, t ∈ [0, 1], \, dt̄ = -dt$ 是负无穷小时间步长， $(B̄_{X_t})_ {t∈R}$ 和 $(B̄_{A_t})_ {t∈R}$ 是由（6）诱导的反向时间标准布朗运动。漂移函数的解耦意味着条件独立性 $X_t ⊥ A_t|G_0$，我们可以将 $p_t(X̄_t, Ā_t)$ 分解为 $p_{t|0}(X_t|X_0) · p_{t|0}(A_t|A_0)$，其中 $p_{t|0}(·)$ 表示 $G_t|G_0$ 的密度函数。

正如 [10] 所提出的，这种条件独立性将去噪评分匹配目标简化为更简单的形式

$$
Ê(θ) \, \dot{=} \, E_G ∼ Unif(S) E_{G_t|G} \| s_θ(G_t) - \nabla \log p_{t|0}(X_t|X_0) \|^2,
$$

$$
Ê(φ) \, \dot{=} \, E_G ∼ Unif(S) E_{G_t|G} \| s_φ(G_t) - \nabla \log p_{t|0}(A_t|A_0) \|^2.
$$

因此，训练和采样过程可以直接借用标准的基于评分的模型。

虽然 GDSS 是在图生成中利用扩散模型的第一次尝试，但其性能受到扩散的暴力应用的限制。对于稀疏连接的图，虽然节点特征的分布在数据集中有所不同，但图拓扑的分布，即邻接矩阵，居住在低维流形中。如第 I 节所述，邻接矩阵的明显模式也意味着 $A$ 的真实分布是低秩的。在这种情况下，评分匹配目标未能提供一致性估计器。尽管在 $A ∈ R^{n×n}$ 上运行全秩扩散通过将受损数据的支持从流形扩展到全空间缓解了这一问题，但它不可避免地引入了致命的噪声到零概率密度区域。因此，支持区域之外的信噪比本质上为零，这对训练去噪评分网络来说是灾难性的。注意，这种全秩扩散对于密集连接的图生成也不合适。这是因为各向同性受损的邻接矩阵鼓励在图的稀疏连接部分进行欺骗性消息传递，这对图消息传递模式具有破坏性。因此，标准扩散会严重损害稀疏图区域的表示学习。

#### B. 图谱扩散模型

为了解决这些臭名昭著但普遍存在的问题，我们提出了一种新颖的图谱扩散模型。对于图拓扑生成，与 GDSS 在整个空间 $R^{n×n}$ 上运行全秩扩散不同，我们的 GSDM 利用 $n$ 维谱流形上的低秩扩散 SDEs，例如 $A$ 的 $n$ 特征值的跨度。正如我们稍后将看到的，GSDM 通过利用图谱结构并在信息集中的流形上运行扩散，实现了稳健性和计算效率。

**定义 2（图谱扩散 SDEs）**：
令 $A$ 的谱分解为 $UΛU^T$，其中 $U$ 的列是正交特征向量， $Λ$ 是对角特征值矩阵，即谱。前向谱扩散指以下 SDE 系统

$$
\begin{cases}
dX_t = f_X(X_t, t)dt + σ_{X,t} dB_{X_t}, \\
dΛ_t = f_Λ(Λ_t, t)dt + σ_{Λ,t} dW_{Λ_t},
\end{cases}
$$

其中 $(X_0, A_0) ∼ G, \, A_0 = U_0 Λ_0 U_0^T, \, t ∈ [0, 1], \, f_X(·, t): R^{n×d} → R^{n×d}$ 是节点特征的漂移； $f_Λ(·, t): R^n → R^n$ 是谱的漂移，仅作用于对角项； $σ_{X,t}, \, σ_{Λ,t}$ 是标量扩散项（即噪声调度函数）， $(B_{X_t})_ {t∈R}$ 和 $(B_{Λ_t})_ {t∈R}$ 是 $R^{n×d}$ 和 $R^n$ 上的标准布朗运动； $W_{Λ_t} \, \dot{=} \, diag(B_{Λ_t})$ 是对角布朗运动。

正如稍后所示， $A_t \, \dot{=} \, U_0 Λ_t U_0^T$ 的演化由 $n$ 维高斯过程驱动。因此，我们防止了受损的邻接矩阵在全空间内肆意横行。

我们现在准备建立反向时间谱扩散 SDEs。

### 反向时间谱扩散 SDEs

**推论 2（反向时间谱扩散 SDEs）**：
系统（10）的反向时间谱扩散 SDE 系统为

$$
\begin{cases}
dX̄_t = \left( f_X(X̄_t, t) - σ_{X,t}^2 \nabla_X \log p_t(X̄_t, Λ̄_t) \right) dt̄ + σ_{X,t} dB̄_{X_t}, \\
dΛ̄_t = \left( f_Λ(Λ̄_t, t) - σ_{Λ,t}^2 \nabla_Λ \log p_t(X̄_t, Λ̄_t) \right) dt̄ + σ_{Λ,t} dW̄_{Λ_t},
\end{cases}
$$

其中 $(X̄_1, Λ̄_1) ∼ π, \, t ∈ [0, 1], \, dt̄ = -dt$ 是负无穷小时间步长； $(B̄_{X_t})_ {t∈R}$ 和 $(B̄_{Λ_t})_ {t∈R}$ 是由（6）诱导的反向时间标准布朗运动， $W̄_{Λ_t} \, \dot{=} \, diag(B̄_{Λ_t})$。由于 $U$ 不再涉及（11），边界条件仅施加在 $(X_1, Λ_1)$ 的联合分布上，使得 law $(X_1, Λ_1) = π$。这一假设意味着可以通过反向时间谱扩散 SDE 从先验 $π$ 恢复真实分布 $(X_0, Λ_0)$。

根据评分匹配技术 [23]，我们可以训练两个评分网络 $s_θ(·, ·, ·)$ 和 $s_φ(·, ·, ·)$ 来学习评分函数 $\nabla_X \log p_t(·, ·)$ 和 $\nabla_Λ \log p_t(·, ·)$，通过最小化以下目标

$$
Ê(θ) \, \dot{=} \, E_G ∼ Unif(S) E_{X_t|G} \| s_θ(X_t, Λ_t, U_0) - \nabla \log p_{t|0}(X_t|X_0) \|^2,
$$

$$
Ê(φ) \, \dot{=} \, E_G ∼ Unif(S) E_{Λ_t|G} \| s_φ(X_t, Λ_t, U_0) - \nabla \log p_{t|0}(Λ_t|Λ_0) \|^2.
$$

简而言之，提出的 GSDM 包括两个主要步骤：

1. 在 $(X, Λ)$ 上运行前向谱扩散模型（10）。训练两个评分网络 $s_θ(·, ·, ·)$ 和 $s_φ(·, ·, ·)$ 学习（11）中出现的评分函数。

2. 从观察到的特征向量矩阵中均匀采样 $Û_0$。通过反向谱扩散 SDE 从 $t = 1$ 到 $t = 0$ 生成合理的 $(X̂_0, Λ̂_0)$，使用估计的评分函数 $s_θ(X̂_t, Λ̂_t, Û_0)$ 和 $s_φ(X̂_t, Λ̂_t, Û_0)$。

由于完整的邻接矩阵未涉及扩散 SDE 的计算，GSDM 在训练和采样中实现了显著的加速。此外，可以通过将谱扩散限制在 $A$ 的最大 $k$ 个特征值来进一步提高计算效率，其中 $k \, \dot{=} \, [αn]$。假设 $Λ_k$ 是截断的特征值矩阵，其中仅保留了 $Λ$ 的前 $k$ 个对角条目，我们可以通过将 GSDM 中出现的 $Λ$ 替换为 $Λ(k)$ 来定义 $\alpha$-分位数 GSDM。正如下一节所见， $\alpha$-分位数 GSDM 展示了显著更快的处理速度和与 GSDM 可比的性能。

训练和采样 GSDM 的伪代码如算法 1 和 2 所述。具体来说，我们首先通过最小化评分匹配误差从真实数据中训练一个 GSDM。在此基础上，我们能够通过反向谱 SDE 生成图特征和图邻接矩阵的特征值。通过从训练集中均匀采样特征向量，我们可以通过谱组合构建合理的图邻接矩阵。


![](https://img-blog.csdnimg.cn/direct/2fe0c4570f0343999d48c83d866fe44f.png)



#### 理论分析

在这里，我们提供支持 GSDM 有效性的理论证据。在命题 1 中，我们首先研究邻接矩阵的谱扩散 SDE 的低秩结构。在命题 2 中，我们进一步证明了我们提出的谱扩散相比于标准图扩散具有更锐利的重建误差界限。

**命题 1（邻接矩阵上的谱扩散 SDEs）**：
假设 $f_Λ(Λ, t) \, \dot{=} \, -σ_{Λ,t}^2/2 Λ$。谱扩散 SDE 系统（10）在整个空间 $R^{n×n}$ 上诱导了一个 $n$ 维的邻接矩阵 SDE 系统。

正如之前的符号所示，前向扩散 SDE 为

$$
\begin{cases}
dX_t = f_X(X_t, t)dt + σ_{X,t} dB_{X_t}, \\
dA_t = -\frac{1}{2} σ_{Λ,t}^2 A_t dt + σ_{Λ,t} dM_t,
\end{cases}
$$

其中 $(M_t)_{t∈[0,1]}$ 是 $R^{n×n}$ 上的 $n$ 维中心高斯过程，均值为零，协方差核 $K(s, t): [0, 1] × [0, 1] → R^{n×n×n×n}$ 为

$$
K(s, t)_ {i,j,k,l} = \min(s, t) \cdot \sum_{h=1}^n U_0[i, h] U_0[j, h] U_0[k, h] U_0[l, h]。
$$

因此， $A_t$ 在 $A_0$ 条件下的条件分布为高斯分布

$$
A_t|A_0 ∼ N \left( A_0 e^{-\frac{1}{2} \int_0^t σ_τ^2 dτ}, \left( 1 - e^{-\int_0^t σ_τ^2 dτ} \right) K(1, 1) \right)。
$$

这一点承认了一个闭式概率密度函数。

**备注 1**：命题 1 显示，我们的谱扩散框架通过用 $n$ 维噪声 $(M_t)_{t∈R}$ 驱动 $n^2$ 维 SDE，从而实质性地重新构造了邻接矩阵的演化。在图谱的指导下，扩散集中于 supp $(A)$ 的显著部分，防止将不可约噪声引入支持区域之外。


![](https://img-blog.csdnimg.cn/direct/022fad29986c46f1a34b6145d196fa9f.png)



图生成的核心问题是如何衡量从噪声中恢复的合成数据的质量，其学习评分函数。这个问题的关键是建立重建误差界限，即用真实评分 $\nabla \log p_t(·)$ 和学习评分 $s_φ(·)$ 重建的数据之间的期望误差。对于图拓扑生成，我们的 GSDM 被证明比标准图扩散享有更锐利的重建界限。详细证明可见第 V-B 节。

**命题 2（邻接矩阵生成的重建界限）**：
遵循之前的符号，我们将标准和谱图扩散模型的估计反向时间 SDE 定义为

$$
d\hat{A}_ {\text{full},t} = \left( -\frac{1}{2} σ_t^2 \hat{A}_ {\text{full},t} - σ_t^2 s_φ(\hat{A}_ {\text{full},t}, t) \right) dt̄ + σ_t d\bar{B}_{A_t}，
$$

$$
d\hat{A}_ {\text{spec},t} = \left( -\frac{1}{2} σ_t^2 \hat{A}_ {\text{spec},t} - σ_t^2 s_φ(\hat{A}_{\text{spec},t}, t) \right) dt̄ + σ_t d\bar{M}_t，
$$

两种生成方法共享相同的漂移项和噪声调度 $(σ_t)_ {t∈[0,1]}$。我们进一步假设 $\| s_φ(·, t) \|_ {\text{lip}} = O(E_{|A_0} \| \nabla_A \log p_t|0(\hat{A}_ {\text{full},t}) \|_ {\text{lip}})$ 和 $\| s_φ(·, t) \|_ {\text{lip}} = O(E_{|A_0} \| \nabla_A \log p_t|0(\hat{A}_ {\text{spec},t}) \|_ {\text{lip}})$ 几乎必然成立。通过从 $t = 1$ 到 $t = 0$ 反向这两个 SDE，我们得到 $\hat{A}_ {\text{full},0}$ 和 $\hat{A}_{\text{spec},0}$，它们是真实 $A_0$ 的两个重建，其期望重建误差界限为

$$
E \| A_0 - \hat{A}_{\text{full},0} \|^2 \le M E(φ) \cdot \left( 1 + n^2 K \int_0^1 Σ_t^{-2} \exp \left( n^2 K \int_t^1 Σ_s^{-2} ds \right) dt \right)，
$$

$$
E \| A_0 - \hat{A}_{\text{spec},0} \|^2 \le M E(φ) \cdot \left( 1 + n K \int_0^1 Σ_t^{-2} \exp \left( n K \int_t^1 Σ_s^{-2} ds \right) dt \right)，
$$

其中 $M \dot{=} C^2 \| σ_{·} \|^4_{∞}; \, K \dot{=} 2ML/E \| A_0 \|^2_{2,2}; \, C, L$ 是绝对常数； $Σ_t^2 \dot{=} 1 - e^{-\int_0^t σ_s^2 ds}; \, E(·)$ 是定义在（3）中的期望评分匹配目标。

**备注 2**：尽管 $\hat{A}_ {\text{full},0}$ 的误差界限在 $O(n^2 \exp(n^2))$ 量级， $\hat{A}_{\text{spec},0}$ 表现出 $O(n \exp(n))$ 量级的更锐利界限。



**定义 3（ $\beta$-光滑）**： $f: R^m \rightarrow R^n$ 称为 $\beta$-光滑当且仅当

$$
\| f(x_1) - f(x_2) - \nabla f(x_2) (x_1 - x_2) \| \le \frac{β}{2} \| x_1 - x_2 \|^2
$$

对于 $∀ x_1, x_2 ∈ R^m$ 成立。

**命题 3（评分匹配目标最小化的收敛性）**：回想一下，通用样本 $Z ∈ R^d ( \hat{A}_ {\text{full}} \text{ 或 } \hat{A}_{\text{spec}})$ 的评分匹配目标定义为

$$
E(θ; Z) \dot{=} E_{Z_t|Z} \| s_θ(Z_t, t) - \nabla_Z \log p_t(Z_t) \|^2,
$$

期望和经验评分匹配误差定义为

$$
E(θ) \dot{=} E_Z∼D E(θ; Z),
$$

$$
Ê(θ; S_N) \dot{=} E_Z∼S_N E(θ; Z),
$$

其中 $D$ 是 $Z$ 的总体分布， $S \dot{=} \{Z_i\}_{i=1}^N$ 是大小为 $N$ 的 i.i.d 采样训练数据集的均匀分布。假设 $E(θ)$ 是通过在训练数据上运行标准随机梯度下降（SGD）最小化的，即在第 $k$ 次迭代时， $θ_k$ 在大小为 $b$ 的小批量上更新

$$
θ_{k+1} \dot{=} θ_k - η ∇θ Ê(θ; S_b)。
$$

假设几乎必然地（相对于 $Z$）， $E(·; Z)$ 是 $\beta$-光滑的，且 $s_θ(·)$ 的切线核 $K_θ(S) ∈ R^{Nd×Nd}$ 满足

$$
λ_{\min} (K_θ(S)) \ge λ > 0, \, θ ∈ B(θ_0, R),
$$

$$
K_θ(S)[N i + 1 : N(i + 1), N j + 1 : N(j + 1)] \dot{=} \nabla_θ s_θ(Z^i)^T \nabla_θ s_θ(Z^j),
$$

其中 $R = 2N \sqrt{2β E(θ_0)/(μδ)}, δ > 0$。那么，对于小批量 $S_b$ 的选择，以 $1 - δ$ 的概率，学习率 $η \dot{=} λ/N (Nβ(N^2β + λ(b - 1)/N))$ 的 SGD 以指数收敛率收敛到球 $B(θ_0, R)$ 中的全局解

$$
E(θ_k) \le \left( 1 - \frac{λ b η}{N} \right)^k E(θ_0)。
$$

## V. 详细证明

### A. 命题 1 的证明

证明：将 $A_t = U_0 Λ_t U_0^T$ 代入（12）得到

$$
dA_t = - \frac{1}{2} σ_{Λ,t}^2 A_t dt + σ_{Λ,t} dM_t，
$$

$M_t \dot{=} U_0 W_{Λ,t} U_0^T = U_0 \cdot \text{diag}(B_{Λ,t}) \cdot U_0^T$。
由于 $(M_t)_ {t∈R}$ 是 $(B_{Λ,t})_ {t∈R}$ 的线性变换， $R^n$ 上的标准布朗运动，因此 $(M_t)_{t∈R}$ 是 $R^{n×n}$ 中的秩- $n$ 中心高斯过程。此外， $M_t$ 的协方差核 $K(s, t): [0, 1] × [0, 1] → R^{n×n×n×n}$ 定义为

$$
K(s, t)_ {i,j,k,l} = \text{Cov}(M_s[i, j], M_t[k, l]) = \mathbb{E}[M_s[i, j] M_t[k, l]]
= \mathbb{E} \left( \sum_{h=1}^n U_0[i, h] B_{Λ,s}[h] U_0[j, h] \right)
\cdot \left( \sum_{h=1}^n U_0[k, h] B_{Λ,t}[h] U_0[l, h] \right)
= \sum_{h=1}^n \mathbb{E}(B_{Λ,s}[h] B_{Λ,t}[h]) U_0[i, h] U_0[j, h] U_0[k, h] U_0[l, h]
= \min(s, t) \sum_{h=1}^n U_0[i, h] U_0[j, h] U_0[k, h] U_0[l, h]。
$$

注意到（10）是一个 Ornstein–Uhlenbeck 过程，承认闭式解

$$
Λ_t = Λ_0 e^{-\frac{1}{2} \int_0^t σ_τ^2 dτ} + (1 - e^{-\int_0^t σ_τ^2 dτ}) W_{Λ,1}。
$$

因此，将（19）代入 $A_t = U_0 Λ_t U_0^T$ 得到

$$
A_t = A_0 e^{-\frac{1}{2} \int_0^t σ_τ^2 dτ} + (1 - e^{-\int_0^t σ_τ^2 dτ}) M_1。
$$

证明完毕。 $\square$


![](https://img-blog.csdnimg.cn/direct/33ad589ff4c0468fad311c375b9bbd7b.png)


![](https://img-blog.csdnimg.cn/direct/aa9f24e6d22a47969352955b8b5a48b2.png)



### B. 命题 2 的证明

为主证明做准备，我们首先建立一些技术引理。

**引理 V.1（通用扩散的重建界限）：**
我们首先考虑 $(R^d, \| \cdot \|)$ 上的以下 Oracle 反向时间 SDE

$$
d\bar{Z}_t = (f(\bar{Z}_t, t) - σ_t^2 \nabla_Z \log p_t(\bar{Z}_t)) dt̄ + σ_t d\bar{B}_t, \, t ∈ [0, 1]，
$$

并定义相应的估计反向时间 SDE 为

$$
d\hat{Z}_t = (f(\hat{Z}_t, t) - σ_t^2 s_φ(\hat{Z}_t, t)) dt̄ + σ_t d\bar{B}_t, \, t ∈ [0, t]，
$$

其中 $s_φ(·)$ 通过最小化评分匹配目标来优化，以预测 Stein 评分函数 $\nabla_Z \log p_t(Z_t)$

$$
\min_φ E(φ) \dot{=} \mathbb{E}_ Z \mathbb{E}_{Z_t|Z} \| s_φ(Z_t, t) - \nabla_Z \log p_t(Z_t) \|^2。
$$

对于任何 $φ$，构建误差界限为

$$
\mathbb{E} \| Z_0 - \hat{Z}_ 0 \|^2 \leq C^2 \| σ_· \|^4_{∞} E(φ)
\cdot \left( 1 + \int_1^0 F(t) \exp \left( \int_1^t F(s) ds \right) dt \right)，
$$

其中 $F(t) \dot{=} C^2 σ_t^4 \| s_φ(·, t) \|^2_{\text{lip}} + C \| f(·, t) \|^2_{\text{lip}}$， $C$ 是一个常数。

命题 2 的证明：命题 2 的假设暗示

$$
\| f(·, t) \|_{\text{lip}} = \frac{1}{2} σ_t^2，
$$

$$
\| s_φ(·, t) \|_ {\text{lip}} \leq L \cdot \mathbb{E}_ {|A_0} \| \nabla \log p_t|0(\hat{A}_ {\text{full},t}) \|_{\text{lip}}，
$$

$$
\| s_φ(·, t) \|_ {\text{lip}} \leq L \cdot \mathbb{E}_ {|A_0} \| \nabla \log p_t|0(\hat{A}_ {\text{spec},t}) \|_{\text{lip}}，
$$

其中 $L$ 是一个常数。根据 [11], [13]，在每个时间步 $t ∈ [0, 1]$，Oracle 条件评分函数 $\nabla \log p_t|0(·)$ 等效于将输入 $d$ 维随机变量 $Z_t$ 映射到 $Σ_t^{-1} ε$ 的映射。所出现的 $ε$ 是 $d$ 维标准高斯向量，与 $Z_t$ 独立， $Σ_t$ 是 $Z_t$ 的标准差，定义为 $Σ_t \dot{=} (1 - e^{-\int_0^t σ_s^2 ds})^{1/2}$。因此，Oracle 条件评分函数的期望 Lipschitz 范数界限为

$$
\left( \mathbb{E}_ {|A_0} \| \nabla \log p_t|0(Z_t) \|_ {\text{lip}} \right)^2 \leq \mathbb{E}_ {|A_0} \| \nabla \log p_t|0(Z_t) \|^2_{\text{lip}}
= Σ_t^{-2} \mathbb{E} \| Z_0 \|^2 \mathbb{E} \| ε \|^2 = Σ_t^{-2} d \| Z_0 \|^2。
$$

利用引理 V.1，我们只需要将（22）代入（21），通过将符号 $(Z, d, \| \cdot \|)$ 替换为 $(\hat{A}_ {\text{full},t}, n^2, \| \cdot \|_ {2,2})$ 和 $(Λ_{t,\text{spec}}, n, \| \cdot \|_{2,2})$ 来限制评分网络的 Lipschitz 范数。这引导我们到

$$
\mathbb{E} \| A_0 - \hat{A}_{\text{full},0} \|^2
\leq M E(φ) \cdot \left( 1 + n^2 K \int_1^0 Σ_t^{-2} \exp \left( n^2 K \int_1^t Σ_s^{-2} ds \right) dt \right)，
$$

$$
\mathbb{E} \| Λ_0 - Λ_{t,\text{spec}} \|^2
\leq M E(φ) \cdot \left( 1 + n K \int_1^0 Σ_t^{-2} \exp \left( n K \int_1^t Σ_s^{-2} ds \right) dt \right)，
$$

其中 $M \dot{=} C^2 \| σ_· \|^4_{∞}$ 和 $K \dot{=} 2ML / \mathbb{E} \| A_0 \|_{2,2}^2$。对于谱扩散部分，最后的证明步骤通过以下事实完成

$$
\mathbb{E} \| A_0 - \hat{A}_ {\text{spec},0} \|^2 = \mathbb{E} \| U_0 (Λ_0 - Λ_{t,\text{spec}}) U_0^T \|^2 = \mathbb{E} \| Λ_0 - Λ_{t,\text{spec}} \|^2，
$$

$$
\mathbb{E} \| A_0 \|_ {2,2}^2 = \mathbb{E} \| U_0 Λ_0 U_0^T \|_ {2,2}^2 = \mathbb{E} \| Λ_0 \|_{2,2}^2。
$$

证明完毕。 $\square$

### C. 命题 3 的证明

证明：由于 $E(θ) = E_{S ∼ D^N} Ê(θ; S_N)$，我们只需要约束经验风险 $Ê(θ; S_N)$。根据假设，记作

$$
h \dot{=} \left( \begin{array}{c}
s_θ(Z_0^1) - \nabla \log p(Z_0^1|Z_1^1) \\
... \\
s_θ(Z_0^N) - \nabla \log p(Z_0^N|Z_1^N)
\end{array} \right) ∈ R^{Nd×1}，
$$

满足

$$
\| \nabla_θ Ê(θ; S_N) \|^2 = \frac{1}{N^2} h^T K_θ(S) h \geq \frac{λ}{N^2} \| h \|^2 = \frac{λ}{N} Ê(θ; S_N)，
$$

这意味着 $Ê(θ; S_N)$ 满足 $\frac{λ}{N}$-Polyak Łojasiewicz 条件 [24]。然后通过将定理 7 应用于 $Ê(·; S_N)$ 完成证明。 $\square$

## VI. 实验

在本节中，我们在几种基准数据集上评估我们提出的 GSDM 与最先进的图生成基线的表现，涵盖通用图生成和分子生成任务。我们还进行了广泛的消融研究和可视化，以进一步说明 GSDM 的有效性和效率。

### A. 通用图生成

**数据集：** 我们在三个不同规模的通用数据集上测试我们的模型，并用 $N$ 表示节点数：
1. Community-small (12 ≤ $N$ ≤ 20)：包含 100 个小社区图。
2. Enzymes (10 ≤ $N$ ≤ 125)：包含 578 个蛋白质图，表示 BRENDA 数据库中酶的三级结构。
3. Grid (100 ≤ $N$ ≤ 400)：包含 100 个标准的二维网格图。为了公平比较我们的模型与基线，我们采用 [9] 中的实验和评估设置，并使用相同的训练/测试拆分。

**基线：** 我们将我们的模型与知名或最先进的图生成方法进行比较，这些方法可分为自回归模型和一次性模型。自回归模型是指序列生成，通过一系列连续步骤构建图，通常是节点逐个和边逐个生成 [14]。在此类别中，我们包括 DeepGMG [25]、GraphRNN [9]、GraphAF [4] 和 GraphDF [26]。一次性模型是指构建一个概率图模型，可以一次性生成所有节点和边 [14]。在此类别中，我们包括 GraphVAE [8]、Graph Normalizing Flow (GNF) [27]、EDP-GNN [12] 和 GDSS [10]。除了图生成方法外，我们还将来自计算机视觉领域的两种最先进的基于扩散的生成方法纳入图生成任务：SubspaceDiff [17] 和 WSGM [18]。这些方法的实现细节在附录中详细阐述，在线可用。

**指标：** 我们采用最大平均差异（MMD）来比较相同数量的生成图和测试图之间的图统计分布，例如度、聚类系数和 4 节点轨道的出现次数 [9]，[10]。

**结果：** 我们在表 I 中展示了结果。结果表明，我们提出的 GSDM 显著优于自回归基线和一次性基线方法。具体来说，GDSS 是最先进的图扩散模型，在整个图数据空间执行扩散。我们的方法在平均表现和收敛率（图 3）方面大大优于 GDSS，这证明了在图的谱中执行 SDEs 相对于整个空间的优势。

### B. 分子生成

除了通用图生成外，我们的模型还可以通过我们提出的反向扩散过程生成有机分子。我们使用两个知名的分子数据集测试我们的模型：QM9 [29] 和 ZINC250K [30]。遵循以往的工作 [10]，[26]，分子通过 RDKit 库 [31] 去氢化处理。我们评估了 10,000 个生成分子的质量，使用 Frechet ChemNet Distance (FCD)、Neighborhood subgraph pairwise distance kernel (NSPDK) MMD、有效性（无需修正）和生成时间。FCD 计算测试集和生成分子之间的距离，使用 ChemNet 倒数第二层的激活。NSPDK MMD 计算生成集和测试集之间的 MMD，考虑节点和边特征进行评估。一般来说，FCD 从化学空间的角度衡量生成质量，而 NSPDK MMD 从图结构的角度评估生成质量。此外，遵循 [10]，我们还包括无需修正的有效性作为另一个指标，以明确评估分子生成的质量，而无需修正程序。它计算在生成分子总数中无需价键修正或边重采样的有效分子的比例。有效性测量在修正阶段后的有效分子的比例。生成时间测量生成 10,000 个分子的时间（以秒为单位），这是衡量分子生成实用性的显著指标，尤其是大分子生成。

**基线：** 我们将我们的模型与最先进的分子生成模型进行比较。基线包括最先进的自回归模型：GraphAF [4] 是一个基于流的模型，GraphDF [26] 是一个使用离散潜变量的基于流的模型。遵循 GDSS [10]，我们修改了 GraphAF 和 GraphDF 的架构，以考虑分子生成中的形式电荷，分别表示为 GraphAF+FC 和 GraphDF+FC，以便公平比较。对于一次性模型，我们包括 MoFlow [3]，这是一个基于流的模型；EDP-GNN [12] 和 GDSS [12] 均为扩散模型。

**结果：** 我们在表 II 中展示了结果。显然，GSDM 在大多数指标下表现出最高性能。NSPDK 和 FCD 中的最高分数表明 GSDM 能够生成在化学空间和图空间中数据分布接近真实分子的分子。特别是，我们的模型在大多数指标上优于 GDSS，验证了我们提出的谱扩散不仅适用于通用图生成，还适用于分子设计。

**分子生成的可视化：** 除了图 2 中的生成图可视化外，生成分子的可视化如图 4 所示。在图中，我们展示了与某些训练分子最大相似的生成分子。我们使用基于 Morgan 指纹的 Tanimoto 相似度计算分子相似度，这是基于 RDKit [31] 实现的。更高的 Tanimoto 分数表明模型能够生成与训练集更相似的分子，这反映了模型的学习能力。正如图中所示，与 GDSS 模型相比，GSDM 能够生成分布与训练集分子更相似的分子。

**时间复杂度：** 与其他扩散模型（例如 EDP-GNN 和 GDSS）相比，我们的 GSDM 的主要优势之一是生成分子的效率。我们展示了生成 10,000 个分子所需的时间（以秒为单位），如表 II 所示，表明我们的 GSDM 在推理过程中所需时间显著低于 EDP-GNN 和 GDSS。特别是，与 GDSS 生成 10,000 个分子图所需的 1.06e3 和 2.11e3 秒相比，我们的模型分别仅需 18.02 和 45.91 秒，分别快 58 倍和 46 倍。这一现象验证了我们在设计谱扩散方法论上的合理性，不仅谱扩散比整个空间扩散更有效，而且更高效。这种改进对于药物设计和材料分析等许多应用至关重要。


![](https://img-blog.csdnimg.cn/direct/f87462e7486c426e9cf925767de53082.png)


![](https://img-blog.csdnimg.cn/direct/65d0f35358b64eac811a9c64488c80af.png)


![](https://img-blog.csdnimg.cn/direct/7c2c0aa08a524a409dcbf68e875829f7.png)


### C. 消融研究

**扩散步骤数的消融研究：** 为了分析我们提出的 GSDM 在重建过程（即反向扩散过程）中的鲁棒性，我们在 Community small 数据集上比较了我们模型与 GDSS 在不同扩散步骤数上的表现。正如图 5 所示，我们的模型在不同扩散步骤数上始终优于 GDSS。

**谱空间维度的消融研究：** 我们还进行了谱空间维度的消融研究。具体来说，我们评估了我们提出的 GSDM 在谱扩散过程中使用不同数量的特征值（前 $k$ 个特征值）时的性能。表 III 中的结果表明，GSDM 的生成性能随着考虑的特征值数量的增加而提高。


![](https://img-blog.csdnimg.cn/direct/ed07cdc5f5ff4f2097902aab8c654f1c.png)


![](https://img-blog.csdnimg.cn/direct/2f816987c8a1404b962ba8330d50eec6.png)


![](https://img-blog.csdnimg.cn/direct/f43279da4be249d2b2b48938683bab92.png)


## VII. 结论

在本文中，我们提出了一种新颖的图谱扩散模型（GSDM），通过在谱域中执行扩散有效且高效地生成图。关于通用图生成和分子生成的广泛实验表明，GSDM 在生成质量和计算效率方面达到了最先进的性能。此外，理论分析提供了为什么谱扩散优于整个空间扩散的见解。我们相信，我们的工作为设计基于扩散的图结构数据生成模型提供了新的视角，可能会激发未来在这一方向上的研究。
声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
