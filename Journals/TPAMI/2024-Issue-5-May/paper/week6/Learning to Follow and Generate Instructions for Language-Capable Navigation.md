# 题目：[Learning to Follow and Generate Instructions for Language-Capable Navigation](https://ieeexplore.ieee.org/document/10359152/)  
## 学习遵循和生成语言导航指令
**作者：基于视频标签的弱监督Tracklet关联学习用于人的重新识别** 

**源码链接：** https://github.com/wxh1996/LANA-VLN
****
# 摘要

视觉-语言导航（VLN）是一项具有挑战性的任务，它要求具身智能体依据自然语言指令在之前未曾见过的环境中进行导航。然而，现有文献主要强调将指令解释为动作，仅提供了“哑巴”寻路智能体，这些智能体不能主动使用自然语言与人类交流。在本文中，我们设计了一个名为LANA的语言型导航智能体，它不仅能执行人类编写的导航命令，还能向人类提供路线描述。这是通过单一模型同时学习指令跟随和生成来实现的。更具体地说，构建了两个编码器，分别用于路线和语言编码，并由两个解码器共享，分别用于动作预测和指令生成，以利用跨任务知识和捕获任务特定的特征。在预训练和微调过程中，指令跟随和生成都作为优化目标。我们进一步通过在路线编码过程中利用对象语义扩展了LANA，从而形成了LANA+，这是一个更强大的框架，它模拟了人类通过地标来组合指令和寻路的方式。我们通过实证验证了，与最近的高级任务特定解决方案相比，LANA在指令跟随和生成两方面都取得了更好的性能，复杂度几乎减半。此外，由于具备语言生成能力，LANA可以向人类解释其行为并协助人类的寻路。得益于地标信息，LANA+展现出了更加令人印象深刻的性能。这项工作预计将促进未来构建更可靠、更具社会智能的导航机器人的努力。

# 关键词

多任务学习，视觉-语言导航，视觉-语言预训练

# 引言

在人工智能领域，开发能够使用自然语言与人类交流的同时感知并采取行动的智能体是一个基本目标。作为向此目标迈出的一小步，视觉-语言导航（VLN）——赋予智能体执行自然语言导航命令的能力——最近受到了显著关注。在VLN领域，已经进行了许多关于语言基础——教授智能体如何将人类指令与感知相关的动作关联起来的工作。然而，关于相反方向——语言生成——即教授智能体如何生动地描述导航路线的工作却鲜有报道。实际上，这两项任务都非常重要，并且具有明确的实际应用价值。前者——语言诱导的寻路（也称为指令跟随）——是开发通用具身智能体的基本技能，而后者——基于地面的路线描述——允许机器人智能体向人类提供直观的反馈，并使用自然语言有效地指导人类完成目标。更关键的是，现有的VLN文献分别训练了专门针对每项单一任务的智能体。结果，交付的智能体要么是强大的寻路者但从不交谈，要么是健谈的路线指导者但从不行走。

本文强调了VLN中的一个基本挑战：我们能否学习一个单一的智能体，它既能跟随导航指令，又能创建路线描述？我们提出了LANA，一个语言型导航智能体，它充分意识到这样的挑战（见图1）。通过同时学习指令基础和生成，LANA在统一框架中将人对人和人对机器人的通信，使用面向导航的自然语言传达。装备VLN智能体的指令生成能力非常重要，因为：i) 它提升了VLN智能体的实际应用价值——随着导航智能体在寻路方面变得更加擅长，它们可以向人类提供建议、提醒和指令，而不仅仅是服从。例如，当一个智能体执行导航命令花费了很长时间，在此期间持续的人类注意力是不可行和不可取的，智能体应该报告其进度。同样，智能体预计会在智能体探索过的区域内指导人类[10]，这与灾难区域的搜索和救援机器人[11]、[12]、公共空间的引导机器人[6]以及视力障碍人群的辅助导航设备[13]有关。ii) 它完成了人与智能体之间必要的通信循环。作为紧密的人-机器人协调[14]的重要组成部分，双向通信可以增强人类对机器人的信任[15]、[16]（即，机器人可以告诉人类“我将继续这样走……”），从而增加导航机器人在社会环境中的接受度。iii) 发展语言生成技能可以制造出更易于解释的机器人，它们可以以人类可读的路线描述的形式解释它们的导航行为。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/01cbfc1acd7c43d4af055280445b4739.png#pic_ center" width="70%" />
</div>

技术上，LANA构建为基于Transformer的多任务学习框架。它由两个单模态编码器组成，分别用于语言和路线编码，以及两个多模态解码器，分别用于路线到指令和指令到路线的双向翻译，基于这两个编码器。整个网络在指令基础和生成任务上通过端到端学习，在预训练和微调阶段。所有这些结合起来，LANA提供了一个统一而强大的框架，它在模型设计和网络训练的核心探索了任务特定和跨任务知识。因此，LANA可以更好地理解语言线索（例如，单词、短语和句子）、视觉感知、长期动作及其关系，即使在没有显式监督的情况下，最终有利于这两项任务。

先前的认知研究[17]、[18]、[19]、[20]已经证实，地标在人类的路线学习中扮演着至关重要的角色。首先，当地标作为信标和指导时，人类可以制定更好的导航策略。其次，地标作为环境中显眼的物体，作为可靠和稳定的联想线索，连接人类知识系统和不断变化的环境，并为人类提供信息丰富的参考点，以传达足够的路线描述。这些发现激励我们进一步设计了LANA+，这是LANA的一个增强版本，它具备在线收集地标语义的能力，以实现更有效的寻路和更丰富的指令创建。LANA+利用大规模预训练的视觉-语言模型CLIP[21]，通过视觉全景观察查询文本地标语义标签列表，并选择排名最高的检索文本线索作为显著地标的表示。这种在线目标发现机制使LANA+能够在导航期间高效地发现显著地标，并对其周围环境获得细粒度的理解。尽管一些语言诱导的导航器[22]、[23]、[24]、[25]和指令生成器[10]也利用了地标上下文，但它们要么依赖于目标检测器进行全面的目标发现[10]、[22]、[23]，这耗时，或者需要大量的手动地标注释[24]，这需要巨大的劳动成本。此外，它们都没有在联合学习指令跟随和生成的背景下研究地标。

总之，我们的主要贡献如下：1）我们是第一个强调在VLN领域开发语言型交互式导航智能体的重要性，并指出了朝这个方向努力的可行方法，通过同时学习指令跟随和生成任务，而无需承担额外的注释负担。2）我们提出了LANA，这是第一个语言型导航智能体，它成功地通过单一模型实例掌握了指令跟随和生成，无需在不同模型之间切换。这是通过集成网络架构设计的联合任务学习框架实现的，其中两个单模态编码器用于路线和语言编码，由两个多模态解码器共享，用于路线和指令之间的双向翻译。3）我们引入了LANA+，这是LANA的一个增强版本，它增加了一个基于预训练视觉-语言模型的在线地标发现机制，以高效地发现新物体，其视觉语义被视为地标上下文，并被路线编码器用来更策略性地跟随指令和更精确地描述路线。4）我们通过多样化的评估指标和广泛的用户研究，实证证明了LANA及其变体LANA+与最近的特定任务的最新竞争对手相比，性能相当甚至更好，复杂度和模型尺寸都有所减少。我们的实验结果还证实了我们的算法在跨任务相关性建模和参数效率方面的优势。5）我们展示了LANA可以通过口头描述其导航动作来向人类解释其行为。它基本上可以被视为一个可解释的VLN机器人，配备了一个自适应训练的语言解释器。因此，我们的工作为通过教智能体创建人类可读的导航报告，促进人类与寻路代理的信任和协作，指明了一个有希望的发展方向。

我们对三个著名的VLN数据集（即R2R[2]、R4R[26]、REVERIE[27]）进行了广泛的实验，证明了LANA和LANA+在指令跟随和生成两方面的优越性能。例如，LANA+在每项任务上都设定了最新水平（指令跟随提高2%，在指令生成上提高5%；见第IV-B节和IV-C节），验证了我们的想法的力量和智能体的多功能性。与专门针对任务变体的智能体相比，LANA和LANA+通过联合任务训练实现了更好的性能和更有效的参数利用（例如，LANA在指令跟随上提高了2.1%，在指令生成上提高了1.3%，并减少了35%的参数；见第IV-D节）。这表明我们的智能体确实可以挖掘并受益于跨任务知识。此外，我们的主观分析揭示了我们的语言学输出质量优于基线，但仍然落后于人类生成的话语（见第IV-B节）。此外，通过对测试时寻路和报告生成的彻底视觉研究（见第IV-E节），我们展示了LANA/LANA+能够通过缩小包含细粒度障碍物和方向信息的有信息量的指令句子，提供及时的解释。我们智能体创建的报告甚至可以帮助揭示它们固有的决策模式，并洞察它们的奇怪行为。虽然仍有很大的改进空间，但我们的结果为未来VLN研究的有希望的方向提供了启示，对于可解释的导航代理和机器人应用具有巨大的潜力。

这项工作是我们之前会议论文[1]的扩展，有几项重大改进。首先，我们引入了一个外部地标发现策略，允许我们的智能体利用细粒度对象信息来跟随和创建指令（第III-A5节）。其次，我们更准确地阐述了构建语言型导航智能体的重要性，以及更好地总结了我们的动机和贡献（第I节）。第三，我们提供了更全面的文献综述，以更好地将我们的工作置于现有研究的背景下（第II节）。第四，我们更详细地描述了我们的算法（第III节），例如阐述了网络架构设计（第III-A节）、联合任务学习协议（第III-B节）和实现细节（第III-C节），并展示了我们的预训练过程的伪代码（算法1）。第五，我们进行了更多的实验来证明我们算法的有效性，包括将其与最近的VLN智能体进行比较（第IV-B节）以及评估其创建的指令在指导寻路智能体方面质量（表VIII）。第六，为了更完整和深入的分析，我们在第II-C节对我们的模型设计进行了额外的诊断研究。最后，我们展示了更多代表性成功和失败案例的视觉结果（第IV-E节），以说明我们算法的有效性并验证导航报告提供的可解释性。

# III. 方法论

任务设置：我们的目标是构建一个能够同时掌握指令跟随和生成任务的语言型导航代理，仅使用单一的模型实例。具体来说：

- 指令跟随：代理需要找到一个到达目标位置的路径  $R = \{r_ t\}_ {t=1}^T$  ，遵循人类编写的指令  $X = \{x_ l\}_ {l=1}^L$  。在每一步  $t$  ，代理会获得一个全景 RGB 感知  $O_ t$  。
- 指令生成：代理观察一个导航路径  $R = \{r_ t\}_ {t=1}^T$  ，即一系列动作  $\{a_ t\}_ {t=1}^T$  以及全景感知  $\{O_ t\}_ {t=1}^T$  ，并必须用自然语言明确描述路径  $R$  。

方法概述：为了解决这一具有挑战性的场景，我们设计了一个基于 Transformer 的多任务视觉-语言导航 (VLN) 代理 LANA，它利用指令跟随和生成之间的共同点，通过架构设计（第三节 A）和网络训练（第三节 B）来实现。在 LANA 的基础上，我们进一步提出了 LANA+，它额外整合了对象级上下文，以促进这两项任务（第三节 A5）。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/1c42c8b411a8405cbe76fa9de17fcad8.png#pic_ center" width="70%" />
</div>

## A. 模型架构

LANA 能够将导航路径  $R = \{r_ t\}_ {t=1}^T$  作为输入并输出相应的指令  $X = \{x_ l\}_ {l=1}^L$  ，反之亦然。为了实现导航路径  $R$  和指令  $X$  之间的双向翻译，并探索任务间的相关性，LANA 精心设计为以下组合：

- **路由编码器 $E_ r$** 和 **语言编码器  $E_ l$**，用于基于自注意力的单模态表示编码；
- **语言解码器 $D_ l$** 和 **路由解码器  $D_ r$**，用于基于交叉注意力的路径-语言双向翻译。

具体来说，两个单模态编码器（即  $E_ r$  和  $E_ l$ ）在两个多模态解码器（即  $D_ r$  和  $D_ l$ ）之间共享并共同训练。它们合作完成两个任务：

- **指令跟随**：在导航步骤  $t$  时，LANA 分别将整个指令  $X$  和历史路径状态序列  $\{r_ 1, \ldots, r_ {t-1}\}$  以及当前感知  $O_ t$  输入到相应的编码器，并使用路由解码器  $D_ r$  预测下一个导航动作  $a_ t$ 。
- **指令生成**：在生成步骤  $l$  时，LANA 分别将完整路径  $R$  和之前预测的词汇  $\{x_ 1, \ldots, x_ {l-1}\}$  输入到相应的编码器，并采用语言解码器  $D_ l$  预测下一个词汇  $x_ l$ 。

我们指出，LANA 以自回归方式执行指令生成任务。这样，两个解码器都受限于两个编码器的条件，导致广泛的视觉和语言知识交换。

1.**路由编码器**：路由编码器  $E_ r$  的输入可以是整个路径  $R = \{r_ t\}_ {t=1}^T = \{(O_ t, a_ t)\}_ {t=1}^T$ （在指令生成期间）；或者是历史路径状态和当前观察结果  $\{r_ 1, \ldots, r_ {t-1}, O_ t\} = \{O_ 1, a_ 1, \ldots, O_ {t-1}, a_ {t-1}, O_ t\}$ （在路径寻找期间）。因此，它有两种类型的输入标记，分别对应全景观察  $O_ t$  和动作  $a_ t$ 。特别是，观察标记  $O_ t$  的计算方式为：

$$
O_ t = [o_ {t,1}, o_ {t,2}, \ldots, o_ {t,K}] \in R^{K \times d}, \quad o_ {t,k} = F_ v(v_ {t,k}) + F_ \theta(\theta_ {t,k}) + \tau_ t + \tau_ O \in R^d,
$$

其中  $v_ {t,k}$  和  $\theta_ {t,k}$  分别是视图  $o_ {t,k}$  的视觉和方向嵌入； $F_ v/\theta$  是用于特征维度对齐的线性投影； $\tau_ t \in R^d$  嵌入时间顺序 -  $t$ ； $\tau_ O \in R^d$  是一个可学习的类型嵌入，表明  $o_ {t,k}$  是一个观察标记。更具体地说，我们遵循 [95]、[96] 使用预训练的 CLIP [21] 图像编码器来获取视图  $o_ {t,k}$  的视觉嵌入  $v_ {t,k}$ ：

$$
v_ {t,k} = F_ {CLIP_ {\text{img}}}(o_ {t,k}) \in R^d,
$$

其中  $F_ {CLIP_ {\text{img}}}$  是预训练 CLIP 的图像编码器。视图  $o_ {t,k}$  的方向嵌入  $\theta_ {t,k}$  定义为：

$$
\theta_ {t,k} = (\cos \phi_ k, \sin \phi_ k, \cos \phi_ k, \sin \phi_ k),
$$

其中  $\phi$  和  $\phi$  分别是头部和仰角的角度。

类似地，动作标记  $a_ t$  给定为：

$$
a_ t = F_ v(v_ {t,at}) + F_ \theta(\theta_ {t,at}) + \tau_ t + \tau_ A \in R^d,
$$

其中  $v_ {t,at}$  和  $\theta_ {t,at}$  分别嵌入与动作  $a_ t$  相关联的视觉视图和转向角度。与（1）类似， $\tau_ A \in R^d$  编码动作标记类型。

将每个全景感知  $O_ t$  的  $K$  个子视图  $\{o_ {t,k}\}_ k$  标记化，允许 LANA 访问/记忆沿着导航路径的所有观察结果。不幸的是，考虑如此多的标记会导致自注意力编码的计算负载不可承受。为了在计算成本和表示能力之间追求良好的平衡，我们首先计算一个动作注意力路由状态：

$$
r_ t = a_ t + c_ t \in R^d, 
c_ t = \text{cross-att}(a_ t, O_ t) = \text{cross-att}(a_ t, [o_ {t,k}]_ {k=1}^K) \in R^d.
$$

通过交叉注意力，即  $cross_att(\cdot, \cdot)$ ，与动作相关的视觉上下文  $c_ t$  被收集并压缩成一个  $d$  维向量。然后通过自注意力获得  $E_ r$  的输出：

$$
\text{Ins. following: } [\bar{r}_ {1:t-1}, \bar{O}_ t] = self_(att)([r_ {1:t-1}, O_ t]) \in R^{(t-1+K) \times d},
$$
 
$$
\text{Ins. generation: } [\bar{r}_ {1:T}] = self_(att)([r_ {1:T}]) \in R^{T \times d}.
$$

2.**语言编码器**：语言编码器  $E_ l$  的输入可以是完整的指令，即  $X = \{x_ l\}_ {l=1}^L$ （在路径寻找期间）；或者是之前生成的词汇，即  $\{x_ 1, \ldots, x_ {l-1}\}$ （在指令生成期间）。它被构建为一个标准的 Transformer 语言编码器，用于上下文化的语言特征提取：

$$
\text{Ins. following: } [\bar{x}_ {1:L}] = E_ l([x_ {1:L}]) \in R^{L \times d},
$$
 
$$
\text{Ins. generation: } [\bar{x}_ {1:l-1}] = E_ l([x_ {1:l-1}]) \in R^{(l-1) \times d},
$$

其中  $E_ l$  包含多个块，每个块都有一个多头自注意力层和一个前馈子层 [97]；为了简洁起见，省略了位置嵌入。

我们注意到，在指令生成任务的训练期间，每个自注意力层都应用了因果未来掩码 [98]，确保每个词汇标记只能关注之前的标记，并允许我们的单一模型同时处理指令跟随和生成。

3.**路由解码器**：路由解码器  $D_ r$  用于指令到路径的翻译。具体来说，在导航步骤  $t$  时， $D_ r$  输入完整的指令嵌入  $\bar{x}_ {1:L}$ 、历史路径状态  $\bar{r}_ {1:t-1}$  以及当前观察特征  $\bar{O}_ t = \bar{o}_ {t,1:K}$ ，并输出当前  $K$  个子视图  $o_ {t,1:K}^1$  上动作选择的概率分布  $p_ t \in \Delta^K$ 。更具体地说， $D_ r$  被构建为几个基于交叉注意力的块的堆栈，用于建模跨模态关系。对于每个块，我们有：

$$
[\hat{r}_ {1:t-1}, \hat{o}_ {t,1:K}] = cross_att([\bar{r}_ {1:t-1}, \bar{o}_ {t,1:K}], \bar{x}_ {1:L}),$$

$$
[\bar{r}_ {1:t-1}, \bar{o}_ {t,1:K}] \leftarrow self_att([\hat{r}_ {1:t-1}, \hat{o}_ {t,1:K}]).
$$

公式（7）通过交叉注意力获得语言增强的路径和观察表示，即  $\hat{r}_ {1:t-1}$  和  $\hat{o}_ {t,1:K}$ ；公式（8）采用自注意力来模拟历史路径状态  $\hat{r}_ {1:t-1}$  之间的时间依赖性，并捕获  $\hat{r}_ {1:t-1}$  和当前观察  $\hat{O}_ t = \hat{o}_ {t,1:K}$  之间的相关性。

经过几个  $D_ r$  解码器块后，子视图  $o_ {t,1:K}^1$  上的动作概率由下式给出：

$$
p_ t = \text{softmax}(\{F_ r(\bar{o}_ {k})\}_ {k=1}^K) \in \Delta^K,
$$

其中  $F_ r : R^d \rightarrow R$  是用于动作分数映射的双层前馈网络，如文献 [42]、[52] 中所述。

4.**语言解码器**：语言解码器  $D_ l$  用于路径到指令的翻译。具体来说，在指令生成步骤  $l$  时， $D_ l$  输入完整的路径状态  $\bar{r}_ {1:T}$  和之前生成指令词的嵌入  $\bar{x}_ {1:l-1}$ ，并输出在预定义词汇表中  $M$  个单词上选择单词的概率分布  $q_ l \in \Delta^M$ 。与  $D_ r$  类似， $D_ l$  也有几个基于交叉注意力的块。每个块给定为：

$$
\hat{x}_ {1:l-1} = cross_att(\bar{x}_ {1:l-1}, \bar{r}_ {1:T}),
$$
 
$$
\bar{x}_ {1:l-1} \leftarrow causal_self_att(\hat{x}_ {1:l-1}).
$$

公式（10）允许文本关注路径上下文。在（11）中，我们采用因果掩蔽的自注意力，而不是正常的双向自注意力，以强制  $D_ l$  “向前关注”，这是自回归推理所需的。

经过几个  $D_ l$  解码器块后，词汇表上  $M$  个单词的概率由下式给出：

$$
q_ l = \text{softmax}(F_ l(\bar{x}_ {l-1})) \in \Delta^M,
$$

其中  $F_ l : R^d \rightarrow R^M$  是用于预测单词分数分布的双层前馈网络。

5.**地标识别**：人类空间认知的一个广泛接受的观点是，我们人类经常依赖显著的地标来找到我们的路和描述去哪里 [17]、[18]、[19]、[20]。这启发我们为我们的代理补充了利用对象级上下文以促进指令跟随和创建的能力，从而产生了一个更强大的变体，即 LANA+。具体来说，我们提出了一个在线地标识别机制，它使用粗略的视觉表示搜索预存储的地标语义标签列表，并额外地将激活度最高的地标语义合并到路径编码过程中。如图 2 所示，地标识别机制被注入到路由编码器  $E_ r$  中，允许 LANA+ 有效地识别和收集地标上下文，以进行在线导航决策和路径描述。

人类指令通常包括显著的地标（例如：桌子、电视）、动作（例如：走、退出）、方向（例如：前方、后面），其中地标通常是名词（而动作和方向通常对应动词和形容词）。我们使用 spaCy [99] 解析训练集中的所有导航指令句子，并收集所有解析出的名词到一个文本列表  $W = \{ noun_word_ n \}_ n^N$  中。然后我们采用预训练的 CLIP [21] 将这些地标标签映射到视觉-语言语义嵌入空间（图 3）：

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/8e967749f3c04da0994e8c8043ff6ce6.png#pic_ center" width="70%" />
</div>

$$
W = [w_ 1, w_ 2, \ldots, w_ N] \in R^{N \times d}, \quad w_ n = F_ {CLIP_ {\text{text}}}(noun_word_n) \in R^d,
$$

其中  $F_ {CLIP_ {\text{text}}}$  是 CLIP 文本编码器， $noun_ word_n$  是第  $n$  个地标标签。注意，地标语义的特征库  $W$  仅在离线时构建一次，并且可以在训练和测试中重复使用。

回想一下，CLIP 图像编码器  $F_ {CLIP_ {\text{img}}}$  被采用来提取每个视图  $o_ {t,k}$  的粗略视觉表示  $v_ {t,k} \in R^d$  ，缺少细粒度的地标信息。接下来，我们使用全局视觉特征  $v_ {t,k}$  在 CLIP 的良好对齐的视觉-语言嵌入空间中查询预存储的地标特征库  $W$  。具体来说，检索是基于  $v_ {t,k}$  与  $W$  中存储的每个地标项  $w_ n$  之间的余弦相似性得分进行的：

$$
s_ {n t,k} = \frac{v_ {t,k} w_ n^\top}{\|v_ {t,k}\| \|w_ n\|} \in [0, 1].
$$

对于每个  $v_ {t,k}$  ，从  $W$  中检索到的前三个最高相似度得分的地标特征被 max-pooling 生成一个紧凑的向量，即  $f_ {t,k} \in R^d$  ，作为  $v_ {t,k}$  的地标上下文的表示。通过这种方式，我们重用了全局视觉特征（从 CLIP 图像编码器  $F_ {CLIP_ {\text{img}}}$  提取）和预存储的地标语义特征  $W$  （由 CLIP 文本编码器  $F_ {CLIP_ {\text{text}}}$  计算）进行地标上下文检索，这比使用外部对象检测器进行地标检测 [10]、[22]、[23] 更加高效和优雅。

与 LANA 相比，LANA+ 在路由编码中同时考虑了全局视觉特征  $v_ {t,k}$  和地标上下文  $f_ {t,k}$  。与（1）不同，LANA+ 中  $v_ {t,k}$  的视图标记计算为：

$$
o_ {t,k} = F_ v([ v_ {t,k}; f_ {t,k} ]) + F_ \theta(\theta_ {t,k}) + \tau_ t + \tau_ O \in R^d.
$$

与（3）不同，LANA+ 中  $a_ t$  的动作标记计算为：

$$
a_ t = F_ v([ v_ {t,k}; f_ {t,k} ]) + F_ \theta(\theta_ {t,at}) + \tau_ t + \tau_ A \in R^d.
$$

因此，LANA+ 明确地利用了大规模多模态 CLIP 模型进行高效有效的地标上下文挖掘，并自然地将地标上下文纳入路由编码，以促进动作预测和指令创建。在第 IV 节中，我们将通过实验展示，借助我们的地标识别机制，LANA+ 在这两项任务上都取得了更好的性能。

## B. 网络训练

所有 LANA/LANA+ 的模块，包括两个单模态编码器  $E_ r$  和  $E_ l$ ，以及两个多模态解码器  $D_ r$  和  $D_ l$ ，通过同时优化指令跟随和生成的训练目标来进行端到端的联合学习。

**指令生成**：对于每对指令-路径训练样本  $(X, R)$ ，其中  $X = x_ 1:L$  和  $R = r_ 1:T$ ，LANA/LANA+ 通过基于完整路径  $R$  和之前的参考词汇  $x_ 0:l-1$  来学习指令生成，预测词汇  $x_ l$ 。我们为  $X$  添加两个特殊标记，即  $x_ 0 = [BOS]$  和  $x_ {L+1} = [EOS]$ ，分别表示指令句子的开始和结束。为了生成词汇  $x_ l$ ，LANA/LANA+ 分别将  $R$  和  $x_ 0:l-1$  输入到  $E_ r$  和  $E_ l$  进行单模态编码（参见公式（5）和（6））。在路径和语言嵌入的条件下，即  $\bar{r}_ {1:T}$  和  $\bar{x}_ {1:l-1}$ ， $D_ l$  提供下一个词  $x_ l$  的概率  $q_ l$ （参见公式（12））。指令生成的训练目标，以语言模型损失的形式表述，可以写成：

$$
L_ g = -\sum_ {l=1}^{L+1} \log(p(x_ l | x_ 0:l-1, R)) = -\sum_ {l=1}^{L+1} \log(q_ l(x_ l)),
$$

其中  $q_ l(x_ l) \in [0, 1]$  是词汇  $x_ l$  的概率。LANA/LANA+ 以行为克隆的方式进行训练，即最小化专家指令词汇  $x_ 1:L$  的负对数似然。这里使用教师强制策略 [100] 以允许并行文本输入。值得一提的是，现有的 VLN 预训练方法 [51]、[52]、[54]、[55] 依赖于掩蔽语言建模（MLM）策略。由于 MLM 每次训练迭代只预测输入词汇的一小部分（通常为 15%），因此对于大规模预训练数据不够高效，正如最近的许多文献在一般视觉-语言预训练中所指出的 [101]、[102]、[103]。

**指令跟随**：对于每对训练样本  $(X, R)$ ，其中  $X = x_ 1:L$  和  $R = r_ 1:T = (O_ t, a_ t)_ {t=1}^T$ ，LANA/LANA+ 同时学习指令跟随，基于完整指令  $X$ 、专家演示的历史  $r_ 1:t-1$  以及当前感知  $O_ t$  来预测  $a_ t$ 。具体来说，LANA/LANA+ 分别将  $X$  和  $\{r_ 1:t-1, O_ t\}$  输入到  $E_ l$  和  $E_ r$ （参见公式（5）和（6））。在输出的单模态编码的条件下，即  $\bar{x}_ {1:L}$  和  $[\bar{r}_ {1:t-1}, \bar{O}_ t]$ ， $D_ r$  提供动作概率  $p_ t$ （参见公式（9））。指令跟随的训练目标是最小化目标视图动作  $a_ t$  的负对数似然：

$$
L_ f = -\sum_ {t=1}^T \log(p(a_ t | r_ 0:t-1, O_ t, X)) = -\sum_ {t=1}^T \log(pt(a_ t)).
$$

LANA/LANA+ 在预训练和微调阶段都使用两个训练目标（参见公式（17）和（18））进行端到端学习。注意，编码器  $E_ r$  和  $E_ l$  从指令生成（参见公式（17））和跟随（参见公式（18））两个训练目标中接收监督信号。此外，这种联合学习框架赋予了 LANA 改进的可解释性 - LANA/LANA+ 可以被视为一个天生具有语言解释器  $D_ l$  的导航器。

## C. 实现细节

网络架构：LANA 由两个单模态编码器构成，即  $E_ r$ （第 III-A1 节）和  $E_ l$ （第 III-A2 节），以及两个多模态解码器，即  $D_ r$ （第 III-A3 节）和  $D_ l$ （第 III-A4 节）。路由  $E_ r$  和语言  $E_ l$  编码器分别有一层和九层，解码器  $D_ r$  和  $D_ l$  都有四个块。特征维度设置为  $d=768$ 。在 LANA 的基础上，LANA+ 采用了一个更强大的路由编码器，该编码器通过我们的地标识别机制（第 III-A5 节）得到了增强。在近期基于地图的 VLN 代理 [42]、[43]、[44]、[45] 的成就基础上，我们通过基于拓扑图的环境表示来增强 LANA+ 的路由编码器。最初，代理对环境图一无所知，从累积观察中发展其地图。在  $t$  步导航后，观察到的地图包括三种类型的节点：已访问的、可导航的和当前节点。全景视图与已访问和当前节点相关联，而可导航节点从已访问的地点部分可见。随着每一步导航操作，地图都会整合当前节点及其未探索的邻居。当前节点在每一步提供图像和对象特征，然后由多层 Transformer 处理，以辨别空间关系。这些特征一旦编码，就会刷新节点的视觉表示。对于指令跟随，拓扑图在导航期间动态更新，如 [43] 中所述。对于指令生成，拓扑图一次从完整观察的路径构建，并且在指令创建期间保持不变。

训练：按照最近的 VLN 实践 [51]、[52]、[53]、[54]、[55]，我们采用预训练和微调协议：

- 预训练：首先在来自 PREVALENT [54] 的离线采样指令-路径对上预训练 LANA/LANA+，包括 104 K 个原始 R2R 样本和 6482 K 个合成样本。除了指令生成 (IG; 参见公式（17）) 和指令跟随 (IF; 参见公式（18）) 的两个训练目标外，我们还按照之前的努力 [52] 采用了一个指令轨迹匹配 (ITM) 任务，该任务强制代理预测指令和轨迹对是否对齐。三个任务以 IG : IF : ITM = 4 : 1 : 2 的比例采样。更具体地说，LANA/LANA+ 训练了 100 K 次迭代，使用 Adam 优化器 [104]，学习率为 1e-4，批量大小为 N=128。我们在算法 1 中提供了预训练过程的伪代码（为简单起见省略了 ITM）。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/ad2047dfe9c54c2694291b346a8be589.png#pic_ center" width="70%" />
</div>

- 微调：然后我们在不同的 VLN 数据集上仅使用 IG 和 IF 训练任务对 LANA/LANA+ 进行微调（采样比例设置为 IG : IF = 2 : 5；放弃了 ITM 任务）。按照常见做法 [6]、[33]、[48]、[105]，指令跟随的训练基于模仿学习 (IL) 和强化学习 (RL) 的混合。IL 利用（18）中的相同损失，而 RL 基于异步优势演员-评论家 (A3C) 算法 [106] 实现。在这个阶段，我们将学习率设置为 1e-5，批量大小为 8。我们使用 Adam 优化器 [104] 对模型进行 20 K 次迭代的微调。对于 REVERIE [27]，如 [48]、[51]、[52] 中所述，我们将对象特征与全景特征连接起来，并为面向对象引用的导航添加了对象定位损失。

我们使用四块 NVIDIA Tesla A100 GPU 进行训练，并且每个小批量只采样一个训练任务。

推理：一旦训练完成，LANA/LANA+ 能够使用单一模型实例执行跟随和口头表述导航指令，无需任何架构更改。具体来说，对于指令跟随，采用贪婪搜索，即在每个预测步骤选择概率最高的动作，并在选择了 STOP 时终止。对于指令生成，句子是以自回归方式预测的，即一次生成一个词，直到选择了 EOS，条件是之前生成的词。

# IV. 实验

## A. 实验设置和结果总结

由于我们的 LANA 和 LANA+ 能够同时进行导航指令跟随和路径描述，我们在两个任务上都评估了它们的表现（分别见 IV-B 和 IV-C 节），然后进行了一系列诊断实验（见 IV-D 节）和定性研究（见 IV-E 节）。具体来说，对于每项任务，我们给出了 LANA 和 LANA+ 的两个版本的分数：

- LANAmt 和 LANA+mt：在预训练和微调过程中联合学习这两个目标任务。因此，这种多任务版本只有一个单一的代理实例，在两项任务上进行测试。
- LANAst 和 LANA+st：在预训练过程中联合学习这两个任务，但在微调时分别针对每个任务进行。有两个单一任务的代理实例；每个实例仅针对相应任务进行测试。

为了方便理解，我们收集了我们后续实验中的关键观察结果，以突出显示 LANA 和 LANA+ 在性能、参数效率、可解释性和算法设计方面的特点：

1) LANA 和 LANA+ 在两项任务上的表现与以前的任务专用代理相当或更好（见 IV-B 和 IV-C 节）。这表明 LANA 和 LANA+ 是功能强大且多功能的具身代理，擅长语言引导的寻路和导航指令生成。

2) LANAmt/LANA+mt 在两项任务上的表现一致性地优于相应的变体（LANAst/LANA+st），并且参数利用更加高效（见 IV-B 和 IV-C 节）。这证明了 LANA/LANA+ 可以利用跨任务知识来提升语言接地和生成。

3) LANA+ 在两项任务上都超过了 LANA（见 IV-B 和 IV-C 节）以及没有地标识别机制的变体（见 IV-D2 节）。这证明了对象级环境理解对于构建语言能力的导航机器人是必要的。

4) 我们的核心架构设计和训练目标有助于强大的性能（见 IV-D1 和 IV-D2 节）。我们还发现，联合训练指令跟随和生成对预训练和微调阶段都有益，为语言引导的具身代理的训练提供了洞见。

5) LANA 可以通过口头描述其导航路径来提供测试时的行为解释（见 IV-E 节）。这表明 LANA 拥有更高的社会智能，并在需要广泛的人与人之间的交流的真实场景中提供了更大的潜力和价值。

## B. 指令跟随的表现

数据集：我们在 Matterport3D 模拟器构建的四个标准 VLN 数据集上进行了实验：

- R2R [2]：包括 90 个逼真的房子，有 10,567 个全景图。R2R 有 7,189 条最短路径轨迹，每个轨迹都配有三条指令。指令写得非常详细，例如，“退出浴室向左转。走向你右侧看到的第一扇门，然后在那里等待。”平均而言，指令有 25 个单词，专家轨迹（始终是起点和目标之间最短的路径）有 6 个步骤。R2R 包含四个分割，即训练集（61 个场景，14,039 条指令）、val seen（61 个场景，1,021 条指令）、val unseen（11 个场景，2,349 条指令）和 test unseen（18 个场景，4,173 条指令）。训练集和 unseen 分割之间没有重叠的场景。

- R4R [26]：通过连接 R2R 中的两个接近的首尾相连的轨迹和相应的指令来扩展 R2R。因此，R4R 拥有更长的指令和轨迹，平均分别为 51 个单词和 12 个步骤。轨迹也不太有偏见，因为它们不一定是起点和终点之间的最短路径。R4R 包含三组，即训练集（61 个场景，233,613 条指令）、val seen（61 个场景，1,035 条指令）和 val unseen（11 个场景，45,162 条指令）。

- REVERIE [27]：它用目标位置和对象的高级描述替换了 R2R 中的细粒度指令，例如，“推入烤箱旁边的厨房里的酒吧椅。”因此，REVERIE 更具挑战性，因为代理必须在没有逐步指导的情况下导航到目标。REVERIE 中的专家路径通常有 4 到 7 个步骤，指令平均为 15 个单词。REVERIE 由四组组成，即训练集（53 个场景，10,466 条指令）、val seen（61 个场景，1,371 条指令）、val unseen（10 个场景，3,753 条指令）和 test unseen（16 个场景，6,292 条指令）。

- RxR [110]：这是一个全面多语种 VLN 集合，包括英语、印地语和泰卢固语的指令。通过解决导航路径中的偏见，并提供更详细的描述，它强调了语言在 VLN 中的关键作用。例如指令：“你开始在一个宽敞的木制房间，有一个餐桌、一个巨大的壁炉和一块优雅的地毯。向右转，沿着最近的地毯边缘前进。”RxR 有四组，即训练集（11,077 条轨迹，79,467 条指令）、val seen（1,244 条轨迹，8,813 条指令）、val unseen（1,517 条轨迹，13,652 条指令）和 test unseen（11,888 条指令）。

评估指标：对于 R2R，我们遵循惯例 [2]、[3] 报告四个评估指标，其中 SR 和 SPL 是优先考虑的：

1) 成功率 (SR)：最终位置与目标位置距离小于 3 米的百分比；
2) 轨迹长度 (TL)：代理路径长度，以米为单位；
3) 预言成功率 (OR)：代理路径上的任何节点距离目标位置小于 3 米的次数；
4) 成功率加权路径长度 (SPL)：SR 根据预测路径和最短路径长度比率进行归一化。

对于 R4R，它针对的是长期导航，我们进一步采用了以下两个标准指标来衡量预测路径和目标路径之间的路径保真度：

5) 覆盖加权长度得分 (CLS) [26]：基于候选路径和目标路径之间的重叠程度和长度相似性，对它们之间的相似性进行测量；
6) 归一化的动态时间弯曲 (nDTW)：目标路径和参考路径之间的动态时间弯曲归一化；
7) 成功率加权 nDTW (sDTW)：由 SR 加权的 nDTW。

对于 REVERIE，前四个指标也用于其导航子任务的评估，另外两个指标用于整体性能评估：

8) 远程接地成功率 (RGS)：停止时接地到正确对象的比率；
9) RGS 加权路径长度 (RGSPL)：由 PL 惩罚的 RGS。

对于 RxR，它有更长的轨迹和更详细的指令，我们遵循惯例 [52]、[111] 报告四个评估指标：SR、SPL、nDTW 和 sDTW。

定量结果：我们比较了几个著名且最近的高级解决方案 [3]、[4]、[6]、[33]、[38]、[41]、[42]、[43]、[44]、[48]、[51]、[52]、[54]、[55]、[107] 在指令跟随方面的表现。注意，我们报告的是在遵循传统的标准单次运行设置下的单一模型实例的分数 [6]、[48]、[51]、[52]。我们复现了 DUET [43] 来报告三个显著的数字。如表 I 所示，LANAst，它在多任务预训练后仅在寻路上进行了微调，展示了与这些替代方案相当，甚至更好的结果。值得注意的是，学习解释导航路径并遵循指令的LANCART甚至产生了更好的导航性能。例如，LANAst分别在瓦尔unseen和test上提升2%和1% SPL。这验证了我们的语言导航方案和多任务学习策略的有效性。此外，拉娜+配备了地标定位机制和基于拓扑图的环境表示，大大提高了拉娜，并优于所有竞争对手。在R4 R上可以观察到更显著的改进（参见表II）、RxR（参见表IV）和REVERIE（参见表III），其中前两个数据集侧重于具有较长指令和轨迹的长视野导航，而后者仅给出抽象指令。这些结果证实了我们的通用性和通用性。重要的是要注意，所有的竞争对手只知道寻路，而只有我们的代理可以生成接地路线描述解释其导航行为/计划。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/521d14f3803d47898b7ab45b783ce2fa.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/aa774fa8bba2427c8f4ad60a994db5e6.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/653b0b9254384d51b2bd46587868ae6f.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/af39c033108645cebdfca8a67f1c222e.png#pic_ center" width="70%" />
</div>

## C. 指令生成的表现

数据集：我们在两个 VLN 数据集上将机器生成的路径描述与人类编写的指令进行比较：

- R2R [2]：由于 R2R 测试保留了用于基准测试指令跟随代理，我们在 val 集上报告指令生成的性能。每个 R2R 导航路径都与三个真实指令相关联。

- R4R [26]：在 R4R val 集上报告性能，每个路径对应九个真实指令。

- RxR [110]：在 RxR 英语 val 集上报告性能，每个路径得到一个美国英语指令和两个印度英语指令。

注意，REVERIE [27] 没有参与此实验，因为它的指令是高级的、简洁的远程对象描述，不能作为我们生成的指令的基准。

评估指标：按照 [5]、[6] 的选择，我们采用五个文本指标，其中 SPICE 被视为主要指标，正如 [114] 所建议的：

1) BLEU [115]：在候选描述和目标描述上计算的 n-gram 精确度分数的几何平均值；
2) CIDEr [116]：候选和目标文本中n-grams 的平均余弦相似度，根据它们的词频-逆文档频率值加权；
3) METEOR [117]：句子之间 unigram 匹配的精确度和召回率的调和平均值；
4) ROUGE [118]：通过计算每个 n-gram 大小、词序列或词对的候选和目标文本之间的召回率和精确度分数，并使用加权 F-measure 进行平均，来衡量相似度；
5) SPICE [119]：基于候选和参考句子的场景图元组的 F 分数。

由于 R2R 和 R4R 中的每个导航路径都标注了三个参考指令，这些指标通过将每个候选指令与同一路径的三个参考进行比较来报告。

定量结果：我们将 LANA 和 LANA+ 与四种基于神经网络的指令生成代理 [3]、[4]、[5]、[6] 进行了比较。表 V 和表 VI 分别总结了我们在 R2R 和 R4R 上的比较结果。可以发现，我们的任务特定代理，即 LANAst 和 LANA+st，已经在所有指标和数据集上超过了所有竞争对手。值得注意的是，CCC [6]，一个当前领先的解决方案，它在单独的寻路器的帮助下学习指令生成模型。此外，我们的多任务代理，即 LANAmt/LANA+mt，表现与 LANAst/LANA+st 相当甚至更好，证明了我们方法的算法和功能性优势。表 VII 展示了 RxR 上的比较结果。值得注意的是，LANA 和 LANA+ 在生成详细指令方面都超过了竞争对手，这一挑战性基准尤其突出。更令人印象深刻的是，通过整合地标信息，LANA+ 在两个基准上都取得了更显著的性能提升。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/af88827fb3bb45fca639e4804d8a1752.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/4994207f7bde4204b55c8e58404aa291.png#pic_ center" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c35777a33963449c939032796712b6ea.png#pic_ center" width="70%" />
</div>

评估指令跟随代理的语言质量：由于缺乏通用标准来衡量好的语言描述，语言评估是一项具有挑战性的任务。评估面向导航的路径描述质量的一种自然方法是检查它们能够多好地指导导航代理按照与遵循人类指令时相似的路径进行导航 [10]、[113]。在这里，我们考虑了三个最先进的指令跟随代理 [48]、[53]、[95]，并计算了它们遵循人类编写和模型生成指令时生成的路径之间的 nDTW。我们的实验结果总结在表 VIII 中。可以看到，与其他指令生成代理相比，LANA 和 LANA+ 可以提供更高质量的指令 - 三个寻路代理相对更难区分 LANA/LANA+ 指令与人类指令。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/a4c6a74b4d1c46389bb95bfbd9e73142.png#pic_ center" width="70%" />
</div>

用户研究：由于自动化文本生成指标的固有局限性，路径描述的性能不能被客观和全面地评估 [114]。为了进行完整的分析，我们进行了一组基于成对比较的人类评估实验，共涉及 50 名大学生，他们被要求分别比较 LANA/LANA+ 生成的指令与 CCC、BTSpeaker 和人类创建的指令，总共比较了 100 条路径。这些路径是从 R2R val unseen 中采样的。总结来说，LANA 在与 CCC（36.6%）和 BT-Speaker（24.9%）的比较中分别获得了 63.4% 的偏好分数。此外，LANA+ 在与 CCC（29.7%）和 BT-Speaker（16.5%）的比较中获得了更高的偏好分数，分别为 70.3% 和 83.5%。然而，人类编写的指令仍然比我们的模型生成的指令更受欢迎，与 LANA（30.7%）和 LANA+（34.8%）的比较中分别获得了 69.3% 和 65.2% 的偏好分数，这表明仍有很大的改进空间。

D. 诊断实验

1) 训练策略的有效性：为了彻底研究我们训练策略的有效性，我们在 R2R [2] 的 val unseen 集合上使用 LANA 对指令跟随和生成任务进行了一系列的诊断实验。实验结果总结在表 IX 中，并涉及总共八个基线。这些基线大致可以分为三类：基线 1、2 和 3 都没有进行预训练，并且在每个任务上单独或联合微调；基线 4 和 5 进行预训练，并在每个任务上单独微调；基线 6、7 和 8 进行联合任务预训练，并在每个任务上单独或联合微调。基线 6 和 7 是两个单任务代理，即 LANAst，基线 8 是我们最终交付的代理 LANAmt；它们的表现已在 IV-B 和 IV-C 节中进行了详细报告。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/18eb74c463b7404ba26156bed5c55444.png#pic_ center" width="70%" />
</div>

同样，注意基线 1、4 和 6 只掌握寻路，基线 2、5 和 7 只能承担路径描述任务。基线 3 和 8 能够执行两者。

可以得出几个重要结论：

   - 联合任务微调可以提升两项任务的表现（基线 3 与 1 和 2 对比）；
   - 联合任务预训练和微调可以提升两项任务的表现（基线 8 与 6、7 对比）；
   - 预训练可以促进最终表现（基线 4 与 1 对比，基线 5 与 2 对比，基线 6 与 1 对比，基线 7 与 2 对比，基线 8 与 3 对比）；
   - 联合任务预训练比单任务预训练更受青睐（基线 8 与 4、5 对比）；
   - 联合任务预训练和微调比其他所有训练策略更受青睐（基线 8 与 1-7 对比）。

注意，联合任务预训练和微调不仅提升了表现，还提高了参数效率，即基线 8（143 M）与 6 + 7（220 M = 123 M + 97 M）相比。总之，我们的消融实验坚定地验证了我们的想法的力量，算法设计的有效性，以及我们在高效参数利用方面的优势。

2) 架构设计的有效性：最后，我们检查了我们的路由编码器的设计，它考虑了先前的动作标记和过去的全景观察（见公式（4））。我们在 R2R val unseen [2] 上测试了 LANA 的两个变体。如表 X 所示，第一个变体（第一行）仅使用前一动作标记上的时间自注意力，而第二个变体（第二行）仅采用交叉注意力操作来关注历史全景观察。我们的完整模型（最后一行）结合了这两种信息源，取得了最佳表现。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/a0aa0febc90b4beea1df3df45974a840.png#pic_ center" width="70%" />
</div>

3) 地标识别的有效性：为了更好地理解 LANA+ 使用的地标识别机制（第 III-A5 节）的影响，我们对 LANA+st 和 LANA+mt 在两项任务上进行了诊断实验。表 XI 总结了实验结果。BASEst 和 BASEmt 分别表示基线模型的单任务和多任务版本，它们只构建了基本路由编码器。如表中第一行和最后一行所示，借助地标识别机制，LANA+st 和 LANA+mt 在所有评估指标和任务上都一贯地提高了基线的表现。此外，第二行和最后一行揭示了 LANA+ 的联合任务训练对指令跟随和生成都有益，这与 IV-D1 节中 LANA 的结论一致。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/ccf90e3be9484f499f442ddd8027dc21.png#pic_ center" width="70%" />
</div>

## E. 定性实验

图 4 描述了 R2R [2] val unseen 集合中的三个示例导航情节。图 4(a) 比较了 LANAmt 和 LANAst 在指令跟随任务上的表现。如所见，这是一个具有挑战性的案例，因为目标位置从起始点不可见。此外，多个分叉的存在为下一步提供了各种可能的路径，增加了挑战。LANAmt 在这种情况下表现稳健，而 LANAst 未能到达目标位置。由于 LANAmt 和 LANAst 构建了相似的网络架构和预训练协议，我们将其归因于微调期间跨任务知识的探索。图 4(b) 可视化了指令创建的比较。如所见，LANAmt 输出了更具接地性的指令，包含精确的动作描述（例如，向左转，走下去）以及显著的地标（例如，双门、餐桌、冰箱）。这些描述具有与人类生成的文本相似的属性，甚至涉及一些地标（例如，沙发），这些地标信息丰富但人类参考中遗漏了。图 4(c) 显示，LANA 可以通过展示其导航过程的人类文本报告来提供实时行为解释。这不仅减轻了人类持续监控的负担，而且在一定程度上揭示了其内部模式。例如，步骤 1-3 的报告通知说 LANA 错误地将储藏室识别为卧室 - 这就是为什么 LANA 在步骤 2 选择进入储藏室。总之，作为一个语言能力的导航器，LANA 在（事后）可解释性和人-机器人双向交流方面展现出优势，这是人类信任产生的基础前提。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/909e43ff6a4440daae47d9e97ce36a95.png#pic_ center" width="70%" />
</div>

图 5 描述了 LANA+ 和 LANA 的视觉结果。在图 5(a) 中，LANA+ 的地标识别模块成功识别了关键地标“沙发、沙发和电视”。这使得代理能够更好地理解给定的指令（“向左转，走过电视和白色沙发”），因此在步骤 4 做出正确的决定“向左转”。此外，借助地标“植物”的检测，LANA+ 在步骤 6 成功“停止”。相比之下，LANA 在步骤 4 做出了错误的决定，未能到达目标位置。在图 5(b) 中，LANA+ 在其导航报告中提到了地标（例如，电视、办公室、地毯），但 LANA 则没有。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/fb9f3d454a4d4d3d8705c6bd17bff75f.png#pic_ center" width="70%" />
</div>

# V. 结论

在本文中，我们挑战了当前的 VLN 代理，它们擅长遵循自然语言指令但无法生成它们，我们指出它们无法与人类伙伴沟通。我们设想了新一代的导航机器人，它们既能执行也能口头表达导航指令。为了实现这一愿景，我们开发了 LANA，这是一个语言能力导航代理，通过一个优雅且集成的多任务学习架构同步学习指令跟随和生成任务。我们进一步提出了 LANA+，它通过一个对象识别机制扩展了 LANA，允许有效地发现和利用地标上下文来促进这两项任务。LANA 在复杂度要低得多且参数效率更高的情况下，超过了专门针对单一任务的先前模型。此外，LANA/LANA+ 展示了能够生成高质量的路径描述的能力，这些描述可以及时解释其行为并在协作场景中指导人类伙伴。这项工作代表了朝着创建交互式和值得信赖的导航机器人迈出的虽小但重要的一步。作为未来的工作，我们打算将大型语言模型整合到 LANA 中。我们还打算扩展 LANA 的功能，以支持在导航期间与人类进行交互式对话。
声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
