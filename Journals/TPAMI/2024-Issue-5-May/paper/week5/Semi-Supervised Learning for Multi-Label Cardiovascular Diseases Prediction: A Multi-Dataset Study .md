# 题目：[Semi-Supervised Learning for Multi-Label Cardiovascular Diseases Prediction: A Multi-Dataset Study ](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10360273)  
## 半监督学习用于多标签心血管疾病预测：多数据集研究
**作者：Rushuang Zhou; Lei Lu; Zijun Liu; Ting Xiang; Zhen Liang; David A. Clifton; Yining Dong; Yuan-Ting Zhang** 

**代码：** https://github.com/KAZABANA/ECGMatch
****
# 摘要
心电图（ECG）是预测心血管疾病（CVDs）的非侵入性工具。由于深度学习技术的快速发展，目前基于ECG的诊断系统表现出令人鼓舞的性能。然而，标签稀缺问题、多种CVDs的共现以及在未见数据集上的表现不佳极大地阻碍了基于深度学习模型的广泛应用。在一个统一框架中解决这些问题仍然是一个重大挑战。为此，我们提出了一种多标签半监督模型（ECGMatch），以在有限监督下同时识别多种CVDs。在ECGMatch中，开发了一个ECGAugment模块用于弱和强的ECG数据增强，从而生成多样化的样本用于模型训练。随后，我们设计了一个基于邻居一致性建模和知识蒸馏的超参数高效框架用于伪标签生成和精炼，从而缓解了标签稀缺问题。最后，提出了一个标签相关性对齐模块，以捕捉标注样本中不同CVDs的共现信息，并将这些信息传播到未标注样本中。在四个数据集和三种协议上的广泛实验表明了所提模型的有效性和稳定性，尤其是在未见数据集上。因此，该模型可以为在有限监督下实现稳健性能的多标签CVDs预测诊断系统铺平道路。


# 关键词
- 心血管疾病
- 心电图
- 多标签学习
- 半监督学习



## I. 引言

近年来，心血管疾病（CVDs）已成为世界上发病率和死亡率的主要原因。作为一种非侵入性测试，12导联心电图（ECG）被广泛用于诊断CVDs。随着深度学习和人工智能的快速发展，AI辅助自动诊断系统在临床实践中引起了广泛关注。大多数这些系统是为标注样本充足且分布相同的设置而设计的，每个样本只属于一种CVDs类别。不幸的是，复杂的现实世界设置与这种理想设置不同，标注的ECG片段难以收集，并且每个片段中可以识别出多种CVDs。此外，现实世界中的训练和测试数据可能不是从同一分布中采样的，这极大地影响了模型性能。现实世界设置与理想设置之间的差异限制了当前系统在临床上的应用。总之，自动诊断系统在临床应用中面临三大挑战：1）标签稀缺问题。2）在未见数据集上的表现不佳。3）多种CVDs的共现。

近年来，半监督学习（SSL）在解决临床应用中的标签稀缺问题上展示了巨大潜力。SSL模型的主要思想是利用未标注样本进行模型训练，这比标注样本更容易收集。通过利用未标注样本中的丰富信息，SSL模型在标注样本数量有限时通常优于全监督模型。因此，提出了许多研究以将SSL的成功扩展到基于ECG的CVDs预测中。例如，Oliveira等人应用现有的SSL模型进行ECG信号分类。在MIT-BIH数据库上的实验表明，SSL模型优于全监督模型。为了提高模型在未见数据集上的性能，Feng等人提出了一个迁移学习框架，将在标签充足的数据集上训练的模型迁移到标签稀缺的目标数据集上。在四个基准上的全面结果证明了所提框架的鲁棒性。同时，多标签学习为如何从一个ECG记录中同时检测多种CVDs提供了新思路。与单标签学习不同，多标签学习为给定样本生成多个预测，每个预测指示样本是否属于特定类别。多标签学习模型有能力从ECG信号中检测多种疾病，而单标签模型仅限于一次识别一种疾病。因此，提出了许多模型以利用多标签学习进行基于ECG的CVDs预测。例如，Strodthoff等人评估了现有模型在PTB-XL数据库上的性能，并证明了使用多标签学习模型进行CVDs预测的可行性。随后，Ge等人和Ran等人提出了利用不同心脏疾病之间的关系来提高模型性能。Lai等人通过开发一种通过自监督预训练初始化的多尺度深度神经网络，实现了CVDs的高效预测。更多关于现有基于ECG的CVDs预测模型的详细信息在第二节中介绍。

据我们所知，之前没有研究提出并验证了一个统一的框架来同时解决上述三个挑战。具体来说，大多数之前的研究仅缓解了上述问题之一，而没有全面考虑CVDs预测中的其他两个挑战。例如，许多基于SSL的模型忽略了多种CVDs的共现，并且它们在未见数据集上的表现不佳。之前的多标签学习模型可以从ECG信号中检测多种CVDs，但其有效性很大程度上依赖于充足的标注数据和手工设计的先验知识。这些显著的不足表明这些模型离实际应用还有很大距离。因此，在本研究中，我们提出了一个多标签半监督框架（ECGMatch），该框架可以仅使用1％的标注样本，在跨数据集的多标签CVDs预测中取得良好结果。接下来，我们介绍所提框架如何同时解决上述问题。

首先，开发了一种新的ECGAugment模块，通过生成多样化的样本来缓解标签稀缺问题。它利用了ECG信号的内在特性，远远优于传统方法。此外，我们设计了一个伪标签生成模块，利用学生和教师网络之间的互动生成未标注样本的伪标签。具体来说，我们将生成任务公式化为一个知识蒸馏过程。在训练期间，教师在两个内存库中存储所学知识，学生访问这些内存库，使用K-最近邻投票策略为未标注样本分配伪标签。为了减轻不准确伪标签的负面影响，我们提出了一种邻居一致性建模方法，并开发了一个超参数高效的模块来精炼这些标签。在K-最近邻投票过程中，邻居之间的一致程度可以用来估计伪标签的置信度，这是发现可信伪标签的重要指标。在多标签学习中，所提超参数高效的精炼模块的优势更为显著，因为它仅依赖于邻居数K，而不是众多阈值和复杂的控制策略。

为了捕捉不同CVDs的共现，我们引入了一个标签相关性对齐模块。它使用有限的标注数据定量估计共现信息，并将这些知识转移到未标注数据中。在实践中，我们计算一个相关矩阵来表示共现信息，并对齐在标注和未标注数据上计算的矩阵，以完成知识转移过程。最后，我们在四个公共数据集和三个协议上进行了广泛的实验。结果全面验证了ECGMatch的优越性，特别是在未见数据集上的优越性。总结来说，主要贡献和创新如下。

- 我们提出了一个稳健的ECG信号增强流程，相比之前的方法表现出显著改进。
- 我们开发了一种用于多标签学习的伪标签精炼的高效方法。它比基于阈值的方法参数更少，但表现更好。
- 我们提出了一种新方法来对齐标注和未标注数据上计算的标签相关性，为捕捉多种CVDs的共现提供了可靠的解决方案。
- 我们提出了一个多标签CVDs预测的统一半监督框架，这是第一个同时解决这一领域三个关键挑战的框架。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/c4d0c6e3b7b6437c87cf6e1619e51d7e.png)



## III. 方法

### A. 概述

在多标签CVDs预测的半监督学习中，训练的ECG数据分为标注和未标注集，表示为 $DB = \{X_ b, Y_ b\} = \{x_ i^b, y_ i^b\}_ {i=1}^{N_ B}$ 和 $DU = \{X_u, -\} = \{x_i^u, -\}_ {i=1}^{N_ U}$。 $N_B$ 和 $N_U$ 是 $DB$ 和 $DU$ 中样本的数量。 $X_b$ 包含标注的12导联ECG记录， $Y_b$ 表示相应的多标签地面真相。具体来说， $y_i^b$ 中的第c维包含类别c的地面真相， $y_i^c \in \{0, 1\}$。因此，一个给定的ECG记录可能同时属于多个类别。为了澄清叙述，常用符号总结在表I中。如图1所示，所提的ECGMatch包括三个模块：ECGAugment模块、伪标签生成和精炼模块以及标签相关性对齐模块。在ECGAugment模块中，受弱强增强方法的启发，我们通过研究ECG信号的内在特性设计了一个新的增强流程，称为ECGAugment。在伪标签生成和精炼模块中，我们引入了一种知识蒸馏方法用于伪标签生成。然后，我们提出了一种邻居一致性建模方法，用于计算伪标签的重要性分数，从而减轻不准确伪标签的负面影响。在标签相关性对齐模块中，我们提出通过Frobenius范数正则化对齐在标注数据和未标注数据上计算的标签相关性矩阵，从而使模型能够捕捉不同CVDs之间的标签依赖关系。以下是关于所提ECGMatch的更多详细信息。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/f9674d84a3664ee1a3921afb7814fdbd.png)




### B. ECGAugment

解决标签稀缺问题的关键方法之一是高效的数据增强。尽管在先前的研究中已经充分研究了ECG增强方法，但如何正确定义适用于基于ECG的半监督学习的弱增强和强增强流程仍然具有挑战性。因此，我们提出了一种新的ECG信号增强流程，通过利用它们的特性，称为ECGAugment。具体来说，‘弱’增强 $w(\cdot)$ 被定义为随机选择一种变换来增强一个12导联ECG信号 $x \in \mathbb{R}^{12 \times L}$，其中L是 $x$ 的长度。

1. 信号丢失：我们随机将一个随机时间窗口内的ECG信号值设置为零。其长度和位置是从均匀分布中随机生成的。这种变换使模型能够处理由ECG电极接触不良引起的弱信号。
2. 时间翻转：受先前研究的启发，我们沿时间轴翻转原始ECG信号，这意味着信号是逆向读取的。
3. 通道重组： $x$ 的每一行表示在一个导联（通道）记录的ECG信号。因此，我们随机更改信号矩阵 $x$ 中行向量的顺序，以打乱其通道组织。
4. 随机噪声：受基于对比学习和对抗学习的ECG噪声污染技术的启发，我们向原始信号 $x$ 添加高斯噪声 $\epsilon \sim \mathcal{N}(0, \sigma)$。

受RandAugment技术用于图像增强的启发，我们通过随机选择 $T \leq 4$ 个变换来定义‘强’增强 $g(\cdot)$ 来扰动输入信号 $x$。具体来说，随机生成一个变换队列，并依次应用队列中的变换。对于一个随机队列 {2, 1, 3}，我们依次对输入信号应用时间翻转、信号丢失和通道重组。与传统的顺序扰动相比，固定变换的数量和顺序，所提方法通过引入额外的随机性显著增加了增强样本的多样性，从而大大提高了模型性能。

### C. 多标签学习的伪标签生成

稳健半监督学习的关键是准确的伪标签生成，这已在许多先前的研究中得到了证明。然而，先前的研究主要考虑单标签条件，其中每个样本仅属于一个类别。相比之下，本研究集中在多标签条件下，其中每个样本同时属于多个类别。在这里，我们使用知识蒸馏方法生成伪标签。具体来说，我们引入了一个教师模型 $M_t = \{f_ t(\cdot), h_ t(\cdot)\}$ 和一个学生模型 $M_s = \{f_ s(\cdot), h_ s(\cdot)\}$，其中 $f(\cdot)$ 是一个特征提取器， $h(\cdot)$ 是一个多标签分类器。如图1所示，我们首先分别将弱增强 $w(\cdot)$ 和强增强 $g(\cdot)$ 应用于未标注的ECG记录 $x_u$。教师模型从弱增强信号 $w(x_u)$ 中提取深度特征 $z_{u,t} = f_ t(w(x_u))$ 并输出相应的预测 $p_{u,t} = \text{sigmoid}(h_t(z_{u,t}))$。然后我们将它们存储在两个内存库中（特征库 $Z = \{z_ {u,t}^n\}_ {n=1}^{N_ U}$ 和预测库 $P = \{p_ {u,t}^n\}_ {n=1}^{N_ U}$）， $N_ U$ 是 $DU$ 中的样本数量。注意， $Z$ 和 $P$ 是随着当前小批量数据进行动态更新的。在本研究中， $p_{u,t}^n = [p_{u,t}^{n,1},  \ldots, p_{u,t}^{n,c}]$ 是一个C维向量，其中第c个元素表示类别c的预测， $p_{u,t}^{n,c} \in [0, 1]$。在训练过程中，学生模型从给定的未标注样本 $x_u^i$ 中提取特征向量 $z_{u,s}^i = f_s(w(x_u^i))$ 并使用广泛使用的软投票方法为其分配一个伪标签 $(\hat{y}_ u^i)$。具体来说， $\hat{y}_ u^i$ 通过整合其 $K$ 个最近邻的预测 $\{z_ {u,t}^k\}_ {k=1}^K$ 计算得出，表示为

$$
\hat{y}_ u^i = \frac{1}{K} \sum_{k=1}^K p_{u,t}^k,
$$

其中 $p_{u,t}^k$ 是 $z_{u,t}^k$ 的预测，是特征向量 $z_{u,s}^i$ 在特征库 $Z$ 中的第k个最近邻， $K$ 是邻居的数量。 $\{p_ {u,t}^k\}_ {k=1}^K$ 通过访问预测库 $P$ 获得。为了进行知识蒸馏过程，我们最小化学生模型预测与伪标签 $\hat{y}_ u^i$ 之间的二元交叉熵损失。受弱强一致性正则化方法的启发，我们将强增强 $g(\cdot)$ 应用于未标注样本 $x_ u^i$ 并通过 $q_ {u,s}^i = \text{sigmoid}(h_ s(z_ {u,s}'))$ 计算相应的学生预测， $z_ {u,s}' = f_s(g(x_ u^i))$。然后我们计算伪标签和未标注样本的学生预测之间的二元交叉熵损失，定义为

$$
L_u = - \frac{1}{B_u C} \sum_{i=1}^{B_u} \sum_{c=1}^{C} (1 - \hat{y}_ u^{i,c}) \log(1 - q_{u,s}^{i,c}) + \hat{y}_ u^{i,c} \log q_{u,s}^{i,c},
$$

其中 $C$ 是数据集中的类别数量， $B_u$ 是当前小批量中的未标注样本数量。使用小批量中的标注样本的地面真相，我们计算监督的二元交叉熵损失，定义为

$$
L_b = - \frac{1}{B C} \sum_{i=1}^{B} \sum_{c=1}^{C} (1 - y_b^{i,c}) \log(1 - p_{b,s}^{i,c}) + y_b^{i,c} \log p_{b,s}^{i,c},
$$

其中 $B$ 是当前小批量中的标注样本数量， $p_{b,s}^{i,c} = \text{sigmoid}(h_s(f_s(w(x_b^i))))$ 是学生模型给出的预测， $y_b^{i,c} \in \{0, 1\}$ 是相应的地面真相。结合 $L_u$ 和 $L_b$，我们计算半监督多标签分类的总体损失，定义为

$$
L = L_b + \lambda L_u,
$$

其中 $\lambda$ 是控制 $L_u$ 权重的超参数。在伪标签生成之前，教师模型 $M_t$ 使用 $L_b$ 在标注数据集 $DB$ 上预训练。然后在知识蒸馏过程中，使用随机梯度下降更新学生模型 $M_s$ 以最小化 $L$。为了稳定维护的特征库 $Z$ 和预测库 $P$，教师模型 $M_t$ 的参数 $\theta_t$ 通过学生模型 $M_s$ 参数的动量移动平均进行更新，定义为

$$
\theta_t = m \theta_t + (1 - m) \theta_s,
$$

其中 $m$ 是动量超参数。

### D. 基于邻居一致性建模的伪标签精炼

不准确的伪标签会损害半监督学习中的模型性能。因此，生成的伪标签 $\hat{y}_ u$ 应进一步精炼以避免此问题。先前的研究利用固定或动态阈值去除置信度低的伪标签。然而，在多标签分类中为不同类别设置单独优化的阈值是困难的。此外，设计动态阈值的更新策略需要大量超参数。因此，我们提出了一种基于邻居一致性建模（NAM）的新伪标签精炼方法。它通过计算伪标签的邻居一致性来精炼原始伪标签 $\hat{y}_u$，然后在损失传播中调整其重要性。与传统的基于阈值的精炼方法相比，NAM用一个重要性加权过程替换了阈值控制过程，这在半监督多标签分类中超参数更高效。

回顾我们通过平均其 $K$ 个最近邻的预测 $p_{u,t}^{k,c} \in [0, 1]$ 为未标注样本 $x_u^i$ 生成了原始伪标签 $\hat{y}_ u^i$。在这里，我们将邻居的预测 $p_{u,t}^{k,c}$ 相加，并应用邻居一致性函数 $I(\cdot)$ 计算伪标签 $\hat{y}_u^i$ 在类别c上的邻居一致性。

$$
\alpha_u^{i,c} = I \left( \sum_{k=1}^K p_{u,t}^{k,c} \right) = \left| \frac{2}{K} \sum_{k=1}^K p_{u,t}^{k,c} - 1 \right|,
$$

其中 $K$ 是最近邻的数量。 $\alpha_u^{i,c} \in [0, 1]$ 是邻居一致性，也可以被视为模型对伪标签 $\hat{y}_u^i$ 的置信度。结合 $\alpha_u^{i,c}$ 和 $L_u$，我们可以将无监督二元交叉熵损失重新写为

$$
L_u = - \frac{1}{B_u C} \sum_{i=1}^{B_u} \sum_{c=1}^{C} \alpha_u^{i,c} \left[ (1 - \hat{y}_ u^{i,c}) \log(1 - q_{u,s}^{i,c}) + \hat{y}_ u^{i,c} \log q_{u,s}^{i,c} \right],
$$

其中 $\alpha_u^{i,c}$ 控制损失计算中 $\hat{y}_u^{i,c}$ 的权重。具体来说， $\alpha_u^{i,c}$ 为邻居预测高一致性的伪标签分配高权重 $(\alpha_u^{i,c} \approx 1)$。注意，NAM模块的标签精炼过程仅与一个超参数 $K$ 相关，即最近邻的数量。相比之下，先前的基于阈值的方法需要为多标签分类中的 $C$ 个独立类别设置固定或动态阈值，在超参数网格搜索中效率较低。此外，基于阈值的方法通常丢弃置信度低于预定义阈值的伪标签。阈值的选择对训练数据集中的类别分布敏感，当应用于类别分布不同的未见数据集时，可能导致次优的泛化性能。相比之下，所提NAM采用了一种软方法，调整生成伪标签的重要性，而不是直接拒绝它们。与基于阈值的方法相比，它对训练数据中的类别分布不太敏感，可以提高模型在未见数据集上的性能。

### E. 标签相关性对齐

CVDs的共现导致不同类别之间的强关系，应该考虑这些关系以在多标签分类中实现更好的预测性能。先前的研究集中于标注样本中的标签依赖性，并利用不同类别之间的语义关系来指导模型训练。然而，在没有足够先验知识的情况下，很难定义各种CVDs之间的关系。另一方面，忽略大规模未标注样本中的标签依赖性导致信息浪费。因此，我们提出通过计算两个标签相关性矩阵（ $R_b$ 和 $R_u$）联合捕捉标注和未标注样本中的标签依赖性。在实践中， $R_b$ 是使用标注样本计算的，而 $R_u$ 是使用未标注样本估计的。计算过程不需要额外的先验信息，如不同标签之间的词嵌入相关性。然后我们最小化 $R_b$ 和 $R_u$ 之间的差异，以对齐标注和未标注样本计算的标签依赖性，从而提高多标签分类中的模型性能。

首先，我们介绍如何基于标注样本集 $DB = \{X_b, Y_b\}$ 计算标签相关性矩阵 $R_b$。$Y_b = [y_b^1; y_b^2; \ldots; y_b^{N_B}]$ 是一个 $N_B \times C$ 的标签矩阵，其中 $C$ 是类别数量。类别 $c1$ 和 $c2$ 之间的标签相关性 $r_{c1,c2} \in [0, 1]$ 可以通过这两个类别上的标签序列 $(y_{c1}, y_{c2})$ 的相似性来估计，其中 $y_{c1} = [y_{b,c1}^1; y_{b,c1}^2; \ldots; y_{b,c1}^{N_B}]$ 和 $y_{c2} = [y_{b,c2}^1; y_{b,c2}^2; \ldots; y_{b,c2}^{N_B}]$。我们发现，余弦相似性比其他度量（如皮尔逊系数）更有效地进行标签相关性分析。如公式（8）所示，对于二值化的标签 $y_{c1}$ 和 $y_{c2}$，它估计了类别 $c1$ 和 $c2$ 之间的条件概率，而不受不同数据集的类别分布影响。公式（8）的证明和不同相似性度量的详细分析见在线附录B。基于余弦相似性，相关性 $r_{c1,c2}$ 计算如下

$$
r_{c1,c2} = \frac{y_{c1}^T y_{c2}}{\|y_{c1}\| \|y_{c2}\|} \approx \sqrt{P(c1=1|c2=1)P(c2=1|c1=1)},
$$

标签相关性矩阵 $R_b$ 可以通过以下公式计算

$$
R_b = N(Y)^T N(Y),
$$

其中 $N(Y)$ 是一个归一化函数，将 $Y$ 的列向量归一化为单位向量。对于未标注样本，我们使用学生网络 $M_s$ 输出的模型预测 $P_u$ 估计标签相关性矩阵 $R_u$。为了提高估计 $R_u$ 的鲁棒性，我们同时使用强增强和弱增强样本来增加计算的样本量。因此， $R_u$ 估计为

$$
R_u = N(P_u)^T N(P_u)， \quad P_u = [q_u^1; p_u^1; \ldots; q_u^{B_u}; p_u^{B_u}],
$$

其中 $P_u$ 是一个 $2 B_u \times C$ 的矩阵，包含强增强和弱增强未标注样本 $(g(x_u)$ 和 $w(x_u))$ 的学生预测， $B_u$ 是当前小批量中的未标注样本数量。具体来说， $q_u^i = \text{sigmoid}(h_s(f_s(g(x_u^i))))$ 和 $p_u^i = \text{sigmoid}(h_s(f_s(w(x_u^i))))$。标签相关性矩阵表示不同CVDs之间的依赖性和语义关系，这应该在标注和未标注数据中保持一致。因此，我们使用Frobenius范数正则化最小化 $R_b$ 和 $R_u$ 之间的差异，定义为

$$
L_f = \|R_b - R_u\|_ F，
$$

其中 $\| \cdot \|_ F$ 表示给定矩阵的Frobenius范数。最后，我们通过结合监督多标签分类损失 $L_b$、重要性加权的无监督多标签分类损失 $L_u$ 和标签相关性对齐损失 $L_f$ 来公式化所提ECGMatch的最终损失

$$
L = L_b + \lambda_u L_u + \lambda_f L_f，
$$

其中 $\lambda_u$ 和 $\lambda_f$ 是控制不同目标函数重要性的两个超参数。我们在算法1中提出了ECGMatch的完整算法。

## IV. 实验和数据集

### A. 公共ECG数据库

为了评估所提ECGMatch模型的性能，我们在PhysioNet网站发布的四个知名公共数据库上进行了实验：乔治亚12导联ECG挑战（G12EC）数据库、物理技术联邦研究所（PTB-XL）数据库、Chapman-Shaoxing数据库和宁波数据库。G12EC数据库包含10,344个可用的ECG记录，每个记录持续5到10秒，采样频率为500 Hz。PTB-XL数据库包含22,353个可用的ECG记录，每个记录大约10秒，采样频率为500 Hz。Chapman-Shaoxing数据库由10,646名受试者的ECG记录组成，而宁波数据库包含40,258个ECG记录。每个记录的采样频率为500 Hz，持续时间为10秒。不幸的是，上述数据库采用了不同的标签注释方案，并包含不同种类的CVDs，这导致数据库之间存在显著的类别差距。由于对类别差距问题的详细讨论超出了我们研究的范围，我们仅通过使用一致的标签注释方案重新注释数据库来解决这一问题。总之，我们通过将数据集中的ECG信号分类为五类（异常心律、ST/T异常、传导障碍、其他异常和正常信号）重新注释了数据集。注意，ECG信号可能同时属于两个或更多类别。有关注释方案的详细信息见在线附录A。为了预处理信号，我们首先通过零填充将原始信号的长度规范化为6144个样本。接下来，我们应用带通滤波器（1.0-47.0 Hz）消除原始ECG记录中的噪声成分。最后，信号使用z-score归一化进行归一化处理。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/a64ee70503f04a7d80a3055d479746bb.png)




### B. 实现细节

在我们的实现中，我们使用基于注意力的卷积神经网络作为特征提取器 $f(\cdot)$，输出特征 $z$ 的维度为128。分类器 $h(\cdot)$ 设计为128个神经元（输入层）-128个神经元（隐藏层1）-5个神经元（输出层）-Sigmoid激活。教师网络 $M_t = \{f_t, h_t\}$ 在标注样本集 $DB$ 上预训练，学生网络 $M_s = \{f_s, h_s\}$ 的参数初始化为 $M_t$ 的参数。在半监督训练过程中，教师网络 $M_t$ 的参数通过公式（5）更新，动量为0.999。我们使用标准的随机梯度下降（SGD）优化器，动量为0.9进行参数优化。初始学习率设置为3e-2，并采用指数学习率衰减计划 $\eta = \eta_0 (1+\gamma e/E)^{-p}$，其中 $\eta_0$ 是初始学习率， $e$ 是当前训练步数， $E = 5000$ 是最大训练步数。在每个小批量中，标注样本的数量 $B$ 为64，未标注样本的数量 $B_u$ 为448。公式（12）中的权重 $\lambda_u$ 和 $\lambda_f$ 在[0,1.6]范围内以0.4为步长进行搜索。

### C. 模型评估的实验协议

为了评估所提模型在多标签CVDs分类中的鲁棒性，我们提出了三种不同的模型评估协议，考虑到各种临床应用。

1. **数据集内协议**：对于模型训练和评估，训练、验证和测试数据按0.8 : 0.1 : 0.1的比例从一个数据集中随机采样。然后，我们按0.05 : 0.95的比例将训练数据分为标注和未标注数据。最后，计算四个数据集的平均性能和标准差，跨三个随机种子。
2. **混合数据集协议**：在这种情况下，我们同时从四个数据集中随机采样训练、验证和测试数据，比例为0.8 : 0.1 : 0.1。训练数据按0.01 : 0.99的比例分为标注和未标注数据。计算平均性能和标准差，跨三个随机种子。该协议考虑了多中心设置，其中训练数据包含来自不同数据集（中心）的样本。
3. **跨数据集协议**：为了评估模型在未见测试数据集上的性能，我们使用三个数据集进行模型训练和验证，保留剩余一个进行测试。例如，我们可以将G12EC数据集保留为未见测试集，并从剩余三个数据集（PTB-XL、Chapman、Ningbo）中采样训练数据（90％）和验证数据（10％）。训练数据中仅有1％被标注，其余99％为未标注。我们重复评估过程，直到每个数据集都作为未见测试集使用一次，并报告跨三个随机种子的平均性能和标准差。该协议作为所提模型的外部验证，评估模型在不同独立数据集上的泛化能力。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/7a22ab414004440d89951f74546b5882.png)



我们使用多种多标签指标评估各种模型的性能，包括排名损失、汉明损失、覆盖、平均平均精度（MAP）、宏AUC和宏Gbeta。需要注意的是，排名损失、汉明损失和覆盖值越低表示性能越好，而MAP、宏AUC和宏Gbeta得分越低表示性能越差。关于这些指标的更多详细信息见文献[53]。以下部分基于上述三种实验协议和六个评估指标，展示了所提ECGMatch与现有文献的比较。由于在ECG多标签分类中应用SSL的研究有限，我们复制了最先进（SOTA）的几个模型，这些模型最初是为图像或文本分类实现的：MixMatch、FixMatch、FlexMatch、DST、PercentMatch、SoftMatch、UPS。通过采用相同的骨干和增强策略（ECGAugment）确保所有比较模型的一致性。我们还使用相同的一组常见超参数，如学习率和批量大小。对于特定模型的参数，如FixMatch中的锐化温度，我们采用参考研究中推荐的最佳设置。

## V. 结果与讨论

### A. 与最先进方法的比较

不同模型在不同协议上的性能如表II、III和IV所示。结果表明，ECGMatch在所有实验协议中都取得了领先性能，证明了其优越性。例如，ECGMatch的平均性能优于基于阈值的SOTA模型，如FixMatch、FlexMatch、DST，尤其是当测试数据来自未见数据集时。具体来说，ECGMatch与其他模型在跨数据集协议中的性能差异比在数据集内和混合数据集协议中的更明显。这一现象表明，NAM模块在多标签分类中比固定或动态阈值策略更有效地进行伪标签精炼，特别是在未见数据集上。此外，我们注意到，ECGMatch的性能优于PercentMatch和UPS，这些是最新设计用于半监督多标签学习的模型。这个观察表明，捕捉标注和未标注样本中的标签关系有利于多标签分类，而这一属性在上述两个竞争对手中被忽略了。关于每个组件贡献的更多详细信息在下一个小节中列出。总之，不同协议中的显著改进表明所提ECGMatch在各种临床应用中具有潜力。

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/f4d3fdc4304a4b7ca36e75262d72a491.png)



### B. 消融研究

为了定量评估ECGMatch中不同模块的贡献，我们依次去除其中一个模块，并使用三种既定协议评估模型性能。表V、VI和VII报告了不同实验协议下的消融研究结果。

1. 当去除伪标签生成模块 $(\lambda_u = 0)$ 时，所提模型在所有实验协议中的性能下降，表明引入伪标签用于半监督学习的优势。例如，在数据集内协议（表V）中，Chapman数据集上的汉明损失从 $0.139 \pm 0.002$ 增加到 $0.163 \pm 0.009$，而MAP从 $0.775 \pm 0.014$ 下降到 $0.761 \pm 0.010$。特别注意，当参数 $\lambda_u$ 设置为零时，随后的精炼模块也被禁用。
2. 从结果中观察到去除伪标签精炼模块的显著负面影响。在跨数据集协议（表VI）中，Chapman数据集上的汉明损失从 $0.219 \pm 0.003$ 增加到 $0.242 \pm 0.007$，而MAP从 $0.748 \pm 0.004$ 下降到 $0.732 \pm 0.006$。这一现象表明，在损失计算中增加可信伪标签的重要性大大提高了模型性能。
3. 比较去除和不去除标签相关性对齐模块 $(\lambda_f = 0)$ 的结果，当去除该模块时观察到显著的性能下降。在混合数据集协议（表VII）中，汉明损失从 $0.270 \pm 0.001$ 增加到 $0.282 \pm 0.010$，而MAP从 $0.658 \pm 0.006$ 下降到 $0.640 \pm 0.010$。这一现象表明，捕捉不同类别之间的相关性是有益的，这在其他多标签学习研究中也有报道。

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/aa1766ab7c644152aa05b215ad4f7961.png)



### C. 不同增强策略的比较

在本节中，我们进一步调查了ECGAugment模块在ECG信号增强中的有效性。使用上述协议，我们比较了ECGAugment与先前研究中提出的固定顺序扰动的性能。遵循他们的设置，我们对小批量的ECG记录应用两个连续的高斯扰动进行强增强，一个高斯扰动进行弱增强。跨四个数据集的平均性能如图2所示，可以观察到由于ECGAugment带来的显著性能提升。对于评价指标越小越好，雷达图中的蓝色区域（ECGAugment）被红色区域（固定顺序扰动）包围。相反，对于指标越大越好，蓝色区域覆盖红色区域。这些现象表明，所提ECGAugment在下游分类任务中的优越性。换句话说，它通过增强数据增强中的随机性增加样本多样性，从而提高模型性能。

### D. 统计分析

为了统计分析ECGMatch与其他SOTA模型之间的性能差异，我们采用了常用的Friedman检验和事后Bonferroni-Dunn检验。按照上述检验的流程，我们使用不同模型在数据集内协议和跨数据集协议中的性能进行比较。表VIII展示了Friedman统计量 $F_F$ 和每个指标的相关临界值（比较模型 $k = 8$，数据集 $N = 4$）。根据结果 $(F_F > 3.2590)$，我们可以拒绝在0.05显著性水平下比较模型没有显著性能差异的零假设。然后应用事后Bonferroni-Dunn检验描述控制模型（ECGMatch）与其他模型之间的性能差距。对于每个评价指标，我们计算所有模型在四个数据集上的平均排名，并确定控制模型与比较模型之间的排名差异。注意，表现最好的模型被分配为1名，表现第二好的模型为2名，依此类推。如果在我们的实验中，控制模型（ECGMatch）与比较模型之间的排名差异大于一个临界差异 $(\text{CD} = 4.6592)$，则控制模型显著优于比较模型。图3展示了不同模型在不同评价指标上的平均排名。显然，所提ECGMatch在所有指标上排名最佳，并在0.05显著性水平上优于一些竞争对手，如MixMatch、DST和SoftMatch。总之，这些统计结果证明了所提ECGMatch的优越性。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/da6775e65aa24bb88c721fba7230590a.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/37b3270af3b24e0d97cb9f439d9ebb95.png)





### E. 灵敏度分析

在本节中，我们使用网格搜索方法研究不同超参数对所提模型性能的影响。为简洁起见，我们只关注公式（12）中的两个关键超参数 $\lambda_u$ 和 $\lambda_f$。具体来说， $\lambda_u$ 控制无监督二元交叉熵损失 $L_u$ 的权重， $\lambda_f$ 控制标签相关性对齐损失 $L_f$ 的权重。在网格搜索过程中，我们调整超参数的值，并使用不同的评估协议评估四个数据集的平均模型性能。首先，我们将 $\lambda_u$ 固定在0.8，并将 $\lambda_f$ 从0调整到1.6，步长为0.4。然后，我们将 $\lambda_f$ 固定在0.8，并以相同的方式调整 $\lambda_u$。如图4所示，所提ECGMatch在每个评价指标上的性能对两个超参数的变化相对不敏感，这表明其在临床应用中的稳定性。

### F. 标注样本比例的影响

SSL模型的性能受标注样本与训练样本总数比例的影响。我们在模型训练过程中调整比例，并研究ECGMatch是否能比其他模型减少标注样本的需求。为简洁起见，我们展示跨数据集协议的实验结果如图5所示。其他协议的结果见在线附录D。比较比例为0.05和0.01下的模型性能，我们可以观察到ECGMatch在减少所需标注样本5％的同时，在所有六个指标上实现了与其他模型相当的性能。这一现象验证了所提ECGMatch在减少模型训练期间对人工注释需求方面的效率。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/3719eee7d8ab46808d33d57bc67e716a.png)




### G. 不同注释方案的影响

在本节中，我们使用另一种注释方案进行实验，以进一步验证所提ECGMatch的优越性能。具体来说，使用PTB-XL数据库的方案进行模型训练和评估。该方案将CVDs分类为四个超类：传导障碍、ST/T异常、心肌梗死和肥厚。具有窦性心律的记录被分类为正常记录。由于心肌梗死和肥厚在PTB-XL数据库中占主导地位，我们采用数据集内协议评估模型在该数据库上的性能，并在表IX中展示结果。可以观察到，所提ECGMatch相比于最先进的模型取得了优越性能。例如，ECGMatch将MAP从 $0.688 \pm 0.007$ 提高到 $0.705 \pm 0.002$，将排名损失从 $0.144 \pm 0.007$ 降低到 $0.130 \pm 0.003$。在在线附录E中，我们报告了使用Cinc2020/2021挑战采用的注释方案的实验结果，所提ECGMatch在不同注释方案中均表现优异。基于上述实验，我们可以得出结论，所提ECGMatch在不同CVDs预测任务中的不同注释方案下均表现优越，证明了其鲁棒性。


![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/85bc74b8e8114620ada7c44ba76040fa.png)



## VI. 结论

在本研究中，我们指出了基于ECG的CVDs预测中的三个重要现实挑战：1）标签稀缺问题。2）在未见数据集上的表现不佳。3）多种CVDs的共现。为了同时解决这些挑战，我们提出了一个新框架（ECGMatch），结合了数据增强、伪标签学习和标签相关性对齐模块，形成了一个统一的框架。此外，我们重新注释了四个公共数据集，并提出了三个实用的实验协议以进行所提模型的多数据集评估。在三个协议和四个数据集上的广泛实验令人信服地证明了所提模型相对于其他SOTA模型的优越性。我们相信所提ECGMatch可以为未来基于ECG的CVDs预测研究提供可靠的基准。然而，ECG数据集中的类别不平衡问题仍然是一个重大挑战。因此，我们倡导未来在这一持续问题上的研究。
声明
本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
