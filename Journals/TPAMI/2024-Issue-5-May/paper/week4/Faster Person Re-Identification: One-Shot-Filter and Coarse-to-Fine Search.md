# [Faster Person Re-Identification: One-Shot-Filter and Coarse-to-Fine Search](https://ieeexplore.ieee.org/document/10354027/)
## 题目：更快的人员再识别：单次过滤和粗到细搜索  
**作者：Guan’an Wang; Xiaowen Huang; Shaogang Gong; Jian Zhang; Wen Gao**  

****
# 摘要
快速的人物重识别（ReID）旨在快速准确地搜索人物图像。最新的快速ReID方法的主要思想是哈希算法，该算法学习紧凑的二进制代码，并执行快速的汉明距离和计数排序。然而，为了实现高准确性（例如，2048位），需要非常长的代码，这影响了搜索速度。在这项工作中，我们通过提出一种新的 Coarse-to-Fine (CtF) 哈希代码搜索策略，引入了一种新的快速ReID解决方案，该策略互补地使用长短代码，实现了更快的速度和更高的准确性。它使用较短的代码粗略地排列广泛的匹配相似性，使用较长的代码只细化少数顶级候选项，以实现更准确实例ReID。具体来说，我们设计了一个集成所有（AiO）模块以及一个距离阈值优化（DTO）算法。在AiO中，我们在一个单一模型中同时学习并增强不同长度的多个代码。它以金字塔结构学习多个代码，并鼓励较短的代码通过自我蒸馏模仿较长的代码。DTO通过一个简单的优化过程解决了复杂的阈值搜索问题，并且通过单个参数轻松控制准确性和速度之间的平衡。它将优化目标制定为可以通过高斯累积分布函数优化的Fβ分数。此外，我们发现即使短代码（例如，32位）在大规模图库下由于O(n)时间复杂度仍然需要很长时间。为了解决这个问题，我们提出了一种基于潜在属性的画廊尺寸无关的一次性筛选（OSF）策略，始终具有O(1)时间复杂度，可以快速过滤大部分容易的负图库图像。具体来说，我们设计了一个潜在属性学习（LAL）模块，受单向度量（SDM）损失监督。LAL源自主成分分析（PCA），它使用最短的特征向量保持最大的方差，同时启用批量和端到端学习。每个特征向量的logit代表一个有意义的属性。SDM是为细粒度属性监督精心设计的，性能优于常见的欧几里得和余弦度量。实验结果在2个数据集上显示CtF+OSF不仅准确度提高了2%，而且速度提高了5倍。

# 关键词
- 人物重识别
- 哈希
- 粗到细
- 潜在属性
- 一次性筛选
- 计算机视觉
- 深度学习


# I. 引言

人再识别（ReID）[1]、[2]、[3]旨在匹配不同摄像头下同一人的图像，它在视频监控、安全和智能城市中有广泛的应用。许多方法[2]、[4]、[5]、[6]、[7]、[8]、[9]、[10]、[11]已被提出用于人ReID。然而，为了获得更高的准确性，它们中的大多数使用大型深度网络来学习用于通过欧几里得距离计算相似性的高维实值特征，并通过对快速排序[12]返回排名列表。当图库集很大时，高维深度特征的快速排序可能会很慢。表I显示，随着ReID图库大小的增加，每个ReID探针图像的查询时间大幅增加；并且计数排序[13]比快速排序更有效率，前者具有与图库大小成线性关系的时间复杂度(O(n))，而后者具有对数复杂度(O(nlogn))。

为了在保持ReID准确性的同时提高ReID速度，已经提出了几种快速ReID方法[14]、[15]、[16]、[17]、[18]、[19]、[20]、[21]。这些方法的共同主要思想是散列算法，它学习二进制代码而不是实值特征。为了对二进制代码进行排序，用哈明距离和计数排序[13]取代了低效的欧几里得距离和快速排序。表II显示，计算2048维二进制代码之间的哈明距离比计算实值特征之间的欧几里得距离快229倍。

与常见的图像检索任务不同，后者是在封闭集上的类别级匹配，ReID是在开放集（零样本设置）上的实例级匹配。在ImageNet[22]中的图像检索中，训练集和测试集的类别是相同的，不同类别的图像外观差异很大，例如狗、汽车和飞机。相比之下，训练和测试ReID图像具有完全不同的ID类别，没有任何重叠（零样本学习），而不同人的外观可能非常相似，对服装、身体特征、性别和携带物品的微小变化（细粒度）很敏感。ReID的零样本学习和细粒度特性要求最先进的基于哈希的快速ReID模型[21]使用非常长的二进制代码，例如2048，以保持竞争性的ReID准确性。

然而，二进制代码的长度显著影响计算哈明距离的成本。表II显示，计算两个2048维二进制代码之间的哈明距离需要1.7×10^−5秒，比计算32维二进制代码的2.4×10^−6秒慢7倍。这激发了我们解决以下问题：如何使用较短的二进制代码从基于哈希的ReID中获得更高的准确性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/da24135b94484d3081754e1a4b245921.png" width="70%" /> </div>


为此，我们提出了一种新的Coarse-to-Fine（CtF）搜索策略，用于更快的ReID，同时保持竞争性的准确性。在测试时，我们的模型(CtF)首先使用较短的代码粗略地对图库进行排名，然后迭代地使用较长的代码进一步对选定的顶级候选项进行排名，其中顶级候选项由一组哈明距离阈值迭代定义。因此，长代码只用于越来越少的匹配项进行排名，以减少整体搜索时间，同时保持ReID准确性。这是一个直观简单的想法，但由于三个困难，对于ReID来说并不容易计算：(1) Coarse-to-fine搜索需要不同长度的多个代码。不对称地，使用多个模型计算它们既耗时又次优。(2) 粗略排名必须足够准确，以最小化在细粒度排名中错过真实匹配候选项的同时，保持它们的数目很小，从而减少总搜索时间。矛盾的是，较短的代码在ReID任务中的表现远不如较长的代码，因此很难足够准确。(3) 用于指导粗略搜索的距离阈值集合影响最终准确性和整体速度。如何自动确定这些阈值以最佳地平衡准确性和速度既重要又非平凡。

在这项工作中，我们提出了一种新颖的All-in-One(AiO)模块以及Distance Threshold Optimization(DTO)算法，以同时解决这三个问题。AiO模块可以在同一模型中同时学习并增强不同长度的多个代码。它以金字塔结构逐步学习多个代码，其中底部长代码的知识由顶部短代码共享。我们通过概率和相似性蒸馏促使较短的代码模仿较长的代码。这使得较短的代码更强大，而无需引入额外的教师网络。DTO算法通过一个简单的优化过程解决了复杂的阈值搜索问题，搜索准确性和速度之间的平衡可以很容易地由一个单一参数控制。它将优化目标制定为可以通过高斯累积分布函数优化的Fβ分数。这样，我们可以通过高斯概率分布的统计量来估计其参数，这些分布模拟了正负对的距離。最后，通过最大化Fβ分数，我们可以迭代地计算最优的距离阈值。

尽管所提出的粗到细（Coarse-to-Fine, CtF）策略通过减少距离计算显著加快了检索速度，但它仍然需要计算短代码之间的距离。具体来说，计算m个查询和n个图库图像之间距离的时间复杂度为O(mn)。当m和n非常大时，这也会影响检索速度。上述讨论启发我们寻找一种可以完全避免距离计算的方法，从而将复杂度大幅降低到O(1)。一个直观的想法是通过语义属性（如衣服颜色、携带物品、性别）进行检索。构建一个查找表，其中键是属性，值是相应的图像。这样，基于排名的检索升级为基于索引的检索。我们称这种方法为一次性过滤器（One-Shot-Filter, OSF），它的流程如图2所示。然而，这个解决方案要求准确且可泛化的语义属性预测，这在实际中并不总是可行的。此外，训练一个属性模型代价也很高。另一个解决方案是使用图像特征向量中的logit作为属性。例如，一个2048维的特征向量可能表示2048个属性。然而，常见的嵌入层（如线性层）[23]和身份损失[2]、[10]导致密集知识（庞大且细粒度的特征）和双向激活特征。属性更倾向于稀疏知识（少数但重要的特征）和单向属性（真或假）。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/2ff7ce6f2bef468db1cc82a2cbbbd434.png" width="70%" /> </div>


为了克服上述挑战，我们提出了一个新颖的潜在属性学习（Latent Attribute-Learning, LAL）模块以及单向度量（Single-Direction-Metric, SDM）损失。LAL源自主成分分析（PCA），它使用最短的特征向量保持最大方差（重要特征），同时实现批量和端到端学习。每个特征向量的logit代表一个有意义的属性。SDM是精心设计的，用于细粒度属性监督，性能优于常见的欧几里得和余弦度量。它基于Jaccard度量，并通过梯度计算提供支持。

我们的贡献可以总结如下，简要版本显示在表III中。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/cb5c9881d8cb4b819c768721a9ffbceb.png" width="70%" /> </div>


1) 我们提出了一种新颖的ReID方法，可以在保持准确性的同时加快检索速度。它由两个主要策略组成，即Coarse-to-Fine（CtF）和One-Shot-Filter（OSF）。CtF利用长短码混合搜索，OSF将基于排名的检索升级为基于索引的检索。给定一个查询，OSF首先过滤掉非常容易的负样本图库，然后CtF对剩余的图库样本进行排名。

2) Coarse-to-Fine（CtF）策略包括一个All-in-One（AiO）模块和一个Distance Threshold Optimization（DTO）算法。AiO模块在金字塔结构中学习不同长度的多个代码，并通过概率和相似性蒸馏损失来增强它们。DTO算法通过将阈值搜索任务归结为Fβ距离优化问题，找到最佳的粗到细搜索阈值。

3) One-Shot-Filter（OSF）策略由一个Latent Attribute-Learning（LAL）模块和一个Single-Direction-Metric（SDM）损失组成。LAL模块仅使用身份标签而不是属性标签自动学习潜在属性。它源自主成分分析（PCA），并支持批量和端到端学习。SDM损失是基于Jaccard度量的IOU类度量，由梯度计算提供支持，性能优于常见的欧几里得和余弦度量。

4) 在Market-1501和DukeMTMC-ReID数据集上的广泛实验结果表明，我们提出的CtF比非哈希ReID方法快50倍，比哈希ReID方法快5倍，准确度高2%。OSF进一步将CtF的速度提高了2倍，总体上提高了10倍，几乎没有准确度下降。MSMT上的实验也验证了其在大规模数据集上的有效性。此外，在不同基线上的实验显示了其对不同骨架的可扩展性。

# III. 提出的方法

在本文中，我们提出了一种新颖的快速Re-ID方法，旨在实现快速准确的Re-ID，其中包括两个核心思想，即一次性筛选（One-Shot-Filter, OSF）和粗到细（Coarse-to-Fine, CtF）搜索策略。前者利用属性过滤大部分简单的负样本图库。为了灵活准确地学习属性，我们提出了一个潜在属性学习（Latent-Attribute-Learning, LAL）模块以及单向度量（Single-Direction-Metric, SDM）损失，无需手动注释即可学习。后者使用长短混合的二进制代码有效搜索剩余的图库样本。我们设计了一个集成一体（All-in-One, AiO）模块以及距离阈值优化（Distance Threshold Optimization, DTO）算法。AiO模块在单一模块中学习并增强不同长度的多个代码。后者以时间复杂度O(1)找到平衡时间和准确性的最佳距离阈值。CtF将Re-ID的速度提高了5倍，OSF进一步将CtF的速度提高了2倍，最终达到了10倍的速度提升。

## A. 粗到细搜索

正如我们在引言部分所阐述的，尽管长二进制代码可以获得高准确度，但其耗时远长于短代码。这激发了我们的思考，是否可以减少长代码的使用，进一步加快哈希Re-ID方法的速度。因此，一个简单但有效的解决方案是补充使用长短代码。在这里，较短的代码快速返回图库的粗略排名列表，而较长的代码仔细地细化少数顶级候选。图1展示了它的程序。尽管这个想法很直接，但正如第I节第4段所讨论的，有三个困难阻碍了这个想法。为了解决这些问题，我们提出了一个集成一体（AiO）模块和一个距离阈值优化（DTO）算法。请参阅接下来的两部分以获取更多详细信息。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/7bcca18e78b842e8be6f062110f35b97.png" width="70%" /> </div>


*1) 集成一体模块：* 集成一体（All-in-One, AiO）模块的目标是同时学习并增强不同长度的多个代码。其架构如图3所示。具体来说，它首先使用卷积网络提取实值特征向量，然后在金字塔结构中学习不同长度的多个代码，最终通过自我蒸馏学习增强代码。自我蒸馏学习鼓励较短的代码模仿较长的代码。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/ad0396b1cbb849f29faad10cc9aa5872.png" width="70%" /> </div>

*学习金字塔结构中的多个代码：* 代码金字塔学习不同长度的多个代码，其中较短的代码基于较长的代码。有了这样的结构，我们不仅可以一次性学习多个代码，还可以共享较长代码的知识给较短的代码。公式如下：

$$
v_0 = F(x), \quad v_k = F_{Ck}(v_{k-1}), \quad k \in \{1, 2, ..., N\},
$$

其中 $x$ 是输入图像， $F$ 是CNN主干网络， $N$ 是代码数量， $V = \{v_k\}_ {k=1}^{N}$ 是具有不同长度 $L = \{l_k\}_ {k=1}^{N}$ 的实值特征向量集合， $F_{Ck}$ 是全连接层，其输入大小为 $l_{k-1}$ ，输出大小为 $l_k$ 。获得不同长度的实值特征后，我们可以通过以下公式获得它们的二进制代码 $B = \{b_k\}_{k=1}^{N}$ ：

$$
b_k = \text{sign}(\mathbf{b}_n(v_k)),
$$

其中 $\mathbf{b}_n$ 是批量归一化层， $\text{sign}$ 是符号函数。我们使用批量归一化层是因为它将实值特征归一化至对称于0，并减少量化损失。

*通过自我蒸馏学习增强代码：* 正如我们在引言部分讨论的，粗略排名必须足够准确，以最小化在细粒度排名中错过真实匹配候选项的同时，保持它们的数目很小，从而减少总搜索时间。受[39]、[40]的启发，我们引入自我蒸馏学习，以不引入额外教师网络的情况下，在单一网络中增强多个代码。与传统的蒸馏模型不同，传统模型引入一个额外的大型教师网络来指导小型学生网络，我们在单一网络中执行蒸馏学习，并实现更好的性能，这对于快速Re-ID很重要。

具体来说，我们的自我蒸馏学习由概率蒸馏和相似性蒸馏组成。概率蒸馏以软化的类分数形式传递实例级知识。其公式如下：

$$
L_{\text{pro}} = \frac{1}{N-1} \sum_{k=1}^{N-1} L_{\text{ce}}(\sigma(z_{k+1} / T), \sigma(\hat{z}_k / T)),
$$

其中 $L_{\text{ce}}(\cdot, \cdot)$ 表示交叉熵损失， $\sigma$ 是softmax函数， $\hat{z}_ k / z_{k+1}$ 表示二进制代码 $b_k / b_{k+1}$ 的输出logits， $\hat{z}$ 表示它作为教师网络固定在训练期间， $T$ 是温度超参数，经验上设置为1.0。相似性蒸馏将较长代码与较短代码之间的关系知识传递，其公式如下：

$$
L_{\text{sim}} = \frac{1}{N-1} \sum_{k=1}^{N-1} \sum_{i,j} || \frac{1}{l_{k+1}} G_{i,j}^{k+1} - \frac{1}{l_k} \hat{G}_{i,j}^k ||^2,
$$

其中 $G_{i,j}^k / G_{i,j}^{k+1}$ 是 $b_i^k / b_i^{k+1}$ 和 $b_j^k / b_j^{k+1}$ 之间的汉明距离， $b_i/j^k/k+1$ 是图像 $x_i/x_j$ 的二进制代码，长度为 $l_k/l_{k+1}$ ， $\hat{G}$ 表示G作为标签固定在优化过程中，因此对梯度没有贡献。

*总体目标函数和训练：* 最近在Re-ID方面的进展显示了分类[2]和三元组[10]损失的有效性。因此，我们的最终目标函数包括我们提出的概率和相似性蒸馏损失以及分类和三元组损失作为最终目标函数。公式如下：

$$
L_{ctf} = L_{\text{ce}} + L_{\text{tri}} + \lambda_{\text{prob}} L_{\text{pro}} + \lambda_{\text{sim}} L_{\text{sim}}.
$$

考虑到映射函数sgn在(2)中是离散的，汉明距离在(2)中不可微，自然地在(5)中使用[36]的松弛方法，通过替换sgn为tanh并将汉明距离更改为内积距离。最后，我们的集成一体模块可以通过最小化(5)中的损失以端到端的方式进行优化。


*2) 距离阈值优化：* 在获得不同长度的多个代码 $B = \{b_i\}_ {i=1}^{N}$ 之后，我们可以执行粗到细（CtF）搜索。CtF搜索有两个要点，即高准确性和快速度。为了快速度，粗略搜索返回的候选数量应该很小。为了高准确性，粗略搜索返回的候选应该尽可能多地包含相关图像。但这两个要求自然矛盾。因此，找到适当的阈值以最佳地平衡这两个目标——即高准确性和快速度——是重要的。一个简单的解决方案是通过交叉验证进行暴力搜索。然而，搜索空间太大。例如，如果我们有多个长度为 $L = \{l_k\}_ {k=1}^{N}$ 的二进制代码，暴力搜索的复杂度将是 $\prod_{l > 4} 10^9$ 次。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/e77a32ae5c9648c88cb196e676867a18.png" width="70%" /> </div>

在这部分，我们提出了一种新颖的距离阈值优化（DTO）算法，它通过一个简单的优化过程解决了耗时的暴力参数搜索任务。具体来说，受到[41]的启发，我们首先明确地将两个子目标制定为(6)中的两个分数，即精确度（P）和召回率（R）分数。然后我们通过单一参数β混合这两个分数，得到(6)中的Fβ分数。

$$
P = \frac{TP}{TP + FP}, \quad R = \frac{TP}{TP + FN}, \quad F_{\beta} = \frac{(\beta^2 + 1) PR}{\beta^2 P + R}
$$

这里，TP是候选中相关图像的数量，FP是候选中非相关图像的数量，FN是未检索到的相关样本数量。如我们所见，精确度分数P表示候选中相关图像的比率。通常，高P意味着候选数量小，这对快速度有利。召回率分数R表示检索到的相关样本在总相关样本中的比率。高R分数意味着检索到更多相关样本，这对高准确性很重要。Fβ通过参数β混合了精确度和召回率分数，同时考虑了速度和准确性。

$$
PDF(t) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(t - \mu)^2}{2\sigma^2}}, \quad CDF(t) = \frac{1}{2} \left[ 1 + \text{erf}\left(\frac{t - \mu}{\sigma \sqrt{2}}\right) \right]
$$

$$
F_{\beta} = \frac{CDF_r(\beta^2 + 1)}{CDF_n + CDF_r + \beta^2(1 - CDF_n + CDF_r)}
$$

考虑到TP/FP/FN是不可优化的统计数据，我们用两个高斯累积分布函数的形式(7)（右）替换它们，其参数μ和σ通过使用(7)（左）中的高斯概率分布函数拟合验证集来估计。最后，通过最大化(8)中的Fβ，我们可以得到由β平衡的最佳距离阈值 $T = \{t_k\}_{k=2}^{N}$ 。

*3) CtF的总结：* 在训练阶段，我们最小化(5)中的 $L_{ctf}$ 。在测试阶段，细节总结在算法2中。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/a97fbb63945243d38369af0766889a5c.png" width="70%" /> </div>


## B. 一次性筛选（One-Shot Filter）

如引言部分所述，尽管粗到细（Coarse-to-Fine, CtF）搜索策略显著提升了检索速度并保持了高准确度，它在距离计算上仍然具有O(mn)的时间复杂度，这里m和n分别是查询和图库的大小。这促使我们寻找一种可以完全避免总距离计算，并获得O(1)时间复杂度的方法。

一个直观的想法是将基于排名的检索问题升级为基于索引的检索问题，其中可以构建查找表，并自然地利用一些先进的数据库（如Oracle, MySQL）来加快检索速度。例如，给定一个男性查询，可以过滤掉所有女性图像。然而，这个想法需要准确且可泛化的属性预测，这限制了它的灵活性。因此，需要大量的属性注释。另一种选择是将身份特征向量中的每个logit视为潜在属性。例如，一个2048维的特征向量可能表示2048个属性。然而，现有的Re-ID模型在欧几里得和余弦度量下学习身份特征，这不适合属性表示。前者用密集特征（例如2048维）表示细粒度信息（如纹理），而属性则更倾向于稀疏知识（几个但显著的特征）和单向属性（真或假）。

为解决上述问题，我们提出了一个潜在属性学习（Latent-Attribute-Learning, LAL）模块和单向度量（Single-Direction-Metric, SDM）损失。前者将潜在属性学习问题形式化为球面上的特征分解过程，自然得到稀疏、主成分和可解释的潜在属性。后者在Jaccard度量下优化潜在属性，性能优于常见的欧几里得或余弦度量。

*1) 潜在属性学习模块（Latent-Attribute Learning Module）：* 潜在属性学习（LAL）模块源自主成分分析（PCA）。我们首先回顾PCA，然后将其适应到我们的任务中。

*回顾主成分分析（PCA）*：PCA定义为一个正交线性变换，它将数据变换到新坐标系统中，使得数据的一些标量投影在第一坐标（称为第一主成分）上的最大方差，第二大方差在第二坐标上，依此类推。PCA的公式如下：

$$
X_{\text{out}} = X_{\text{in}} U^T \quad \text{s.t.} \quad \Lambda = U \Sigma U^T, \quad I = U U^T
$$

其中， $X_{\text{in}} \in \mathbb{R}^{n \times dl}$ 是一组零均值特征，具有长维度， $X_{\text{out}} \in \mathbb{R}^{n \times ds}$ 是一组具有短维度的特征， $\Sigma \in \mathbb{R}^{dl \times dl}$ 是长特征的协方差， $U \in \mathbb{R}^{ds \times dl}$ 是前ds个特征向量， $\Lambda \in \mathbb{R}^{ds \times ds}$ 是对角矩阵，其对角元素为特征值，非对角元素为零。

*适应批量学习与移动平均协方差*：受PCA启发，PCA将多个长特征减少到多个短特征的同时保持最大方差，短特征向量可以被视为多个潜在属性logits，而U可以被视为潜在属性ds。然而，U是根据全局统计量Σ后计算的，这无法处理端到端优化和批量训练。在这部分，我们提出了一个新颖的潜在属性学习（LAL）模块来学习潜在属性，它保持最少的属性，端到端可优化，批量可训练。LAL模块在两个关键改进上做出了贡献：(1) 通过用可训练函数 $U_\theta(\Sigma)$ 替换U，实现端到端优化；(2) 通过使用移动平均协方差 $\Sigma = \eta \Sigma + (1 - \eta) \Sigma_{\text{batch}}$ ，其中η经验设置为0.9，实现批量训练。

*适应端到端学习与可训练的特征向量*：LAL模块的详细结构如图4所示。它包括零均值部分、移动平均协方差部分和特征向量学习部分。零均值部分ZeroMean由一个线性层（从2048维到512维）、一个不可训练的批量归一化层（权重和偏置分别设置为1和0）以及一个归一化层组成，该层将每个特征归一化为范数1。移动平均协方差部分首先在批量内计算协方差 $\Sigma_{\text{batch}}$ ，然后使用策略 $\Sigma = \eta \Sigma + (1 - \eta) \Sigma_{\text{batch}}$ 计算移动平均协方差。特征向量学习部分使用函数 $U_\theta(\cdot)$ ，它包括一个线性层、一个批量归一化层、一个带有比例0.1的leakyReLU层和一个线性层。它根据移动平均协方差预测特征向量，即 $U = U_\theta(\Sigma)$ 。此外，使用ReLU层将值限制为始终为正。LAL模块的最终公式如下：

$$
X_{\text{out}} = \text{ReLU}(\text{ZeroMean}(X_{\text{in}}) U_\theta(\Sigma)^T) \quad \text{s.t.} \quad \Sigma = U_\theta(\Sigma)^T \Lambda_\Phi U_\theta(\Sigma), \quad I = U_\theta(\Sigma) U_\theta(\Sigma)^T,
$$

其中 $\Lambda_\Phi$ 是一个方阵，其对角元素是可训练的，其余元素为零。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/313341e1298f475fb3ee25d9d4f0ce51.png" width="70%" /> </div>


*目标函数的LAL模块*：最终的LAL模块将两个约束转换为两个损失，包括一个身份损失 $L_{\text{identi}}$ 和一个正交性损失 $L_{\text{orth}}$ 。

$$
L_{\text{identi}} = ||I - U_\theta(\Sigma) U_\theta(\Sigma)^T||^2, \quad L_{\text{orth}} = ||\Sigma - U_\theta(\Sigma)^T \Lambda_\Phi U_\theta(\Sigma)||^2.
$$

*讨论*：所提出的LAL模块源自主成分分析（PCA），并通过批量学习和可训练的特征向量能力得到增强。批量学习能力类似于增量PCA[42]，它增量地估计顶部特征向量。然而，增量PCA仍然以统计方式计算特征向量，这是不可微分的，无法应用到深度学习流水线中。我们提出的LAL模块专门设计用于深度学习流水线中的潜在属性学习，并且提出了一种新颖的单向度量损失，这保证了其可以通过随机梯度下降进行优化。

*2) 单向度量损失（Single-Direction-Metric Loss）：*LAL模块想要学习潜在属性。然而，现有的度量（例如，欧几里得、余弦）无法处理属性，属性需要类似IOU的度量。这里，我们使用Jaccard相似性来度量属性，并通过改进使其成为端到端版本。这部分受到[43]、[44]的启发，并改进以适应人物Re-ID三元组损失。

*回顾Jaccard相似性*：Jaccard相似性用于测量两个集合。定义为两个集合交集的大小除以并集的大小。给定两个集合A和B，Jaccard相似性使用以下公式计算：

$$
J(A, B) = \frac{|A \cap B|}{|A \cup B|},
$$

其中 $| \cdot |$ 表示集合的基数。使用C维二进制向量{0,1}^C表示集合A和B，其中每个通道表示一个特定属性，1表示激活的属性，0表示未激活的属性，这两个集合之间的Jaccard相似性通过以下公式计算：

$$
J(A, B) = \frac{\sum_{c=1}^{C} A[c] \land B[c]}{\sum_{c=1}^{C} A[c] \lor B[c]},
$$

其中 $\land$ 和 $\lor$ 表示逻辑与和逻辑或运算符，运算符 $[\cdot]$ 返回属性集在位置c的元素。为了使Jaccard相似性适应连续变量，我们使用最小化和最大化来分别近似(14)中的按位与和或运算符。对于给定的两个属性集合g1和g2，Jaccard相似性被重新定义为：

$$
J(g_1, g_2) = \frac{\sum_{c=1}^{C} \min(g_1[c], g_2[c])}{\sum_{c=1}^{C} \max(g_1[c], g_2[c])},
$$

其中c表示属性索引。此外，为了平滑最小/最大运算符，我们引入了Softmax-Jaccard相似性：

$$
J(g_1, g_2) = \frac{\sum_{c=1}^{C}(w_{\text{min},1}[c] \cdot g_1[c] + w_{\text{min},2}[c] \cdot g_2[c])}{\sum_{c=1}^{C}(w_{\text{max},1}[c] \cdot g_1[c] + w_{\text{max},2}[c] \cdot g_2[c])},
$$

$$
w_{\text{min},k}[c] = \frac{e^{-\tau \cdot g_k[c]}}{\sum_{n=1}^{N} e^{-\tau \cdot g_n[c]}}, \quad w_{\text{max},k}[c] = \frac{e^{\tau \cdot g_k[c]}}{\sum_{n=1}^{N} e^{\tau \cdot g_n[c]}},
$$

其中， $w_{\text{min},k}/c$  和  $w_{\text{max},k}/c$ 分别是 gk[c] 沿 k（k = 1, 2, ..., N，N 是批量大小）的 softmin/softmax。τ是平滑因子。

*归一化*：为了保持 Js(·, ·) 在 [0, 1] 范围内，我们在计算 gi 和 gj 时对 wmin_k/wmax_k 进行归一化：

$$
w_{\text{min},i}[c] = \frac{w_{\text{min},i}[c]}{R_{\text{min}}}, \quad w_{\text{min},j}[c] = \frac{w_{\text{min},j}[c]}{R_{\text{min}}}, \quad \text{s.t.} \quad R_{\text{min}} = w_{\text{min},i}[c] + w_{\text{min},j}[c],
$$

$$
w_{\text{max},i}[c] = \frac{w_{\text{max},i}[c]}{R}, \quad w_{\text{max},j}[c] = \frac{w_{\text{max},j}[c]}{R_{\text{max}}}, \quad \text{s.t.} \quad R_{\text{max}} = w_{\text{max},i}[c] + w_{\text{max},j}[c].
$$

*单向度量（SDM）损失*：SDM损失定义在下面的公式中，其中 gn 表示样本 xn 的属性，gn- 是 xn 的负样本属性，gn+ 属于 xn 的正样本属性，δ 是一个边界参数。

$$
L_{\text{sdm}} = \sum_{n=1}^{N} [\delta + J(gn, gn^+) - J(gn, gn^-)]^+,
$$

*OSF的总结：*本节总结了(19)中的训练和测试细节。

*训练阶段*：在训练阶段，所提出的一次性筛选（One-Shot-Filter, OSF）策略的总体目标函数如下，其中λ*是相应的权重。

$$
L_{\text{osf}} = \lambda_{\text{sdm}} L_{\text{sdm}} + \lambda_{\text{identi}} L_{\text{identi}} + \lambda_{\text{orth}} L_{\text{orth}}.
$$

*测试阶段*：在测试阶段，如算法3所示，OSF包括两个步骤：(1) 离线构建潜在属性查找表；(2) 在线使用潜在属性查找表过滤负样本。具体来说，给定一个训练好的潜在属性学习（LAL）模块(10)，一个查询数据 xq，一组图库数据 $X_g = \{x_i\}_{i=1}^{N_g}$ 和过滤阈值 γ，OSF首先构建一个查找表，其键是属性索引，值是相应的图库数据索引。查找表只初始化一次，并在所有查询中重复使用。然后，给定一个查询数据，OSF提取其属性向量，选择置信度最高的 γ 个属性，并找到拥有所有 γ 个激活属性的图库数据。γ 是一个超参数，用于平衡准确性和速度。较大的 γ 会过滤掉更多的负图像，有助于提高速度，但可能会丢弃更多的正样本，损害准确性。相反，较小的 γ 在保持准确性的同时牺牲了速度的提升。我们通过交叉验证将 γ 设置为 1。
<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/038f1122b66841b3bb38ca4dd337137d.png" width="70%" /> </div>
## C. 总体框架

我们提出的总体框架如图5所示。一个卷积神经网络（CNN）模块联合全局平均池化（GAP）提取输入图像的特征向量。随后，两个分支，即AiO和LAL，连同相应的损失学习二进制代码和潜在属性。其目标函数如下所示：

$$
L = L_{\text{ce}} + L_{\text{tri}} + \lambda_{\text{prob}} L_{\text{prob}} + \lambda_{\text{sim}} L_{\text{sim}} + \lambda_{\text{sdm}} L_{\text{sdm}} + \lambda_{\text{identi}} L_{\text{identi}} + \lambda_{\text{orth}} L_{\text{orth}}. \quad (20)
$$

在测试阶段，给定一个查询图像和一组图库图像，首先使用OSF过滤掉主要的简单负样本，然后CtF逐步使用混合长短代码对剩余的图库样本进行排名。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/c3e0bfb2f4b640b59d8734a12b851a7f.png" width="70%" /> </div>
# IV. 实验

## A. 数据集和评估协议
数据集：我们在两个常用数据集（Market-1501 [45] 和 DukeMTMC-reID[46]）以及一个大规模数据集（Market-1501+500k[45]）上广泛评估了我们提出的方法。Market-1501数据集包含1,501个身份，通过6个摄像头观察，分为12,936个训练图像、3,368个查询图像和15,913个图库图像。Market-1501+500k在Market-1501的基础上扩大了图库，增加了额外的500,000个干扰物，使得准确度和速度方面的挑战更大。DukeMTMC-reID包含1,404个身份，有16,552个训练图像、2,228个查询图像和17,661个图库图像。

评估协议：对于准确性，我们使用标准指标，包括累积匹配特征（CMC）曲线和平均精度均值（mAP）。所有结果均来自单查询设置。为了评估速度，我们使用平均每张图像的查询时间，包括距离计算和排序时间。为了公平评估查询时间，我们没有使用任何并行算法进行距离计算和排序。

## B. 实现细节
我们使用Pytorch在一台装有2.6GHz Intel Core i5 CPU、10GB内存和NVIDIA RTX 2080Ti GPU的PC上实现了我们的方法。为了公平比较，并遵循大多数ReID方法[21]、[23]，我们使用Resnet-50[47]作为CNN主干网络。在训练阶段，每张图像被调整为256×128大小，并通过水平翻转和随机擦除[48]进行增强。一个批次数据包括来自16个不同人的64张图像，每个人包括4张图像。多个代码的长度 $L = \{l_k\}_ {k=1}^{N}$ 被经验性地设置为{32, 128, 512, 2048}。三元组损失中的边界在(5)中设置为0.3。该框架通过Adam[49]进行优化，总周期为120。初始学习率为0.00035，在前10个周期进行预热，在40和70个周期时分别衰减到其0.1倍和0.01倍。我们随机将训练数据分为训练集和验证集，比例为6:4，然后通过交叉验证决定参数，之后我们在所有训练数据上训练我们的方法。(5)中的 $\lambda_ {\text{prob}}$ 和 $\lambda_{\text{sim}}$ 被设置为1.0和1,000，(8)中的β被设置为2.0。 
 $\lambda_{\text{sdm}}$ 、 $\lambda_{\text{identi}}$ 和 $\lambda_{\text{orth}}$ 被设置为1.0。

## C. 与非哈希ReID方法的比较
非哈希ReID使用较长的实值特征，例如2048维float64特征，以获得更好的准确性。这显著影响了它们的速度，即查询时间。表IV显示，我们提出的CtF（包括AiO）方法比非哈希ReID方法快得多（两个数量级）。CtF在Market-1501和DukeMTMC-reID上的Rank-1（93.7%对比94.1%）和mAP（87.6%对比86.4%）得分与非常流行的基线ReID方法BoT[23]相当，并且比其他使用不同特征长度的非哈希方法更好，这些方法的特征长度短于2062（例如PSE[50]、IDE[2]、PN-GAN[51]、CamStyle[53]、PIE[73]）以及特征长度长于10240（例如SPReID[61]、PCB[11]、VPM[63]）的方法。总体而言，较长的特征通常会带来更高的准确性，但速度较慢。例如，SPReID、PCB和VPM使用超过10240的特征，分别在Market-1501和DukeMTMC-reID数据集上获得92%-93%和83%-84%的Rank-1得分。其他使用不超过2048的特征获得的Rank-1得分小于92%和80%。另一方面，具有长特征的这些方法的查询速度要慢得多。例如，PCB在两个数据集上分别需要6.9秒和6.3秒来查询每张图像。这比IDE在任一数据集上的2秒慢3-4倍。具体来说，CtF+OSF比非哈希方法执行速度快得多，并且显著地，它与具有实值特征模型的准确性相当。例如，CtF+OSF在Market-1501/DukeMTMC-reID上实现了95.5%/91.4%的Rank-1得分，与LUPersonNL分别为96.6%/92.0%。这是因为CtF（包括AiO）利用了集成一体模块以及粗到细搜索策略，不仅学习了强大的二进制代码，还长短代码互补使用，既实现了高准确性又实现了快速度。同时，OSF使用非常快的查找表过滤简单硬负样本，显著减少了图库大小。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/135cd84dfa7447ae87e18c96a486eb56.png" width="70%" /> </div>


## D. 与哈希ReID方法的比较
哈希ReID方法使用哈希算法学习二进制代码。二进制代码有利于速度，但牺牲了模型准确性。为了缓解这个问题，现有的最先进的哈希ReID方法通常采用较长的代码，如2048。在二进制编码中，2048相对较长，与更常用的512长度相比，与上文比较的实值特征长度不同。表V显示，CtF（带AiO）不仅实现了最佳准确性（即使与其他哈希方法使用的更短代码长度相比），而且比现有的哈希ReID方法显著更快（即使与其他哈希方法使用相同的代码长度相比）。总体而言，哈希ReID方法的表现通常不如非哈希方法。例如，最佳的非哈希ReID方法在Market-1501和DukeMTMC-reID上分别实现了93.3%和84.3%的mAP得分。但最佳的哈希ReID方法仅获得了88.8%和79.4%的Rank-1得分。此外，现有的哈希ReID模型可以通过使用更长的代码长度来提高准确性，同时牺牲速度。例如，ABC使用512维二进制代码实现了69.4%/69.9%的Rank-1得分和9.8/7.5×10^-2秒的查询时间。当使用2048维二进制代码时，其Rank-1得分提高到81.4%/82.5%，查询时间减慢到2.8/2.0×10^-1秒。这一观察结果也通过我们的方法CtF（带AiO）使用不同代码长度进行了验证。重要的是，我们的方法CtF+OSF在准确性和速度方面都显著优于所有现有的哈希ReID方法（快5倍）。具体来说，CtF与AiO一起使用2048维代码长度，实现了与没有CtF的AiO相近的高准确性，但获得了显著的速度优势，与短得多的128维二进制代码长度相当。此外，OSF进一步提高了速度，几乎不降低准确性。最后，CtF和OSF的结合使我们提出的方法在Market1501/DukeMTMC-reID数据集上分别比最先进的哈希ReID方法SIAMH提高了1.2%/2.0%的mAP得分和11.7倍/10倍的查询速度。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/3f074aa980de4fb2a452b9f7516aef6d.png" width="70%" /> </div>


## E. 在更强基线上的评估
一个典型的人物ReID模型包括三个模块，即主干（例如，ResNet [47]，ViTB16 [68]）从图像中提取特征图，颈部（PCB [11]，MGN [60]）细化特征，以及头部（例如，三元组[10]，IDE [2]）训练这些特征。例如，BoT [23]，一个非常流行的非哈希ReID方法，使用ResNet-50主干提取特征图，全局平均池化（GAP）颈部获得全局特征向量，以及IDE/三元组头部（带有交叉熵和三元组损失的线性层）来训练它们。PCB使用ResNet-50主干提取特征图，PCB颈部将特征图分割成6个局部特征向量（例如，身体、腿部、脚部），以及6个相应的IDE头部（带有交叉熵损失的线性层）来训练它们。我们提出的CtF和OSF是头部的一种形式，其中前者将实值特征映射到不同长度的二进制代码，后者学习潜在属性。因此，它们应该能够应用于任何具有不同主干和颈部的基线。如表IV所示，最近在Re-ID方法上取得的进展可以分为全局特征、细粒度特征、更强的主干和更好的预训练。前两者可以被视为颈部，后两者是主干。为了验证CtF和OSF对主干和颈部的可扩展性，我们报告了在更强基线上的指标，包括更先进的主干（VITB16 [68]）、更好的主干策略（LUPersonNL [70]）和更好的颈部（MGN）。通过这三个高级模块的加持，CtF+OSF在Market-1501/DukeMTMC-reID上的mAP得分分别提高了6.1%和6.9%。这证明了Ctf和OSF对主干和颈部的可扩展性。

## F. 在大规模ReID数据集上的评估
本节在大规模数据集MSMT [82]上评估我们提出的方法。MSMT包含4,101个身份和126,441个图像，比Market-1501和DukeMTMC-reID数据集更具挑战性。实验结果如表VI所示。我们可以看到，首先，非哈希和哈希方法在MSMT上的性能比在Market-1501和DukeMTMC-reID上要差得多，表明更大的数据集通常比更小的数据集更复杂。例如，最佳的非哈希ReID方法LUPersonNL在Market-1501/DukeMTMC-reID上获得了93.3%/84.3%的mAP得分，但在MSMT上只有66.1%。这是因为更大的数据集（即更多的身份）引入了更多的困难样本，导致频繁的误报。第二，哈希方法的性能不如非哈希方法，并且这种现象在MSMT上变得更糟。例如，Market1501上最佳非哈希和哈希方法之间mAP的差距（即PASS+ViTB16和SIAMH）是4.4%，但MSMT上的差距是11.8%。原因是更多的身份需要更细粒度的线索，但二进制代码的量化过程常常丢失了它们。最后，与非哈希方法相比，我们提出的CtF+OSF在准确性上具有可比性，并且速度更快。此外，CtF+OSF在准确性和速度方面都超越了现有的最先进的哈希方法。这是因为CtF（包括AiO）利用了集成一体模块，通过自我蒸馏（从较长代码传递线索到较短代码）丰富了二进制代码的线索，而OSF使用查找表过滤负样本，自然避免了量化损失。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/f38aec6e6380415bb1adc4a99add1f8a.png" width="70%" /> </div>


## G. CtF分析
AiO分析：集成一体（AiO）模块的目标是在单个模型中同时学习并增强不同长度的多个代码。它使用代码金字塔（CP）结构和自我蒸馏（SD）学习。结果见表VII。首先，较长的代码有助于提高准确性。这在所有设置中都可以看到，无论是否使用CP或SD以及代码类型如何。其次，当使用短代码时，实值特征比二进制代码要好得多。但对于长代码，它们获得相似的准确性。例如，32维实值特征获得了82.7%的Rank-1得分，比32维二进制代码高出60%，后者仅达到了25.5%。但是当使用2048维代码长度时，二进制代码和实值特征都达到了大约Rank-1 94%和mAP 84%。这表明短代码的量化损失比长代码的量化损失要严重得多。第三，使用代码金字塔（CP）结构或自我蒸馏（SD）学习显著提高了短代码的性能。例如，CP+SD将32维二进制代码的Rank-1得分从25.5%提高到60.0%，增长了35%。显然，代码金字塔（CP）结构和自我蒸馏（SD）学习都有助于粗到细（CtF）搜索策略的有效性，并显著提高了模型性能。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/523a586a813245b9bce625dc19599c15.png" width="70%" /> </div>


DTO分析：我们进一步分析了距离阈值优化（DTO）算法中的参数β，它控制ReID准确性和速度之间的平衡。图6显示了在Market-1501和DukeMTMC-reID上使用不同β值的模型准确性和速度。首先，显然β的值可以很好地控制准确性和速度，增加β会减慢速度但提高准确性。例如，当β = 10^-2时，ReID最快，大约0.03秒和0.02秒就能在Market-1501和DukeMTMC-reID上ReID每个探针图像，但mAP得分仅为40%和30%。相比之下，β = 10^1给出了高mAP 85%和75%，但查询速度慢了5倍，大约为0.1秒和0.2秒。其次，当β接近100时，Rank-1和mAP几乎达到了一个在速度上很好的平衡点。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/761a1b8eafa042c1a0d3270daac25167.png" width="70%" /> </div>


在更大的图库上的分析：图库大小显著影响ReID搜索的准确性和速度。为了展示我们提出的粗到细（CtF）搜索策略的有效性，我们在大规模ReID数据集Market1501+500 k上评估了它。该数据集基于Market-1501，并增加了500,000个干扰物。我们将CtF与三种ReID方法进行了比较，包括一种使用2048维实值特征的非哈希ReID方法，一种使用2048维长二进制代码的哈希ReID模型，以及一种使用32维短二进制代码的哈希ReID模型。实验结果如图7所示。我们可以观察到以下现象。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/1e7e630273ba4831b48da2c5146758cf.png" width="70%" /> </div>


首先，随着图库大小的增加，对于所有方法，Rank-1和mAP得分都有所下降，每个探针图像的ReID速度也逐渐变慢。原因是更多的图库图像更有可能包含更多困难样本。它们使ReID搜索更具挑战性。此外，额外的图库图像显著增加了计算所有距离比较和排序所需的时间。其次，使用2048-D实值特征的非哈希方法实现了最佳准确性，但查询时间最差。这是因为实值特征更具区分性，但计算和排序速度慢。2048-D二进制代码的ReID速度比非哈希模型快10倍，达到了类似的ReID准确性，但哈希ReID方法的查询时间比2048-D二进制代码慢5倍，但其准确性显著下降。最后，所提出的CtF模型实现了与非哈希方法相当的准确性，并且具有类似速度的优势，与32-D二进制代码的哈希ReID方法相当。关键的是，这种优势与图库大小无关。总体而言，这些实验证明了CtF在大规模ReID任务中的有效性。

时间和空间复杂度分析：我们分析了CtF对时间和空间复杂度的影响。如表VIII所示，我们使用了4个指标（3个用于时间，2个用于空间），包括FLOPs（推理一张图像的浮点运算次数）、PARAMS（模型的总参数数量）、LATENCY（推理一张图像的延迟）和STORAGE（每张图像的二进制代码磁盘存储）以及MEM（推理时间的内存成本）。请注意，上述所有指标已经考虑了主干模块。所有指标都在ResNet50[47]主干和128×256图像大小下，使用公共工具thop2和torchstat进行了评估。我们使用PyTorch后端评估了LATENCY，没有使用ONNX或TRT，在单个3090 GPU上，批量大小为256。实验结果表明，CtF模块几乎没有额外的推理时间复杂度，也没有推理时间空间复杂度。原因是集成一体（AiO）模块只包括三个线性层，并且需要2048×512 + 512×128 + 128×32 = 1 M FLOPs，因此对ResNet-50主干（需要2.7 G FLOPs）几乎没有影响。唯一值得注意的指标是STORAGE，与基线版本相比增加了1.32倍。但是考虑到5倍的匹配时间加速，应该是可以接受的。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/dd5ddbdafe324848a6256a9f569cb64f.png" width="70%" /> </div>


## H. OSF分析
OSF与CtF互补：所提出的粗到细（CtF）和一次性筛选（OSF）策略彼此互补。Market-1501数据集的准确性（平均精度均值，mAP）和速度（查询时间）之间的关系如图8(a)所示，CtF（黄色星号）的不同参数β（6）的点（从左到右是10^-2到10^1），CtF+OSF（红色方块）的β设置为2.0，并使用算法3中的不同参数γ（从左到右是0, 1, 2, 3, 4和5）。我们可以看到，CtF通过参数β很好地平衡了准确性和速度。增加β会减慢速度但提高准确性。例如，当β = 10^-2时，ReID在Market-1501上每个探针图像的查询速度最快，大约为0.03秒，但mAP得分仅为40%。相比之下，β = 10^1给出了85%的高mAP，但查询速度慢了5倍，大约为0.1秒和0.2秒。当β接近100时，Rank-1和mAP几乎达到了一个在速度上很好的平衡点。此外，γ也很好地控制了准确性和速度。增加γ会减慢速度但提高准确性。例如，从γ = 6开始，ReID最快，每个查询图像大约为10毫秒，但准确度低，mAP和Rank-1分别为40%和85%。此外，OSF与CtF互补。OSF通过CtF（β = 2）再次加速，几乎不降低准确性。例如，在CtF(β = 2.0)的基础上，增加γ将速度从46毫秒减少到大约18毫秒，而仅增加β只会减少到大约38毫秒。总之，CtF+OSF将CtF的速度从46毫秒提高到24毫秒，几乎没有准确性下降。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/3ff39cb59a114af482644d1eb9683e90.png" width="70%" /> </div>


LAL模块的有效性：所提出的LAL模块源自主成分分析（PCA），它用最少的维度保持最大方差，同时保持批量和端到端学习的能力。为了验证其优势，我们将LAL与几种变体进行了比较，包括全连接层（线性）和多层感知机（MLP）。实验结果如图8(b)所示。我们可以看到，所有三个版本（LAL、线性和MLP）都能在可接受的准确性成本下比单一CtF实现更快的速度，证明了所提出的一次性筛选（OSF）策略的有效性和鲁棒性。其中，我们的LAL表现最佳，在几乎没有准确性下降的情况下，速度提高了2倍。具体来说，当γ = 1时，CtF+OSF(LAL)将CtF的速度从46毫秒提高到24毫秒，仅mAP和Rank-1分别下降了0.1%和0.02%，而线性和MLP在速度上分别慢了40毫秒和35毫秒，准确性显著下降了2% mAP和0.5% Rank-1。

SDM损失的分析：SDM损失是专门为属性设计的。在这部分，我们比较了SDM与常见的欧几里得和余弦度量。实验结果如图8(c)所示。我们可以看到，无论是使用欧几里得、余弦还是SDM，所提出的一次性筛选（OSF）策略都表现良好，显示了其有效性和鲁棒性。其次，余弦和欧几里得度量的性能相似。例如，CtF+OSF(欧几里得)（η = 1）将CtF的速度从45毫秒提高到27毫秒，Rank-1和mAP分别下降了约1.0%和0.5%，而CtF+OSF(余弦)（η = 1）仅得到34毫秒，准确性相似。最后，我们提出的CtF+OSF(SDM)在速度上最快，为24毫秒，准确性下降较少。实验结果表明，所提出的SDM性能优于常见的欧几里得和余弦度量。

参数分析：在这一部分，我们分析了影响OSF的三个参数，包括(20)中的λsdm、λidenti和λorth。实验结果如图9所示。我们可以观察到几个现象。首先，非零参数的表现（准确性更高和速度更快）优于零参数，证明OSF对这三个参数都是鲁棒的。其次，在这三个损失（Lsdm、Lidenti和Leigen）中，Lsdm影响最大，其次是Leigen和Lidenti。具体来说，去除Lsdm，即设置λsdm = 1，会显著降低Rank-1和mAP，从93.7%和83.9%分别降低到91.0%和68.0%，速度也从24毫秒降低到35毫秒。去除Lidenti和Leigen只会略微降低准确性和减慢速度。去除Lidenti/Leigen会导致大约0.5%/0.2%的Rank-1和0.3%/0.3%的mAP下降，速度分别慢了3毫秒/11毫秒。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/0d99b80a75344cfb907b52f7fa101832.png" width="70%" /> </div>


## I. 可扩展性分析
最近，许多ReID方法被提出，通过使用更先进的主干架构、与人物相关的主干预训练策略和更精细的局部线索来提高准确性。我们提出的一次性筛选（OSF）和粗到细（CtF）搜索策略基于实值特征，并进一步用于加速搜索阶段，这与现有的实值ReID方法相辅相成。在这一部分，我们将OSF和CtF应用于三种典型的实值方法，以展示互补性。

这一部分验证了我们提出的一次性筛选（OSF）和粗到细（CtF）搜索策略在不同主干和更大的数据集MSMT [82]下的有效性。MSMT包含4,101个身份和126,441个图像。基线参考TransReID [68]及其代码，除了将最终层映射到2,048维外，还使用了一个额外的线性层，以便进行公平比较。我们分析了两种流行的主干，包括CNN系列（ResNet-50 [47]、ResNet-101 [47]、ResNet-152 [47]、ResNeSt50 [83]、ResNeSt200 [83]）和transformer系列（DeiT-S/16 [84]、DeiT-B/16 [84]、ViT-B/16 [84]、ViT-B/16s=14 [85]、ViT-B/16s=12 [85]）。详细信息见表IX。

我们可以看到，随着更大的（例如，更多层）和更先进的主干（例如，使用transformers代替CNNs），基线方法获得了更高的准确性。当然，查询时间是相同的，因为它们都使用2,048维实值特征。在OSF和CtF的加持下，查询时间显著减少，同时保持了可比的准确性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/0dad79b8f5b743888cce94a07d643997.png" width="70%" /> </div>

# V. 结论

在这项工作中，我们提出了一种新颖的一次性筛选（One-Shot-Filter, OSF）以及粗到细（Coarse-to-Fine, CtF）搜索策略，用于在传统哈希ReID上提高速度和准确性。OSF将基于排名的检索升级为基于索引的检索，通过属性匹配过滤掉简单的负样本。OSF包括两个关键组件，即潜在属性学习（Latent-Attribute-Learning, LAL）模块和单向度量损失（Single-Direction-Metric Loss）。前者在没有显式属性注释的情况下学习潜在属性。后者以类似IOU的度量优化潜在属性，表现优于常见的欧几里得和余弦度量。CtF首先使用较短的二进制代码粗略地对图库进行排名，然后逐步使用较长的二进制代码对选定的顶级候选进行更准确的排名。为了实现CtF策略，我们提出了一个集成一体（All-in-One, AiO）模块和距离阈值优化（Distance Threshold Optimization, DTO）算法。前者在单个模型中同时学习并增强不同长度的多个二进制代码。后者通过简单的优化过程解决了复杂的参数搜索任务。通过单一参数很容易控制搜索准确性和速度之间的平衡。广泛的实验表明，我们的方法比现有的哈希ReID方法快5倍，但与速度慢50倍的非哈希ReID模型实现了相当的准确性。基于CtF，OSF进一步将查询速度提高了2倍，几乎没有准确性损失。


# 声明

本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
