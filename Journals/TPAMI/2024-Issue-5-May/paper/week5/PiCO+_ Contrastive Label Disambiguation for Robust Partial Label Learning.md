# [PiCO+: Contrastive Label Disambiguation for Robust Partial Label Learning](https://ieeexplore.ieee.org/document/10356820/)
## 题目：PiCO+：用于鲁棒部分标签学习的对比标签消歧
**作者：Haobo Wang; Ruixuan Xiao; Yixuan Li; Lei Feng; Gang Niu; Gang Chen; Junbo Zhao**  
**源码：https://github.com/hbzju/PiCO**  
****
# 摘要
部分标签学习（Partial Label Learning, PLL）是一个重要的问题，它允许每个训练样本被标记为包含真实标签的粗略候选集。然而，在更实际但具有挑战性的场景中，注释者可能遗漏真实标签并提供错误的候选集，这被称为噪声PLL问题。为了解决这个问题，我们提出了PiCO+框架，该框架同时对候选集进行消歧和减轻标签噪声。PiCO+的核心是，我们开发了一种新颖的标签消歧算法PiCO，它由对比学习模块和新颖的基于类原型的消歧方法组成。从理论上讲，我们展示了这两个组成部分是相互有益的，并且可以从期望最大化（Expectation-Maximization, EM）算法的角度进行严格论证。为了处理标签噪声，我们将PiCO扩展到PiCO+，它进一步执行基于距离的清洁样本选择，并通过半监督对比学习算法学习鲁棒分类器。除此之外，我们进一步研究了PiCO+在面对分布外噪声时的鲁棒性，并结合了一种新颖的能量基拒绝方法以提高鲁棒性。广泛的实验表明，我们提出的方法显著优于当前最先进的方法，在标准和噪声PLL任务中表现优异，甚至达到了完全监督学习的可比结果。

# 关键词
- 对比学习
- 噪声标签学习
- 部分标签学习
- 基于原型的消歧

# I. 引言

现代深度神经网络的训练通常需要大量的标记数据，这在数据收集上构成了巨大的障碍。特别是，现实世界中的数据注释自然可能存在固有的标签歧义和噪声。例如，如图1所示，对于人类注释者来说，从西伯利亚哈士奇中识别出阿拉斯加马拉穆特可能很困难。标签歧义问题普遍存在，但在许多应用中经常被忽视，例如网络挖掘[1]和自动图像注释[2]。这突显了部分标签学习（PLL）的重要性[3]，[4]，在PLL中，每个训练样本都配备了一组候选标签，而不是确切的真实标签。这与其监督学习对应物形成对比，后者必须选择一个标签作为“黄金标准”。可以说，由于注释成本相对较低，PLL问题在各种情况下被认为更常见、更实用。

标准的PLL设置理想地假设真实标签保证包含在候选集中。然而，由于缺乏领域知识，注释者很可能会将错误的标签集视为候选标签，而忽略了真实的标签。Lv等人[5]将这个问题形式化为噪声部分标签学习（noisy PLL）。但是，他们专注于分析现有PLL方法的理论鲁棒性，而不是提供新的解决方案。从实验上，我们发现当前表现最佳的PLL算法，包括PiCO，在噪声PLL设置中表现出性能退化（见IV-C节），例如，在20%错误的候选集上，PRODEN的准确率下降了-10.62%。主要原因是当前PLL方法的标签消歧程序仅限于候选标签，这导致在错误标签上严重过拟合。值得注意的是，在更一般的设置中，数据源可能进一步包含分布外（OOD）噪声，这显著挑战了现有PLL算法的鲁棒性。图1说明了具有分布内噪声和分布外噪声的噪声PLL问题。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/921fe704217a4a8d9a37479276f76c46.png" width="70%" /> </div>


处理噪声PLL问题有两个挑战性问题。第一个是标签消歧，即从候选标签集中识别真实标签，这是部分标记的自然属性。第二个是防止模型在错误的候选集上过拟合。值得注意的是，现有的PLL方法[6]，[7]，[8]大多关注标签消歧问题，并在假设特征空间中更接近的数据点更有可能共享相同的真实标签的假设下运行。然而，这种策略在很大程度上依赖于现成的良好特征表示。当从头开始训练深度网络时，这会导致一个非平凡的困境——固有的标签不确定性和噪声可能不希望地体现在表示学习过程中——其质量又可能反过来阻止有效的标签消歧。迄今为止，很少有努力解决这个问题。

本文通过在一个连贯和协同的框架中调和这三个高度依赖的问题——表示学习、标签消歧和去噪——来弥合这一差距。我们PiCO+框架的核心是带有对比标签消歧的部分标签学习（被称为PiCO）算法，该算法为来自相同类别的示例生成紧密对齐的表示，并促进标签消歧。具体来说，PiCO专为标准PLL问题量身定制，包含两个关键组件。首先，我们利用对比学习（CL）[9]来部分标签学习，在以前的PLL文献中尚未探索过。为了缓解构建正样本对的关键挑战，我们采用分类器的输出并为对比比较生成伪正样本对（见III-A1节）。其次，基于学习到的嵌入，我们提出了一种新颖的基于原型的标签消歧策略（见III-A2节）。我们方法的关键是，我们逐渐根据最近的类原型更新分类的伪目标。通过交替上述两个步骤，PiCO收敛到一个具有高度可区分表示的解，以进行准确分类。在标准PLL基准测试中，PiCO在三个基准数据集上建立了最先进的性能，显著优于基线（见IV节），并且获得了与完全监督学习相媲美的结果。

为了处理噪声PLL问题，我们随后将PiCO扩展到PiCO+，它还额外结合了两个机制。首先，我们提出了一种新颖的基于距离的清洁样本检测技术，选择接近原型的示例作为清洁样本。其次，为了处理其余的噪声示例，我们开发了一个半监督对比学习框架，通过（i）对比学习：通过噪声预测和最近邻嵌入构建正集；（ii）标签消歧：为噪声样本猜测基于原型的软目标。更有趣的是，我们展示了PiCO+也可以对分布外噪声鲁棒，并且可以通过基于能量的拒绝机制进一步改进。通过广泛的实验，PiCO+在噪声PLL基准测试中表现出对现有PLL方法的显著改进。

从理论上讲，我们证明了我们的对比表示学习和基于原型的标签消歧是相互有益的，并且可以从期望最大化（EM）算法的角度进行严格解释（见V节）。首先，改进的伪标签通过准确选择伪正例来改善对比学习。这可以类比于E步骤，我们利用分类器的输出将每个数据示例分配给一个特定标签的簇。其次，更好的对比性能反过来提高了表示的质量，从而提高了标签消歧的有效性。这可以从M步骤的角度理解，其中对比损失部分通过聚类相似数据示例来最大化可能性。最后，训练数据将被映射到单位超球面上的von Mises-Fisher分布的混合中，这通过使用特定于组件的标签促进了标签消歧。通过适当的样本选择，我们的理论结果也解释了半监督PLL程序，证明了PiCO+在标签噪声下的鲁棒性。

我们在[10]中介绍了这项工作的初步结果。

在本文中，我们进一步提出了一个鲁棒的扩展。我们的主要贡献总结如下：
  1) (**方法论**)：据我们所知，我们的论文开创了通过PiCO和PiCO+对部分标签学习进行对比学习探索的先河。
  2) (**实用性**)：此外，我们提出了PiCO的扩展PiCO+，旨在减轻对噪声候选集的过拟合。我们还对OOD噪声进行了初步调查，并展示了PiCO+对此类噪声的鲁棒性。我们相信我们的工作在提高开放世界环境中PLL的实用性方面做出了认真的尝试。
  3) (**实验**)：从实证角度来看，我们提出的PiCO+框架在各种PLL任务上建立了最先进的性能，展示了其对标签歧义、标签噪声和分布外数据的鲁棒性。
  4) (**理论**)：我们从期望最大化的角度理论上解释了我们的框架。我们的推导也可以推广到其他对比学习方法，并且展示了对比学习中的对齐属性在数学上等于基于中心的聚类算法中的M步骤。

# III. PiCO+ 框架

在本节中，我们详细介绍了我们的PiCO+框架。在III-A节中，我们介绍了我们的核心组件——带有对比标签消歧的局部标签学习（PiCO）算法，它包含两个关键组件，用于提高表示质量和高标签消歧能力。接下来，在III-B节中，我们展示了PiCO+算法，通过将PiCO封装到半监督对比局部标签学习框架中来处理标签噪声，该框架执行基于距离的干净样本选择以进行鲁棒训练。最后，在III-C节中，我们进一步为PiCO+配备了基于能量的拒绝机制，以提高其对分布外噪声的鲁棒性。

## A. PiCO算法用于标签消歧

1) 对于局部标签学习（PLL）的对比表示学习：标签空间的不确定性为学习有效表示带来了独特的障碍。在PiCO中，我们将分类损失（1）与对比项结合起来，促进嵌入空间中的聚类效应。虽然对比学习在最近的文献中已经得到了广泛的研究，但在局部标签学习的领域尚未被开发。主要挑战在于构建正样本集。在传统的监督对比学习框架[9]中，可以根据真实标签轻松地抽取正样本对。然而，在局部标签学习的环境中，这并不直接。

训练目标：首先，我们描述标准的对比损失项。我们采用最流行的设置，紧密跟随MoCo[13]和SupCon[9]。给定每个样本（x, Y），我们通过随机数据增强Aug(x)生成两个视图——查询视图和关键视图。然后将这两个图像输入查询网络g(·)和关键网络g(·)，得到一对L2标准化的嵌入q = g(Augq(x))和k = g'(Augk(x))。在实现中，查询网络与分类器共享相同的卷积块，后跟一个预测头（见图2）。按照MoCo的方式，关键网络使用查询网络的动量更新。我们另外维护一个队列，存储最新的关键嵌入k，并且我们按时间顺序更新队列。为此，我们有以下对比嵌入池：

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/0809a7b1f263444d9e163879358af9c8.png" width="70%" /> </div>


$$
A = B_q \cup B_k \cup \text{queue},
$$

其中Bq和Bk是当前小批量的查询视图和关键视图对应的向量嵌入。给定一个示例x，每个样本的对比损失定义为将其查询嵌入与池A的其余部分进行对比，

$$
L_{cont}(g; x, \tau, A) = -\frac{1}{|P(x)|} \sum_{k^+ \in P(x)} \log \frac{e^{q^T k^+ / \tau}}{\sum_{k \in A(x)} e^{q^T k' / \tau}},
$$

其中P(x)是正集，A(x) = A\{q\}。τ≥0是温度参数。

正集选择：正如前面提到的，关键挑战是如何构建正集P(x)。我们提议利用分类器预测的标签 $\tilde{y} = \arg\max_{j \in Y} f_j(Augq(x))$ 。注意，我们将预测标签限制在候选标签集Y中。然后，正例被选择如下，

$$
P(x) = \{k' | k' \in A(x), \tilde{y}' = \tilde{y}\}.
$$

其中 $\tilde{y}'$ 是k'对应的训练示例的预测标签。为了计算效率，我们还维护一个标签队列来存储过去的预测。换句话说，我们定义x的正集是那些带有相同的近似标签预测  $\tilde{y}$ 的示例。尽管它很简单，但我们展示了我们的选择策略可以在理论上得到证明（见第V节），并且在实验结果上也领先（见第IV节）。注意，可以探索更复杂的选择策略，我们在附录B.5中讨论，可在线获取。将所有这些放在一起，我们联合训练分类器和对比网络。总体损失函数为：

$$
L_{pico} = L_{cls} + \lambda L_{cont}.
$$

然而，我们通过对比学习学习高质量表示的目标依赖于分类器预测的正集选择的准确性，这在标签歧义存在时仍未解决。为此，我们进一步提出了一种新颖的基于对比嵌入和原型的标签消歧机制，并展示这两个组件是相互有益的。

2) 基于原型的标签消歧：正如我们提到的（并在第V节中从理论上证明），对比损失在嵌入空间中产生了聚类效应。作为一种协作算法，我们引入了我们的新颖基于原型的标签消歧策略。重要的是，我们为每个类别c ∈ {1, 2, ..., C}保持一个原型嵌入向量 $\mu_c$ ，它可以被视为一组代表性嵌入向量。从类别上讲，伪目标分配的一个简单版本是找到当前嵌入向量的最近原型。值得注意的是，这个原始版本类似于聚类步骤。我们通过使用移动平均公式进一步软化这个硬标签分配版本。为此，我们直观地认为原型的使用在嵌入空间中由对比项带来的聚类效应建立了联系（见III-A1节）。我们在第V节中提供了更严格的证明。

伪目标更新：我们提出了一种软化和移动平均风格的策略来更新伪目标。具体来说，我们首先用均匀分布初始化伪目标， $s_j = \frac{1}{|Y|}I(j \in Y)$ 。然后我们通过以下移动平均机制迭代更新它，

$$
s = \phi s + (1 - \phi) z, \quad z_c =
\begin{cases} 
1 & \text{if } c = \arg\max_{j \in Y} q^T \mu_j, \\
0 & \text{otherwise}
\end{cases}
$$

其中φ ∈ (0, 1)是一个正常数， $\mu_j$ 是第j类的原型。直觉是，拟合均匀伪目标可以为分类器提供良好的初始化，因为对比嵌入在开始时不太可区分。然后，移动平均风格策略平稳地更新伪目标朝向正确的目标，同时确保训练的稳定动态。这得到了我们在附录B.1.4中的置信度曲线的定量结果的支持，可在线获取。在第V节中提供了更严格的验证后，我们为原型提供了以下解释：(i)-对于给定的输入x，最近的原型表明了它的真实的类别标签。在每一步中，s倾向于根据(6)稍微向基于z的一位有效分布移动；(ii)-如果一个示例持续指向一个原型，伪目标s可以收敛（几乎）到一个一位向量，具有最小的歧义。

原型更新：更新类条件原型向量的最典型方法是在每次训练迭代中计算它。然而，这将带来沉重的计算代价，并反过来造成难以忍受的训练延迟。因此，我们以移动平均风格更新类条件原型向量：

$$
\mu_c = \text{Normalize}(\gamma \mu_c + (1 - \gamma) q),
$$

$$
\text{if }c = \text{argmax}_{j∈Y}f^j(Aug_q(x)),
$$

其中类别c的动量原型 $\mu_c$ 由与c一致的归一化查询嵌入q的移动平均定义。γ是一个可调的超参数。

3) 对比学习与标签消歧之间的协同：虽然看起来彼此分离，但PiCO的两个关键组件以协作的方式工作。首先，由于对比项在嵌入空间中有利地表现出聚类效应，标签消歧模块通过设置更精确的原型进一步利用它。其次，一组经过精心打磨的标签消歧结果可以反过来回报对比学习阶段中的重要部分——正集构建。整个训练过程在两个组件表现令人满意时收敛。我们进一步严格地将PiCO与经典的EM风格的聚类算法进行了类比，见第V节。我们的实验，特别是第IV-B2节中的消融研究，进一步证明了两个组件之间协同的相互依赖性。我们完整的算法的伪代码显示在算法1中。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/e64ea4c8706f476486a1969f8c3e94c6.png" width="70%" /> </div>


## B. PiCO+ 处理噪声候选集

在本节中，我们的目标是解决更实际的噪声局部标签学习（noisy PLL）设置[5]，其中注释者可能会产生错误的候选集。通过实验观察，包括PiCO在内的当前局部标签学习方法在这样的设置中表现出显著的性能下降（见第IV-C节）。一个主要原因是这些方法大多依赖于集合内的伪标签更新步骤，但噪声候选集可能会误导它们过度拟合到错误的标签上。为此，我们提出了PiCO+，PiCO的扩展，它从噪声局部标签中学习鲁棒分类器。首先，我们引入了一种基于距离的样本选择机制，选择包含真实标签的干净示例来运行PiCO方法。然后，我们开发了一个半监督对比局部标签学习框架来处理带有噪声候选的数据。接下来，我们详细阐述我们的新型PiCO+框架。PiCO+的可视化插图如图3所示。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/a80148f868844562905afe323ceb1b8d.png" width="70%" /> </div>


1) 基于距离的干净样本检测：为了解决在噪声候选上的过拟合问题，我们希望选择那些包含真实标签的可靠候选集来运行PiCO方法。在噪声标签学习领域，一个广泛采用的策略是使用小损失选择标准[14]，这基于观察到的噪声示例通常表现出较大的损失。然而，在噪声局部标签问题中，损失值的指示性较差，因为即使候选集是可靠的，拥有更多候选标签的示例也可能产生更大的损失。

为解决这个问题，我们提出了一种基于距离的选择机制，如下所示：

$$
D_{\text{clean}} = \{(x_i, Y_i)| q^T \tilde{\mu}_{y_i} > \kappa\delta\},
$$

其中 $\tilde{y_i} = \arg\max_{j \in Y_i} f_j(Augq(x_i))$ 是分类器预测。 $\kappa\delta$ 是查询嵌入与第 $\tilde{y_i}$ 个原型之间余弦相似度的(100 - δ)百分位数。例如，当δ = 60时，意味着60%的示例高于阈值。我们的动机是对比学习聚类效应使得干净示例主导原型计算，因此它们至少在一个候选集内的原型附近分布。另一方面，噪声候选项大多偏离所有候选原型，因为它们的真正标签不包含在它们的候选集中。

2) 半监督对比学习：虽然利用干净示例运行PiCO模型是直接的，但数据的低效用限制了它更好的性能。因此，我们将噪声示例视为未标记数据，并开发了一个半监督学习框架来从这两组数据中学习。在干净数据集上，我们假设真实标签包含在候选集中，并运行我们的PiCO方法。特别要注意的是，我们也仅将正集构建和原型更新过程限制为仅使用干净示例。但是，伪目标更新是在所有数据点上执行的。

在噪声数据集上，表示为 $D_{\text{noisy}} = D\setminus D_{\text{clean}}$ ，我们遵循PiCO中的设计模式，协同训练对比分支和分类器。这是通过以下组件实现的：

邻居增强的对比学习：回想一下，设计对比损失的关键步骤是构建正集，这对于噪声样本来说是一个挑战，因为它们的候选集不可靠。为此，我们首先提出了一个基于标签的构造方法。通过将噪声样本视为未标记数据，直观地将所有标签视为候选项。这产生了以下噪声正集：

$$
P_{\text{noisy}}(x) = \{k | k' \in A(x), \hat{y}' = \hat{y}\},
$$

其中 $\hat{y} = \arg\max_{1 \leq j \leq C} f_j(Augq(x)))$ 如果 $x \in D_{\text{noisy}}$ ，否则 $\hat{y} = \arg\max_{j \in Y} f_j(Augq(x)))$ 。也就是说，我们为干净示例选择集合内的分类器预测，并为其余的样本选择全标签预测。我们将这个噪声正集应用于所有D中的数据，并根据(3)计算噪声对比损失 $L_{\text{n-cont}}$ 。这个目标作为我们半监督训练的最终目标，即在干净和噪声未标记数据上恢复PiCO算法。

然而，由于我们对噪声样本的了解较少，我们对 $P_{\text{noisy}}(x)$ 的估计可能是不准确的，并分配错误的聚类中心。为此，我们结合了一种数据驱动技术来规范噪声对比损失。具体来说，我们收集噪声样本的最近邻居作为正样本，

$$
P_{k\text{NN}}(x) = \{k' | k' \in A(x) \cap N_k(x)\},
$$

其中 $N_k(x)$ 是嵌入空间中x的k近邻的嵌入集。然后，我们基于kNN计算噪声样本的对比损失 $L_{k\text{NN}}$ 。请注意，原始的对比学习目标自然通过使增强副本对齐来鼓励示例在局部平滑性——我们的邻居增强损失进一步增强了这种效果，以确保局部区域内的示例共享相同的标签。通过这种方式，噪声示例与其局部邻居对齐，这有助于它们向正确标签的聚类效应。

原型基础的标签猜测：同样，我们也希望识别噪声示例上的真实标签以增强分类器训练。尽管噪声示例被视为未标记数据，但直接将它们的标签设置为均匀标签1/C（如PiCO中那样）是不合适的，因为数据分离程序在训练期间动态变化。为此，我们利用类原型来猜测它们的伪目标s，

$$
s'_ j = \frac{e^{q^T \mu_j / \tau} }{\sum_{t=1}^C e^{q^T \mu_t / \tau}}, \quad \forall 1 \leq j \leq C.
$$

我们在噪声数据集 $D_{\text{noisy}}$ 上计算交叉熵损失，定义为(1)中的 $L_{\text{n-cls}}$ 。

Mixup训练：最近，mixup正则化技术已被广泛采用，以提高弱监督学习算法的鲁棒性[15]，[16]。因此，我们也将其纳入PiCO+以提高性能。具体来说，给定一对图像 $x_i$ 和 $x_j$，我们通过线性插值两者创建一个虚拟训练样本：

$$
xm = \sigma Augq(x_i) + (1 - \sigma)Augq(x_j),
$$

$$
sm = \sigma \hat{i} + (1 - \sigma)\hat{s}_j, 
$$

其中 $\sigma \sim Beta(\zeta, \zeta)$ ， $\zeta$ 是一个超参数。这里，我们取干净样本上的 PiCO 伪目标和噪声样本上的猜测标签，即，如果 $x \in D_{clean}$ ，则 $\hat{s} = s$ ；否则 $\hat{s} = s'$ 。我们定义 mixup 损失 $L_{mix}$ 为 $xm$ 和 $sm$ 的交叉熵。

最终，我们将上述损失合并起来，

$$
L_{pico+} = L_{mix} + \alpha L_{clean} + \beta (L_{n-cont} + L_{kNN} + L_{n-cls}), 
$$

其中 $L_{clean}$ 是干净样本上的 PiCO 损失。注意，过度信任噪声样本上的猜测标签和正集可能会导致确认偏差 [17]，从而使模型过度拟合到错误的标签上。通过实验，我们设置较大的 $\alpha$ 和较小的 $\beta$（例如， $\alpha = 2, \beta = 0.1$ ），这样干净样本主导学习过程，以确保有利的噪声样本检测能力。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/ec5626d4111448d191fc44623f2f0eb3.png" width="70%" /> </div>


## C. 减轻分布外噪声
最后，我们探讨了 PiCO+ 对分布外（OOD）噪声的鲁棒性。在现实世界的应用中，一些训练样本可能来自与预定义标签空间 Y 不同的领域，但却被分配了来自 Y 的候选标签。通过适当的样本选择，我们相信 PiCO+ 仍然可以对 OOD 噪声保持鲁棒。然而，半监督学习过程不可避免地会受到 OOD 样本的影响，因为它鼓励所有样本向原型靠拢。在这种情况下，基于距离的度量可能不适用于检测 OOD 样本。

为解决这个问题，我们为 PiCO+ 配备了基于能量的拒绝机制，因为已知 OOD 样本具有较大的能量 [18]。形式上，我们首先通过以下方式计算分类器上的能量分数：

$$
E(x) = -\frac{1}{\tau'} \log \sum_{i=1}^C e^{\hat{f}_i(Augq(x))/\tau'}
$$

其中 $\hat{f}$ 是 softmax 层之前的网络输出， $\tau' = 1$ 是能量温度。人们可以使用验证集来确定一个阈值，以分离 OOD 数据，但这在实践中可能很烦琐。受到噪声标签学习文献 [16] 的启发，我们拟合了一个两分量的高斯混合模型（GMM）到 E(x)。对于每个样本，如果其 GMM 后验概率 p(G|E(x)) < 0.5，其中 G 是均值较小的高斯分量，即能量较小，那么它就被视为 OOD。然后，我们拒绝这些 OOD 数据，并使用剩余的样本运行 PiCO+。


# IV. 实验

在本节中，我们展示了PiCO和PiCO+方法的主要结果和部分消融结果。在IV-B节中，我们首先检验PiCO及其扩展PiCO+在标准部分标签学习（Partial Label Learning, PLL）数据集上的有效性。然后，在IV-C节中，我们在噪声PLL设置中报告了结果。读者可参阅附录B中的更多实验结果和分析，附录B可在线获取。代码和数据可在以下链接获取：https://github.com/hbzju/PiCO。

## A. 设置

**数据集**：首先，我们在两个常用的基准数据集CIFAR-10和CIFAR-100上评估PiCO。采用与之前工作相同的实验设置，我们通过以概率q翻转负标签生成传统的部分标记数据集。换句话说，所有C-1个负标签都有均匀的概率成为假正标签，我们将翻转的标签与真实标签聚合以形成候选集。我们考虑CIFAR-10中的q值分别为{0.1, 0.3, 0.5}，CIFAR-100中的q值分别为{0.01, 0.05, 0.1}。在IV-D1节中，我们进一步在细粒度分类任务上评估我们的方法，其中标签消歧可能更具挑战性。

对于噪声PLL任务，我们引入了一个控制噪声的参数η，它控制真实标签不被选为候选项的概率。由于某些实例可能未被分配任何候选标签，我们简单地重新生成候选集，直到它至少有一个候选标签。我们为两个数据集选择η值分别为{0.1, 0.2}；更强烈的噪声比例的结果在IV-C3节中展示。

**基线**：我们选择了迄今为止表现最佳的五种部分标签学习方法：1) LWS[21]通过在候选标签和剩余标签之间的损失之间进行权衡来加权风险函数；2) PRODEN[20]以自训练的方式迭代更新潜在标签分布；3) CC[22]是一种分类器一致性方法，它假设集合级别的统一数据生成过程；4) MSE和EXP[23]是两个简单的基线，采用均方误差和指数损失作为风险。对于噪声PLL任务，我们还额外采用了一个基线方法GCE[5],[24]，它通过负Box-Cox转换推广交叉熵损失。我们在附录B.8中报告了与[5]中的其余基线的比较。超参数根据原始方法进行调整。在所有实验中，我们报告了基于5次独立运行（使用不同的随机种子）的平均值和标准差。

**实现细节**：按照PLL[21],[22]中的标准实验设置，我们从训练集中分割出一个干净的验证集（训练数据的10%），以选择超参数。之后，我们将验证集恢复为其原始的PLL形式，并将其纳入训练集以完成最终模型训练。我们使用18层ResNet作为特征提取的骨干网络。对比网络的大多数实验设置遵循先前的工作[9],[13]。对比网络的投影头是一个2层MLP，输出128维嵌入。我们分别使用SimAugment[9]和RandAugment[25]作为查询和关键数据增强的两个数据增强模块。从实验中，我们发现即使关键嵌入的弱增强也能带来好的结果。存储关键嵌入的队列的大小固定为8192。动量系数分别设置为对比网络更新的0.999和原型计算的γ=0.99。对于伪目标更新，我们从0.95线性降低φ到0.8。温度参数设置为τ=0.07。损失加权因子设置为λ=0.5。模型使用标准的SGD优化器进行训练，动量为0.9，批量大小为256。我们训练模型800个周期，采用余弦学习率调度。我们还从实验中发现，当候选标签很多时，分类器预热可以带来更好的性能。因此，我们在CIFAR-100数据集上，q=0.1时，禁用了前100个周期的对比学习，其余实验禁用了1个周期。

对于PiCO+，我们基本上遵循原始的PiCO方法。干净样本选择比例参数δ分别设置为0.8/0.6，对应噪声比0.1/0.2。对于邻居增强，我们为CIFAR-10设置k=16，对于CIFAR-100设置较小的k=5。起初，嵌入可能意义不大，因此在前100个周期后启用kNN增强。我们将Beta分布的形状参数固定为ς=4，用于mixup训练。我们设置损失加权因子α=2和β=0.1。与标准PLL设置类似，我们通过在CIFAR-10和CIFAR-100数据集上分别使用5个和50个周期的均匀目标来预热模型。

## B. 标准PLL上的主要经验结果

1) **主要结果**：PiCO在标准PLL任务上取得了最先进的结果：如表I所示，PiCO在所有数据集上显著优于所有竞争对手。具体来说，在CIFAR-10数据集上，我们在q分别设置为0.1、0.3、0.5时，分别提高了最佳基线4.09%、4.80%和5.80%。此外，随着候选集大小的增加，PiCO一致地取得了优越的结果，而基线则表现出显著的性能下降。此外，值得一提的是，以前的工作[20],[21]通常在标签空间较小（C=10）的数据集上进行评估。我们通过在CIFAR-100上展示额外的结果来挑战这一点。当q=0.1时，所有基线都无法获得令人满意的性能，而PiCO仍然具有竞争力。此外，我们观察到PiCO在完全监督的对比学习模型上取得了可比的结果（见表II），表明消歧已经足够完成。比较突出了我们标签消歧策略的优越性。最后，我们在标准PLL设置中评估了PiCO+方法，它等同于带有mixup训练的PiCO模型。PiCO+通过显著的优势进一步改进了PiCO，验证了mixup技术的重要作用。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/94c5eddae17c4455be9dc34c6ce79d4a.png" width="70%" /> </div>
<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/43d647b0e1164fa193275a9994a7045f.png" width="70%" /> </div>


PiCO学习了更可区分的表示：我们在图4中使用t-SNE[26]可视化了特征编码器生成的图像表示。不同的颜色代表不同的真实类别标签。我们使用q=0.5的CIFAR-10数据集。我们将三种方法的t-SNE嵌入进行了对比：(a) 使用均匀伪目标训练的模型，即对于Y中的j，sj = 1/|Y|；(b) 最佳基线PRODEN；(c) 我们的方法PiCO。我们可以观察到，由于其监督信号受到高度不确定性的影响，统一模型的表示是无法区分的。PRODEN的特征有所改进，但仍有一些类别重叠（例如，蓝色和紫色）。相比之下，PiCO产生了良好分离的簇和更可区分的表示，这验证了其在学习高质量表示方面的有效性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/5d66031b5dce43288e166691cc5df211.png" width="70%" /> </div>


2) **PiCO的消融研究**：对比学习和基于原型的标签消歧两个关键组件的影响：我们特别比较了PiCO与两个变体：1) 没有消歧的PiCO，保持伪目标为均匀的1/|Y|；2) 没有Lcont的PiCO，进一步去除了对比学习，只使用均匀伪目标训练分类器。从表II中，我们可以观察到变体1在CIFAR10上显著优于变体2（例如，提高了8.04%），这表明对比学习对于产生更好的表示至关重要。此外，通过标签消歧，PiCO获得了接近完全监督设置的结果，这验证了PiCO在识别真实情况的能力。

不同的消歧策略：基于对比原型，可以使用不同的策略来消歧标签，这对应于我们理论分析中的E步骤。我们选择了以下变体：1) 始终使用最接近的原型分配一个一热伪目标s = z（φ = 0）；2) 软原型概率遵循[27]，使用软类概率si = exp(q⊤µi/τ) / ∑j∈Y exp(q⊤µj/τ)作为伪目标（φ = 0）；3) MA软原型概率逐渐使用软概率以移动平均风格更新伪目标。从表II中，我们可以看到直接使用基于软或硬原型的标签分配可以获得有竞争力的结果。这证实了我们第V节中的理论分析，因为基于中心的类概率估计在聚类算法中很常见。然而，MA软原型概率显示出性能下降，表明软标签分配在识别真实情况方面不太可靠。最后，PiCO在两个数据集上都比最佳变体高出约2%的准确率，显示了我们标签消歧策略的优越性。

移动平均因子 φ 的影响：接下来，我们探讨了伪目标更新因子 φ 对 PiCO 性能的影响。图 5(a) 展示了在 CIFAR-100 数据集上（q = 0.05）PiCO 的学习曲线。我们可以看到，在 φ = 0.9 时达到最佳结果，当 φ 取较小值时性能下降，特别是在早期阶段。当 φ = 0 时，PiCO 获得了有竞争力的结果，但远低于 φ = 0.9 的结果。这证实了在早期阶段信任均匀伪目标对于获得优越性能至关重要。在另一个极端值 φ = 1 时，使用的是均匀伪目标，PiCO 表现出性能退化和严重的过拟合现象。总的来说，当 φ 接近 0.9 时，PiCO 的性能表现良好。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/cc0e370f325e49e3b3765807c898a8a9.png" width="70%" /> </div>


## C. 主要实验结果在噪声 PLL 上

1) 主要结果：PiCO+ 在噪声 PLL 任务上取得了 SOTA 结果：在表 III 中，我们比较了 PiCO+ 与 CIFAR 数据集上其他有竞争力的 PLL 方法，PiCO+ 显著优于基线。具体来说，在 CIFAR-10 数据集上，当 q = 0.5 时，PiCO+ 比最佳竞争者分别提高了 6.66% 和 12.52%，当 η 分别设置为 0.1 和 0.2 时。值得注意的是，在噪声 PLL 设置下，即使只有 10% 的示例具有错误的候选集，基线算法（包括 PiCO）也表现出严重的性能下降。这在 CIFAR-100 上更为严重，后者具有更大的标签空间，而 PiCO+ 始终保持其出色的鲁棒性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/e92466dae65346b6a8488b4934267445.png" width="70%" /> </div>


PiCO+ 学习到紧凑且可区分的特征：在图 6 中，我们可视化了 PiCO+ 在带有噪声的 PLL CIFAR-10 数据集上（q = 0.5，η = 0.2）的特征表示。可以看出，即使在带有噪声候选集的情况下，PiCO 也能产生紧凑的表示，这进一步支持了对比学习的聚类效应。然而，PiCO 和 PRODEN 都表现出对错误标签的严重过拟合。相反，我们的 PiCO+ 的特征既紧凑又可区分。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/0fd3ff75974c4cd9964a2e08d80cc15f.png" width="70%" /> </div>


2) PiCO+ 的消融研究：样本选择的影响：我们首先通过比较 PiCO+ 与两个变体来研究我们基于距离的选择机制的有效性：1) PiCO+ with SL-Sel 通过按交叉熵损失排序来选择干净样本；2) PiCO+ with Only Clean 仅使用干净样本来运行简单的 PiCO 方法。如表 IV 所示，仅使用干净数据的 PiCO+ 比原始 PiCO 方法表现更好（例如，在 CIFAR-10 上提高了 7.56%），表明所选示例具有很高的纯度。此外，PiCO+ with SL-Sel 的表现不如 PiCO+，这证实了损失值在候选标签存在时确实信息较少，我们的策略是更好的选择。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/84370b2a83d04fa2a76fd22c4237a57a.png" width="70%" /> </div>


半监督对比训练的影响：接下来，我们探讨了 SSL 训练中每个组件的影响。我们比较了 PiCO+ 与三个变体：1) PiCO+ w/o Ln-cls 移除了标签猜测技术；2) PiCO+ w/o Ln-cont 移除了标签驱动的对比损失；3) PiCO+ w/o kNN 禁用了邻居增强的对比损失；4) PiCO+ w/o Mixup 禁用了 mixup 训练。从表 IV 可以看出，我们 SSL 框架的所有组件都有助于性能提升。特别是，在 CIFAR-10 上，Ln-cont 有更强的正面影响，标签猜测组件为两个数据集都带来了额外的性能提升。Mixup 和邻居增强对最终性能最为关键。我们注意到，mixup 训练技术也提高了全监督模型的性能（例如，在 CIFAR10 上提高了 1.05%）。但是，在噪声 PLL 任务中性能提升更为显著（例如，在 CIFAR-10 上提高了 2.92%），表明其在噪声数据上的鲁棒性。最后，图 5(b) 显示了邻居数 k 的影响，PiCO+ 在 k 值的广泛范围内表现良好。然而，过大的 k 可能会收集许多噪声正样本，导致性能略有下降。

损失加权因子 β 的影响：图 5 报告了 PiCO+ 在不同 β 值下的性能。在 CIFAR-10 数据集上，我们观察到当 β 较大时性能严重下降。随着 β 的增大，变化也变得越来越大。在 CIFAR-100 上也可以观察到类似趋势，尽管结果更稳定。这表明，使用噪声样本时要小心，因为它们可能导致确认偏差。

3) PiCO+ 在严重噪声下的鲁棒性：最后，我们在包含更多噪声的 PLL 数据集上进行实验，以展示我们 PiCO+ 方法的鲁棒性。具体来说，我们选择了 η ∈ {0.3, 0.4} 和 η ∈ {0.3, 0.4, 0.5} 分别用于 CIFAR-10 和 CIFAR-100。相应地，我们调整选择比率到 δ = 0.5, 0.4 当 η = 0.4, 0.5，而其他设置保持不变。表 V 比较了 PiCO+ 与两个最具竞争力的基线 PiCO 和 PRODEN，PiCO+ 获得了非常令人印象深刻的性能。例如，在 CIFAR-10 上 η = 0.4 和 CIFAR-100 上 η = 0.5 时，PiCO+ 与最佳基线之间的差距分别为 41.50% 和 24.99%。我们得出结论，PiCO+ 确实比现有的 PLL 算法更加鲁棒。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/a6c6a66a4e0f42e4886e7441f6c09d1b.png" width="70%" /> </div>
## D. 在更具挑战性的数据集上的实验

1) 细粒度局部标签学习：回顾第一节中强调的狗的例子，其中语义上相似的类别更有可能引起标签歧义。这就引出了一个问题，即PiCO在具有挑战性的细粒度分类任务中是否有效。为了验证这一点，我们在三个数据集上进行了实验：1) CUB-200数据集[28]包含200种鸟类；2) Flowers-102[29]收集了102种在英国常见的花卉；3) CIFAR-100的层次标签（CIFAR-100-H），我们生成属于同一超类的候选标签。值得注意的是，CUB-200/Flowers-102数据集包含了大量的相似的狗/花卉样本，并且可能很难区分候选标签。我们为CUB-200/Flowers-102设置了q = 0.05，为CIFAR-100-H设置了q = 0.5。在表VI中，我们比较了PiCO与基线算法，PiCO在CUB-200上比最佳方法PRODEN高出9.61%，在CIFAR-100-H上高出11.15%。此外，我们在标准和噪声版本的细粒度数据集上测试了PiCO+的性能。对于噪声版本，我们为CUB-200/Flowers-102设置了邻居数k = 3，所有数据集设置了η = 0.2。结果列在表VI和VII中，PiCO+在所有基线算法上都取得了显著更好的性能，例如在Flowers-102上比最佳PRODEN算法提高了19.07%的准确率。我们的结果验证了PiCO+框架的有效性和鲁棒性，即使在存在强烈的标签歧义的情况下。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/d65ad714db144412b0ce5a85eb1a8267.png" width="70%" /> </div>
<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/37cffc46c9d04dc18556dbdfba055c52.png" width="70%" /> </div>


2) 在ImageNet上的实验：最后，我们验证了PiCO+在大规模ImageNet数据集上的可扩展性。由于计算资源有限，我们遵循以前的弱监督学习文献[30]，[31]，并采用了一个包含100个类别的抽样版本。结果的数据集仍然是大规模的，包含128,545个图像样本。在运行过程中，我们将图像分辨率设置为224×224。歧义度设置为q = 0.1。对于噪声PLL任务，我们将噪声率设置为η = 0.2。在表IX中可以看出，PiCO+以显著的优势超越了基线算法，例如在干净的PLL上比最佳CC算法提高了2.78%，在噪声PLL设置上比最佳GCE方法提高了3.74%。结果进一步验证了PiCO+在大规模数据集上的可扩展性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/45bbbdaa7cb74cd09edbabd2c5b11e07.png" width="70%" /> </div>


## E. 在带有OOD噪声的PLL上的实证结果

最后，我们研究了PiCO+在存在OOD噪声的情况下的鲁棒性。按照[32]，我们使用了一系列的辅助数据集SVHN[33]、Places-365[34]和Texture[35]。我们随机选择了大规模SVHN和Places365数据集的10,000个样本的子集。这些数据集与CIFAR-10和CIFAR-100结合，合成了包含分布内(ID)噪声和分布外(OOD)噪声的PLL数据集。我们为CIFAR-10设置了q = 0.5，为CIFAR-100设置了q = 0.05，以在所有样本上生成候选标签，并使用η = 0.2随机翻转ID数据为噪声候选项。值得注意的是，所有OOD样本都是噪声的，因为它们的真标签不包括在候选集中。实验结果列在表VIII中。我们可以观察到，即使没有基于能量的拒绝，PiCO+与PiCO和PRODEN算法相比也表现出了巨大的鲁棒性。主要原因是我们的样本选择过程主导了训练过程。配备拒绝机制后，PiCO+能够实现进一步改善的结果，例如，在CIFAR-10上使用SVHN作为OOD数据集时，与PRODEN相比准确率提高了35.73%。这些发现清楚地验证了PiCO+在开放世界场景中的鲁棒性。

<div align=center>   <img src="https://img-blog.csdnimg.cn/direct/d8b7df3295ab4575a76a9940444cd0a7.png" width="70%" /> </div>



# V. 为什么PiCO提升了部分标签学习？

在本节中，我们提供了理论上的解释，阐明了为什么对比学习的原型有助于消歧真实标签。我们展示了对比学习中的对齐属性[11]本质上最小化了嵌入空间中的类内协方差，这与经典聚类算法的目标一致。这激发了我们从期望最大化（EM）算法的角度来解释PiCO。为了更清楚地看到这一点，我们考虑一个理想设置：在每个训练步骤中，所有数据示例都是可访问的，增强副本也包含在训练集中，即， $A = D$ 。然后，对比损失被计算为，

$$
\tilde{L}_ {\text{cont}}(g; \tau, D) = \frac{1}{n} \sum_{x \in D} \left( -\frac{1}{|P(x)|} \sum_{k^+ \in P(x)} \log \frac{e^{q^T k^+ / \tau}}{\sum_{k \in A(x)} e^{q^T k' / \tau}} \right) = \frac{1}{n} \sum_{x \in D} \left( -\frac{1}{|P(x)|} \sum_{k^+ \in P(x)} {(q^T k_+ / \tau)} \right)+\frac{1}{n} \sum_{x \in D} \left( \log {\sum_{k \in A(x)}} exp(q^T k /\tau)  \right)
$$

我们专注于分析第一项（a），这通常被称为对齐项[11]。这一项的主要功能是优化嵌入空间中聚类的紧密度。在这项工作中，我们将其与经典聚类算法联系起来。我们首先将数据集分割为C个子集 $S_j \in D_C$ （ $1 \leq j \leq C$ ），每个子集包含具有相同预测标签的示例。实际上，我们在（4）中的选择策略通过从同一子集中选择示例来构建正集。因此，我们有，

$$
(a) = \frac{1}{n} \sum_{x \in D} \frac{1}{|P(x)|} \sum_{k^+ \in P(x)} \left( \frac{||q - k^+||^2 - 2}{2\tau} \right) \approx \frac{1}{2\tau} \sum_{S_j \in D_C} \frac{1}{|S_j|} \sum_{x, x' \in S_j} ||g(x) - g(x')||^2 + K =  \frac{1}{\tau n}\sum_{S_j \in D_C} \sum_{x \in S_j}||g(x) - \mu_j||^2 + K,
$$

其中K是常数， $\mu_j$ 是 $S_j$ 的均值中心。这里我们近似为 $\frac{1}{|S_j|} \approx \frac{1}{|S_j|-1} = \frac{1}{|P(x)|}$ ，因为n通常很大。我们为了简化省略了增强操作。一致性项（b）可以有利于信息的保持，并且在文献[11]中已经进行了分析。

我们现在已经准备好将PiCO算法解释为一个期望最大化算法，它最大化了一个生成模型的似然。在E步骤中，分类器为每个数据示例分配到一个特定的簇。在M步骤中，对比损失通过最小化（16）将嵌入集中到它们的簇均值方向，这通过最小化以下公式实现：

$$
\frac{1}{\tau n} \sum_{S_j \in D_C} \sum_{x \in S_j} ||g(x) - \mu_j||^2
$$

最终，训练数据将被映射到单位超球面上的von Mises-Fisher分布的混合。

EM视角：回想一下候选标签集是真实的标签的噪声版本。为了估计似然 $P(Y_i, x_i)$ ，我们需要建立候选标签和真实标签之间的关系。按照[6]，我们提出了一个温和的假设：

假设1：所有在候选标签集中的标签 $y_i$ 都有相同的概率生成 $Y_i$ ，但 $Y_i$ 之外的任何标签都不能生成 $Y_i$ ，即如果 $y_i \in Y_i$ ，则 $P(Y_i|y_i) = \pi(Y_i)$ ，否则为0。这里 $\pi(·)$ 是使其成为一个有效概率分布的函数。

然后，我们展示了PiCO隐式地最大化了如下的似然：

E步骤：首先，我们引入了所有示例和候选标签上的概率分布 $\pi_{j|i} \geq 0$ （ $1 \leq i \leq n, 1 \leq j \leq C$ ），使得如果 $j \notin Y_i$ ，则 $\pi_{j|i} = 0$ ，并且 $\sum_{j \in Y_i} \pi_{j|i} = 1$ 。让 $\theta$ 是函数g的参数。我们的目标是最大化以下似然：

$$
\begin{aligned}
\arg\max_\theta \sum_{i=1}^n \log P(Y_i, x_i|\theta) &= \arg\max_\theta \sum_{i=1}^n \log \left(\sum_{y_i \in Y_i} P(x_i, y_i|\theta) + \log(\pi(Y_i))\right) \\
&= \arg\max_\theta \sum_{i=1}^n \log \left(\sum_{y_i \in Y_i} \pi_{y_i|i} P(x_i, y_i|\theta)\right) \\
&\geq \arg\max_\theta \sum_{i=1}^n \sum_{y_i \in Y_i} \pi_{y_i|i} \log P(x_i, y_i|\theta)
\end{aligned}
$$

最后一步的推导使用了詹森不等式。通过使用对数函数是凹函数的事实，不等式在 $P(x_i,y_i|\theta) \pi_{y_i|i}$ 是某个常数时取得等号。因此，

$$
\pi_{y_i|i} = \frac{P(x_i, y_i|\theta)}{\sum_{y_i \in Y_i} P(x_i, y_i|\theta)} = \frac{P(y_i|x_i, \theta)}{P(y_i| \theta)} = P(y_i|x_i, \theta)
$$

这是后验类概率。在PiCO中，这是通过使用分类器的输出来估计的。

为了估计 $P(y_i|x_i, \theta)$ ，传统的无监督聚类方法直观地将数据示例分配给簇中心，例如k均值。然而，在监督学习的设置中，我们可以直接使用真实标签。然而，在PLL的设置下，监督信号介于监督和无监督设置之间。基于经验发现，候选标签在开始时对后验估计更可靠；然而，随着训练过程的进行，原型趋向于变得更加可信。这一经验观察激发了我们以移动平均风格更新伪目标。因此，我们在估计类后验时有一个很好的初始化，并且在训练过程中它将被平滑地细化。这在第IV-B2节和附录B.1.4中的实证研究中得到了验证。

M步骤：在这一步中，我们的目标是在已知后验类概率的假设下最大化似然。我们展示了在温和的假设下，最小化（16）也最大化了（17）中的下界。

定理1：假设在对比输出空间中来自同一类别的数据遵循d变量von Mises-Fisher (vMF)分布，其概率密度由 $f(x|\bar{\mu}_i, \kappa) = c_d(\kappa)e^{\kappa \bar{\mu}_i^T g(x)}$ 给出，其中 $\bar{\mu}_i = \mu_i / ||\mu_i||$ 是均值方向， $\kappa$ 是浓度参数， $c_d(\kappa)$ 是归一化因子。我们进一步假设类先验是均匀的 $P(y_i = j) = 1/C$ 。设 $n_j = |S_j|$ 。那么，优化（16）和（17）等同于最大化以下R1和R2：

$$
R1 = \sum_{S_j \in D_C} n_j ||\mu_j||^2 \leq \sum_{S_j \in D_C} n_j ||\mu_j|| = R2
$$

证明可以在附录A中找到。定理1表明，最小化 (16) 也最大化了 (17) 中似然的下界。当  $\|\mu_j\|$  接近 1 时，下界是紧密的。这意味着在超球面上类内集中性强，从而在欧几里得空间中类内协方差低。直观上说，当假设空间足够丰富时，可以在欧几里得空间中实现低类内协方差，这导致在超球面上的归一化嵌入也具有强烈的类内集中性，因为较大的 $\|\mu_j\|$ 也会导致较大的浓度参数 $\kappa$ [36]。从图4中的可视化表示来看，我们注意到PiCO确实能够学习到紧凑的簇。因此，最小化对比损失也部分地最大化了定义在 (17) 中的似然。

关于PiCO+的鲁棒性：上述理论结果也有助于分析PiCO+。一方面，PiCO的聚类效应鼓励样本与原型对齐。由于深度网络在训练初期倾向于找到简单的模式[37]，那些干净的样本可以更快地移动到类中心，这一点在附录B.9中的实证研究得到了验证。另一方面，在样本选择之后，我们的半监督对比学习过程也可以（近似地）被视为一个部分标签学习问题，如果我们将噪声数据视为一个完整标签候选集的相关性。因此，PiCO+也运行了一个EM算法，该算法借助对比学习的聚类效应来训练鲁棒分类器。

# VII. 结论

在这项工作中，我们提出了一个新颖的噪声部分标签学习框架PiCO+，它主要由PiCO算法驱动。关键思想是使用对比学习到的嵌入原型从候选集中识别真实标签。此外，我们的PiCO+通过样本选择和半监督训练扩展了PiCO，使其能够从噪声部分标签中学习鲁棒分类器。理论分析表明，PiCO可以从EM算法的角度进行解释。从实证角度来看，我们进行了广泛的实验，并展示了PiCO和PiCO+建立了最先进的性能，并展示了对分布内噪声和分布外噪声的鲁棒性。我们的结果与完全监督设置具有竞争力，其中真实标签被明确给出。具有模糊标签的多类分类应用可以从我们的方法中受益，我们期待在PLL领域进一步研究，将此框架扩展到图像分类之外的任务。我们希望我们的工作能够吸引社区更多关注，从更广泛的角度使用对比原型进行部分标签学习。

# 声明

本文内容为论文学习收获分享，受限于知识能力，本文队员问的理解可能存在偏差，最终内容以原论文为准。本文信息旨在传播和学术交流，其内容由作者负责，不代表本号观点。文中作品文字、图片等如涉及内容、版权和其他问题，请及时与我们联系，我们将在第一时间回复并处理。
